{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WZ0d_-vHn51U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZ0d_-vHn51U",
    "outputId": "5e0eb4a5-f0dc-440a-a4ae-2778111e23ea"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "454e0124",
   "metadata": {
    "id": "454e0124"
   },
   "source": [
    "# Speaker-Independent Spoken Digit Recognition (xSDR)\n",
    "\n",
    "\n",
    "One of the successful stories of deep neural networks is the proliferation of commercial of automatic speech recognition (ASR) systems. This project aims to explore one application of ML-powered ASR to the problem of spoken digit recognition (SDR). Since digits are widely used as unique identifiers for bank information, social security numbers, post codes, etc, SDR systems can be an efficient alternative to fully-fledged ASR systems since the domain is more predictable than other applications of ASR. \n",
    "\n",
    "In this project, we focus on developing a SDR system in a speaker-independent setting. That is, the speakers in the evaluation set are disjoint from the training set speakers. We do so because we expect real-world ASR systems to generalize to different speakers than those we have data for. Moreover, for many languages that are under-resourced, we have have (limited) annotated speech data from a single speaker, but we would still want the system to be deployed to work on any speaker of that language. We tackle the problem of spoken digit recognition as a sequence classification task. Concretely, the inputs are short audio clips of a specific digit (in the range 0-9), then the goal is to build deep neural network models to classify a short audio clip and predict the digit that was spoken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be83711d-f753-44e7-9521-8881623b9521",
   "metadata": {
    "id": "be83711d-f753-44e7-9521-8881623b9521"
   },
   "source": [
    "# Notes\n",
    "\n",
    "## Code Submission\n",
    "\n",
    "You don't necessarily need to complete the code in this Jupyter Notebook, you are free to use another notebook or a python script file, as you would like. You are expected to submit the code by **22.03.2023**.\n",
    "\n",
    "Your code should be clean and well commented. We also expect that if we decide to run it on our system, it should be straighforward to do so. We recommend creating a ```requirements.txt``` file with the names of all the libraries with their versions. If applicable, please mention the python version in a ```README.md``` file, which should also include instructions on how to run your code.\n",
    "\n",
    "As mentioned for the assignments, always remember to cite the code with the links as comments, if you decide to use it from a public repository.\n",
    "\n",
    "## Report Submission\n",
    "\n",
    "With the code, you are also expected to submit a report with a maximum of 4 pages. You should write your report in LaTeX using this template for ACL 2023 [Overleaf Link](https://www.overleaf.com/latex/templates/acl-2023-proceedings-template/qjdgcrdwcnwp). Use this document to fill in any missing information that are not necessarily covered during your presentation for the sake of time in the presentation. While writing your report, we would highly encourgae you to cite the papers behind each tool / library / function that you might use for your experiments. We have also released an example on how to write equations in LaTeX [here](https://piazza.com/class/l9so16qqvk34hu/post/52).\n",
    "\n",
    "You art also expected to submit this report with your code. You should provide the **.tex, .pdf and all image files** zipped with the same naming convention as it was in your assignment(s).\n",
    "\n",
    "## Presentation\n",
    "\n",
    "During the last week of March 2023, i.e. 27.03 -- 31.03, each team will be presenting their works for 15 minutes. We expect equal contribution from each member in delivery and content of the presentation. So roughly 5 minutes for one person, if you have 3 people in your team. There will be 5 minutes for some Q&A. At-least one person from your team should be present to do an in-person presentation, rest of your team could join remotely, if they are not present.\n",
    "\n",
    "## Important Dates\n",
    "\n",
    " - Code & Report Submission: 22.03.2023 (08.00)\n",
    " - Presentation: 27.03.2023 -- 31.03.2023\n",
    " \n",
    " You'll get a precise date and time for your team's presentation at a later time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61601679-f2f0-437a-8233-54c5ab0cac17",
   "metadata": {
    "id": "61601679-f2f0-437a-8233-54c5ab0cac17"
   },
   "source": [
    "### Grading\n",
    "\n",
    "In this project, your final grades will be determined as follows:\n",
    "\n",
    " - **30%**: &emsp; Completing all the tasks\n",
    " - **30%**: &emsp; Providing scientific-backings for all the methods used\n",
    " - **20%**: &emsp; Quality of the content of the presentation\n",
    " - **20%**: &emsp; Delivery of the presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020b704f",
   "metadata": {
    "id": "020b704f"
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy, matplotlib.pyplot as plt, IPython.display as ipd\n",
    "import librosa, librosa.display\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn  import preprocessing\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# add this to ignore warnings from Librosa\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b2719f5",
   "metadata": {
    "id": "2b2719f5"
   },
   "outputs": [],
   "source": [
    "# for linear models \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f70e4098",
   "metadata": {
    "id": "f70e4098"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2lmVUx97rUcx",
   "metadata": {
    "id": "2lmVUx97rUcx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "import itertools\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0a0884",
   "metadata": {
    "id": "6a0a0884"
   },
   "source": [
    "## Exploring the Dataset \n",
    "\n",
    "The speech samples are already divied into training, development, and test spilts. The splits are made in such way that evaluation speakers are not present in training split. You should use the splits as they are. \n",
    "\n",
    "**CAUTION:** \n",
    "\n",
    "In this project, you are not allowed to use any external data for this problem (at least for the main three tasks). Exploring the effect of additional datasets in this project can only included as a further step after completing the main requirements with the given data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c40503e1",
   "metadata": {
    "id": "c40503e1"
   },
   "outputs": [],
   "source": [
    "# read tsv file into a dataframe \n",
    "sdr_df = pd.read_csv('SDR_metadata.tsv', sep='\\t', header=0, index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9a087bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "b9a087bc",
    "outputId": "a14d1248-936b-4bed-c9ba-a647409d11c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>speaker</th>\n",
       "      <th>split</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5_theo_23</td>\n",
       "      <td>theo</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>5</td>\n",
       "      <td>speech_data/5_theo_23.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_yweweler_39</td>\n",
       "      <td>yweweler</td>\n",
       "      <td>TEST</td>\n",
       "      <td>2</td>\n",
       "      <td>speech_data/2_yweweler_39.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6_yweweler_34</td>\n",
       "      <td>yweweler</td>\n",
       "      <td>DEV</td>\n",
       "      <td>6</td>\n",
       "      <td>speech_data/6_yweweler_34.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6_yweweler_16</td>\n",
       "      <td>yweweler</td>\n",
       "      <td>DEV</td>\n",
       "      <td>6</td>\n",
       "      <td>speech_data/6_yweweler_16.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9_yweweler_2</td>\n",
       "      <td>yweweler</td>\n",
       "      <td>TEST</td>\n",
       "      <td>9</td>\n",
       "      <td>speech_data/9_yweweler_2.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      identifier   speaker  split  label                           file\n",
       "0      5_theo_23      theo  TRAIN      5      speech_data/5_theo_23.wav\n",
       "1  2_yweweler_39  yweweler   TEST      2  speech_data/2_yweweler_39.wav\n",
       "2  6_yweweler_34  yweweler    DEV      6  speech_data/6_yweweler_34.wav\n",
       "3  6_yweweler_16  yweweler    DEV      6  speech_data/6_yweweler_16.wav\n",
       "4   9_yweweler_2  yweweler   TEST      9   speech_data/9_yweweler_2.wav"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c34786a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c34786a",
    "outputId": "93f69dfa-b19e-4e6b-f65e-71cf6b2ffc19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'george', 'jackson', 'lucas', 'nicolas', 'theo', 'yweweler'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(sdr_df.speaker.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "155ea375",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "155ea375",
    "outputId": "5665e700-95cb-47b1-f91a-bb4e5e256938"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>speaker</th>\n",
       "      <th>split</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>7_theo_0</td>\n",
       "      <td>theo</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>7</td>\n",
       "      <td>speech_data/7_theo_0.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    identifier speaker  split  label                      file\n",
       "700   7_theo_0    theo  TRAIN      7  speech_data/7_theo_0.wav"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# explore one sample: 7_theo_0\n",
    "sdr_df.loc[sdr_df['identifier'] == '7_theo_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e03e0920",
   "metadata": {
    "id": "e03e0920"
   },
   "outputs": [],
   "source": [
    "sample_wav_file = sdr_df.loc[sdr_df['identifier'] == '7_theo_0'].file[700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d853a68a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "d853a68a",
    "outputId": "de556b4f-efc4-44bd-8a4c-00aa641088e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'speech_data/7_theo_0.wav'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_wav_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab5f7e7",
   "metadata": {
    "id": "6ab5f7e7"
   },
   "source": [
    "## The Speech Waveform\n",
    "\n",
    "The acoustic realization of speech segment can be (digitally) viewed as a time-variant wavform $\\mathbf{S} \\in \\mathbb{R}^{n}$. Here, $n$ depends on both the duration of the speech segment and the sampling rate of the continous speech singal. Let's check out one sample from the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac93353b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "ac93353b",
    "outputId": "92837c7d-23f8-47e3-d2e9-3001630e9abc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# play and listen to a sample \n",
    "SAMPLING_RATE = 8000 # This value is determined by the wav file, DO NOT CHANGE\n",
    "x, sr = librosa.load(sample_wav_file, sr=SAMPLING_RATE) #, \n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7438910",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "b7438910",
    "outputId": "045f9a28-06af-45b8-ed9c-de15e9ad94c2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot as a waveform \n",
    "fig, ax = plt.subplots(figsize=(10, 2), sharex=True)\n",
    "\n",
    "img = librosa.display.waveshow(y=x, sr=sr, alpha=0.75, x_axis='time', color='blue')\n",
    "\n",
    "ax.set(title='Amplitude waveform')\n",
    "ax.set_ylabel('Amplitude')\n",
    "ax.label_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c4297e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3c4297e5",
    "outputId": "021a3d35-5857-4016-f2b2-753c20cb0093"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample duration in milliseconds\n",
    "(1000*len(x))/SAMPLING_RATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df44120",
   "metadata": {
    "id": "3df44120"
   },
   "source": [
    "In the cell above, you can see the temporal duration of the audio is 428.5 milliseconds. For digits in the range 0-9, the duration of the speech segment should be around 0.5 seconds with reasonable variation depending on speech rate (i.e., how fast the speaker speaks). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a0c08e",
   "metadata": {
    "id": "d2a0c08e"
   },
   "source": [
    "## The Speech Signal Representation - Mel Spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6370d9c2",
   "metadata": {
    "id": "6370d9c2"
   },
   "source": [
    "Humans can recognize and differentiate different speech sounds based on the frequency characteristics of the sounds. For machine learning applications, human speech is represented using spectro-temporal features in the [Mel-scale](https://en.wikipedia.org/wiki/Mel_scale) extracted from the speech sample. Mel-scale features are inspired by human speech perception and auditory processing whereby the human ear has difference sensitivity (or resolution) in differet frequency bandes. That is, the human ear can better recognize differences in in lower range frequences, while higher range frequences have a lower resolution. The Mel-scale is linear for frequencies in the range (0-1kHz), and logarithmic for frequencies above 1kHz.\n",
    "\n",
    "In the spectro-temporal representation of speech, a speech sample can be seen as a sequence of $T$ spectral vectors as $\\mathbf{X} = (\\mathbf{x}^1, \\mathbf{x}^2, \\dots, \\mathbf{x}^T)$. Each spectral vector $\\mathbf{x}^t \\in \\mathbb{R}^{k}$ at time-step $t$ is extracted from a short speech segment (~25 milliseconds) with the assumption that the signal is time-invariant in this small time window. Here, $k$ is the number of frequency bands in the [spectrogram](https://en.wikipedia.org/wiki/Spectrogram) and this is a parameter of the feature extraction pipeline. The representation is based on the Fourier transform to convert the temporal signal into the frequency domain. \n",
    "\n",
    "In automatic speech recognition (ASR) research and applications, spectral vectors are usually referred to as \"acoustic frames\". Morover, adjacent frames are extracted with some overlap between them, usually ~10 milliseconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef41492d",
   "metadata": {
    "id": "ef41492d"
   },
   "outputs": [],
   "source": [
    "def extract_melspectrogram(signal, sr, num_mels):\n",
    "    \"\"\"\n",
    "    Given a time series speech signal (.wav), sampling rate (sr), \n",
    "    and the number of mel coefficients, return a mel-scaled \n",
    "    representation of the signal as numpy array.\n",
    "    \"\"\"\n",
    "    \n",
    "    mel_features = librosa.feature.melspectrogram(y=signal,\n",
    "        sr=sr,\n",
    "        n_fft=200, # with sampling rate = 8000, this corresponds to 25 ms\n",
    "        hop_length=80, # with sampling rate = 8000, this corresponds to 10 ms\n",
    "        n_mels=num_mels, # number of frequency bins, use either 13 or 39\n",
    "        fmin=50, # min frequency threshold\n",
    "        fmax=4000 # max frequency threshold, set to SAMPLING_RATE/2\n",
    "    )\n",
    "    \n",
    "    # for numerical stability added this line\n",
    "    mel_features = np.where(mel_features == 0, np.finfo(float).eps, mel_features)\n",
    "\n",
    "    # 20 * log10 to convert to log scale\n",
    "    log_mel_features = 20*np.log10(mel_features)\n",
    "\n",
    "    # feature scaling\n",
    "    scaled_log_mel_features = preprocessing.scale(log_mel_features, axis=1)\n",
    "    \n",
    "    return scaled_log_mel_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3600d78e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3600d78e",
    "outputId": "087ea676-2acb-475b-af0d-33e022008476"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4403375 , -1.1560788 , -1.2758843 , -1.3302561 , -1.455996  ,\n",
       "        -1.2271106 , -1.3477    , -1.1566846 , -1.1540704 , -1.317029  ,\n",
       "        -1.0830339 , -1.1264331 , -1.289925  , -1.291689  , -1.1598166 ,\n",
       "        -1.2263535 ,  0.2289877 ,  1.0015292 ,  1.0212659 ,  1.0087676 ,\n",
       "         1.0344915 ,  1.0081851 ,  0.95065796,  0.94541764,  1.024923  ,\n",
       "         1.0669168 ,  1.0016327 ,  1.026864  ,  1.057682  ,  0.98052514,\n",
       "         0.79963857,  0.5760491 ,  0.6717507 ,  0.7536291 ,  0.725084  ,\n",
       "         0.740158  ,  0.76018435,  0.6208987 ,  0.5152995 ,  0.24102668,\n",
       "         0.20198077,  0.0268851 ,  0.04796753],\n",
       "       [-1.5693731 , -1.1794999 , -1.1788254 , -0.9945803 , -1.2961985 ,\n",
       "        -1.4162161 , -1.177581  , -0.99777126, -1.0092193 , -1.5616904 ,\n",
       "        -0.99744636, -0.93611056, -1.1575567 , -1.0355861 , -0.82686776,\n",
       "        -1.0189241 ,  0.30772254,  1.0856628 ,  1.5396351 ,  1.5049155 ,\n",
       "         1.4061823 ,  1.3355076 ,  1.2298043 ,  1.1036735 ,  1.1364572 ,\n",
       "         1.1352123 ,  1.0290319 ,  0.9949448 ,  0.9711231 ,  0.82521033,\n",
       "         0.5849991 ,  0.39372113,  0.5395087 ,  0.6424302 ,  0.54114664,\n",
       "         0.5031837 ,  0.492552  ,  0.18268879,  0.1271016 , -0.08422625,\n",
       "        -0.1672305 , -0.47996524, -0.5275473 ],\n",
       "       [-1.7347753 , -1.4902945 , -1.0637255 , -0.9449346 , -1.1367611 ,\n",
       "        -1.3821775 , -1.1514153 , -1.0584965 , -0.9120909 , -1.0183238 ,\n",
       "        -1.1211722 , -1.0505496 , -1.1186196 , -0.84629875, -0.67956793,\n",
       "        -0.8126775 , -0.13979663,  1.094634  ,  1.5824354 ,  1.5133313 ,\n",
       "         1.3370779 ,  1.2957212 ,  1.3362716 ,  1.3376083 ,  1.3000916 ,\n",
       "         1.2101457 ,  1.1286147 ,  0.9476803 ,  0.80687857,  0.82495064,\n",
       "         0.60302794,  0.35593954,  0.4447451 ,  0.5568745 ,  0.4997836 ,\n",
       "         0.4804301 ,  0.44254974,  0.26389012,  0.20483992, -0.11112265,\n",
       "        -0.26211923, -0.6578617 , -0.8747412 ],\n",
       "       [-1.391722  , -1.1057345 , -0.89369917, -1.1324476 , -1.0548867 ,\n",
       "        -1.0672922 , -0.95176685, -1.0967911 , -1.159061  , -0.9692353 ,\n",
       "        -1.16986   , -1.0765302 , -1.0915915 , -0.95037764, -0.97501576,\n",
       "        -0.7668196 , -0.35911602,  0.7323629 ,  0.78120494,  0.8723504 ,\n",
       "         1.1471362 ,  1.4086066 ,  1.6043525 ,  1.6107941 ,  1.5172784 ,\n",
       "         1.4697207 ,  1.4265528 ,  1.3025454 ,  1.0307002 ,  0.90871304,\n",
       "         0.48845202,  0.11637936,  0.34936514,  0.5197037 ,  0.55319065,\n",
       "         0.72485423,  0.6400227 ,  0.4726943 ,  0.18429475, -0.14505036,\n",
       "        -0.58685225, -0.8559912 , -1.0614339 ],\n",
       "       [-1.2378834 , -1.0690638 , -1.0845468 , -1.0974616 , -0.9515945 ,\n",
       "        -0.67303336, -0.73205656, -0.5664825 , -0.91632193, -0.59681314,\n",
       "        -1.729224  , -0.95695883, -0.87773174, -1.0637627 , -0.9843711 ,\n",
       "        -1.1444131 , -0.6894361 ,  0.9440357 ,  0.9890242 ,  1.1497438 ,\n",
       "         1.2562567 ,  1.5192958 ,  1.6723098 ,  1.7464544 ,  1.722891  ,\n",
       "         1.6449761 ,  1.4856591 ,  1.3374709 ,  0.8617258 ,  0.57840896,\n",
       "         0.192197  ,  0.02490828,  0.13209909,  0.36241847,  0.2616569 ,\n",
       "         0.35075805,  0.31041983,  0.19894779, -0.00408759, -0.32760453,\n",
       "        -0.37675932, -0.5528305 , -1.1092207 ],\n",
       "       [-1.4006268 , -1.0861837 , -1.3198297 , -0.9787974 , -0.73835415,\n",
       "        -0.5997551 , -0.65040654, -0.38464463, -0.7562143 , -0.21641275,\n",
       "        -0.8029446 , -1.0548553 , -0.79353267, -1.3231087 , -0.80757856,\n",
       "        -1.1415468 , -0.4549507 ,  0.3057685 ,  0.97303164,  1.2037803 ,\n",
       "         1.4545047 ,  1.8000598 ,  1.9446265 ,  1.8351538 ,  1.6204934 ,\n",
       "         1.3838463 ,  1.466981  ,  1.2207112 ,  0.63571364,  0.6632989 ,\n",
       "         0.47909984,  0.260278  ,  0.0631672 ,  0.5652265 ,  0.15788119,\n",
       "         0.29223135,  0.31216472, -0.466851  , -0.3770921 , -0.820091  ,\n",
       "        -0.68052655, -0.2488652 , -1.5348498 ],\n",
       "       [-1.1604859 , -1.1081061 , -0.8004312 , -0.6004508 , -1.163995  ,\n",
       "        -1.0977411 , -0.72384083, -0.33615226, -0.5884144 , -1.0068698 ,\n",
       "        -0.9107716 , -0.80185944, -0.78995246, -1.123356  , -0.59977597,\n",
       "        -0.92553514, -0.7019691 ,  0.83703494,  1.0121129 ,  1.1563345 ,\n",
       "         1.3793348 ,  1.4224977 ,  1.5535913 ,  1.4102718 ,  1.6721659 ,\n",
       "         1.6228312 ,  1.3305485 ,  1.2557645 ,  1.3195627 ,  1.1468898 ,\n",
       "         0.70622426,  0.51273084,  0.274275  , -0.00279123, -0.34293407,\n",
       "         0.22326207,  0.4153832 ,  0.03341097, -0.21289395, -0.44918007,\n",
       "        -0.94323295, -1.2537293 , -1.6397576 ],\n",
       "       [-1.224631  , -1.3889189 , -1.1668657 , -0.91154546, -0.9136314 ,\n",
       "        -1.1551903 , -0.8498834 , -0.7785394 , -0.8782761 , -1.1086435 ,\n",
       "        -1.032553  , -0.9626374 , -0.9826151 , -0.6967043 , -0.8687933 ,\n",
       "        -0.83616567, -0.58914286,  0.78805435,  1.3718098 ,  1.5315164 ,\n",
       "         1.5354606 ,  1.2613461 ,  1.3146187 ,  1.2637851 ,  1.5079244 ,\n",
       "         1.5083734 ,  1.4883705 ,  1.311087  ,  0.88035506,  0.7504794 ,\n",
       "         0.52165043,  0.49400687,  0.07316224, -0.15788114,  0.12546025,\n",
       "         0.68024755,  0.51856625,  0.42927116,  0.16696355,  0.01403506,\n",
       "        -0.74686605, -1.0642383 , -1.2228216 ],\n",
       "       [-1.376043  , -1.2069814 , -1.0909749 , -0.73616195, -0.7629946 ,\n",
       "        -1.0372964 , -0.8295327 , -0.80660474, -0.98755425, -0.63249755,\n",
       "        -0.97861713, -0.9216698 , -0.64716405, -0.5026656 , -0.7023125 ,\n",
       "        -0.86213887, -0.4795573 ,  0.8636526 ,  1.4432814 ,  1.7099313 ,\n",
       "         1.4857544 ,  1.2720169 ,  1.4668548 ,  1.520963  ,  1.7631645 ,\n",
       "         1.7178949 ,  1.5884659 ,  0.9039222 ,  0.5934866 ,  0.6514836 ,\n",
       "         0.35097474,  0.18726349, -0.19331715, -0.07899404,  0.140248  ,\n",
       "         0.65516675,  0.37489817,  0.25950816, -0.10297746, -0.6152652 ,\n",
       "        -0.7899325 , -1.071251  , -1.5364273 ],\n",
       "       [-1.1287369 , -1.3636402 , -1.0309564 , -1.2836518 , -1.222579  ,\n",
       "        -0.47646654, -0.61427534, -0.26557466, -0.5702081 , -0.72345245,\n",
       "        -0.45195964, -0.1303016 , -0.19038033, -0.87785554, -0.4296246 ,\n",
       "        -0.69103676, -1.537294  ,  0.77080745,  1.1473993 ,  1.4454273 ,\n",
       "         1.5443386 ,  1.6217023 ,  1.6857096 ,  1.7525306 ,  1.6362176 ,\n",
       "         1.508248  ,  1.420724  ,  0.8127766 ,  0.55639255,  0.81307805,\n",
       "         0.55464566,  0.265626  ,  0.07289158,  0.20409253,  0.37197226,\n",
       "         0.04909446, -0.48726624, -0.02974502, -0.37944523, -0.47245988,\n",
       "        -0.99531555, -1.0934741 , -1.787975  ],\n",
       "       [-1.5213234 , -1.3167166 , -0.8005538 , -1.2255936 , -1.1421735 ,\n",
       "        -0.43306196, -0.20540479, -0.21420424, -0.67212176, -0.37037247,\n",
       "        -0.91484994, -0.35341507, -0.39017087, -0.59863204, -0.94305986,\n",
       "        -1.04821   , -0.7731913 ,  0.5954922 ,  1.3774819 ,  1.6170894 ,\n",
       "         1.5202674 ,  1.2329619 ,  1.6950921 ,  1.6540364 ,  1.3078051 ,\n",
       "         1.3647311 ,  1.6708016 ,  0.88015544,  0.80275285,  0.8653632 ,\n",
       "         0.5625749 ,  0.32926524, -0.0517568 ,  0.39110544,  0.6380077 ,\n",
       "         0.20038804, -0.2652747 ,  0.00867074, -0.7763578 , -0.618796  ,\n",
       "        -1.1655087 , -1.2900499 , -1.6232432 ],\n",
       "       [-0.522186  ,  0.33660203,  0.42096215, -0.13731626, -0.16935769,\n",
       "         0.33960742,  0.4296739 ,  0.34031618,  0.35388568,  0.05835257,\n",
       "        -0.00471124,  0.15801878,  0.18202017,  0.08629435, -0.18554765,\n",
       "        -0.8175839 , -0.9892813 ,  0.49452367,  1.5288466 ,  1.8874582 ,\n",
       "         1.773566  ,  1.529322  ,  2.0881257 ,  1.7933608 ,  1.1883214 ,\n",
       "         1.0894456 ,  1.2364604 ,  0.29833123, -0.04225687, -0.9231698 ,\n",
       "        -0.5578111 , -1.1133755 , -1.0978855 , -1.0957851 , -0.8076134 ,\n",
       "        -0.8105353 , -0.8676283 , -0.80955505, -1.332052  , -0.888753  ,\n",
       "        -1.539049  , -1.4084656 , -1.4935756 ],\n",
       "       [ 0.7652981 ,  1.6376963 ,  1.291755  ,  0.83253247,  1.0299186 ,\n",
       "         1.9516901 ,  1.4676487 ,  1.546585  ,  1.4420701 ,  0.71461904,\n",
       "         0.4467012 ,  0.55160636,  0.7515761 ,  0.75352484,  0.4540209 ,\n",
       "        -0.3602208 , -1.195288  , -0.5026396 ,  0.05484153,  0.2042861 ,\n",
       "         0.6088298 ,  0.4951964 ,  0.6325824 ,  0.58348024,  0.3796947 ,\n",
       "         0.46429443, -0.02022593, -0.45058352, -0.4996492 , -0.7221903 ,\n",
       "        -0.578028  , -1.0459657 , -0.9391036 , -1.1912518 , -1.0020903 ,\n",
       "        -0.83425426, -1.4063542 , -1.2765743 , -1.4369782 , -1.5630101 ,\n",
       "        -1.3645761 , -1.3404114 , -1.3310536 ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melspectrogram = extract_melspectrogram(x, sr, num_mels=13)\n",
    "melspectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae0a639",
   "metadata": {
    "id": "7ae0a639"
   },
   "source": [
    "Note that the shape of the array (K x T) represents the number of frequency bands (K) and the number of spectral vectors in this representation (here, K=13, T=43). K is a hyperparameter and the recommended values in ASR research are (13, 39, 81, etc). Here, we fix K = 13. On the other hand, T varies from sample to sample depending on the duration of the sample.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f17e8976",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "f17e8976",
    "outputId": "d9adb5ab-2e6b-4467-b213-b95b4bdbfd34"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot and view the spectrogram\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 2), sharex=True)\n",
    "\n",
    "img = librosa.display.specshow(\n",
    "    melspectrogram, \n",
    "    sr=sr, \n",
    "    x_axis='time', \n",
    "    y_axis='mel', \n",
    "    cmap='viridis', \n",
    "    fmax=4000, \n",
    "    hop_length=80\n",
    ")\n",
    "\n",
    "ax.set(title='Log-frequency power spectrogram')\n",
    "\n",
    "ax.label_outer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c872b6",
   "metadata": {
    "id": "e6c872b6"
   },
   "source": [
    "As you can see above from the figure, the spectrogram representation can be viewed as a matrix $\\mathbf{X} \\in \\mathbb{R}^{T} \\times \\mathbb{R}^{k}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5392b92",
   "metadata": {
    "id": "d5392b92"
   },
   "source": [
    "## Task I\n",
    "1. One problem with the spectrogram as a speech feature represetation is that different speech samples would have dfferent durations due to inherent speech variability (e.g., speech rate, speaker dialect, etc). That is, the $T$ in the $(T \\times k)$-dimensional representation would be different for each sample. Therefore, for the baseline model, we will implement a method to have a fixed-size representation for all speech samples. Write a function downsample_spectrogram(X, N) that takes as input a spectrogram $\\mathbf{X} \\in \\mathbb{R}^{T \\times k}$ and a parameter N <= 25. The function should (1) make N equally-sized splits of S across the time-axis, (2) apply a pooling technique (e.g., mean pooling) to each split across the frequency axis to obtain an array that represents a downsampled version of the spectrogram $\\mathbf{X}' \\in \\mathbb{R}^{N \\times k}$, and (3) re-arange $\\mathbf{X}'$ as a vector $\\mathbf{v} \\in \\mathbb{R}^{Nk}$.    \n",
    "\n",
    "2. Using the downsample_spectrogram(X, N) function, transform all the speech samples into vectors $\\mathbf{v} \\in \\mathbb{R}^{Nk}$. \n",
    "\n",
    "3. Given the speaker-based train/dev/test spilts in the SDR_metadata.tsv, fit a linear model on the training samples. That is, your model should be build on data from 4 speakers {'nicolas', 'theo' , 'jackson',  'george'}. Hint: you can experiment with a few model alternatives in the SGDClassifier module in scikit-learn. \n",
    "\n",
    "4. Evaluate you model on the dev and test splits. Use accuracy as an evaluation metric. Analyze the model performance using a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) of the all possible labels (0-9), Analyze [precision, recall](https://en.wikipedia.org/wiki/Precision_and_recall), [F1-score](https://en.wikipedia.org/wiki/F-score) for each label. Report your observation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IN0veh4vphwX",
   "metadata": {
    "id": "IN0veh4vphwX"
   },
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7a0e8ce",
   "metadata": {
    "id": "e7a0e8ce"
   },
   "outputs": [],
   "source": [
    "def downsample_spectrogram(X, N):\n",
    "    k, T = X.shape\n",
    "    M = T // N\n",
    "    X_downsampled = np.zeros((N,k ))\n",
    "\n",
    "    for i in range(N):\n",
    "        X_split = X[:, i*M:(i+1)*M]\n",
    "        X_downsampled[i, :] = np.mean(X_split, axis=1)\n",
    "\n",
    "    v = X_downsampled.reshape(k, N).astype(float)\n",
    "\n",
    "    return v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3b4235f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "e3b4235f",
    "outputId": "4865a780-2a87-4cbf-a606-8d4096f6b910"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>speaker</th>\n",
       "      <th>split</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5_theo_23</td>\n",
       "      <td>theo</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>5</td>\n",
       "      <td>speech_data/5_theo_23.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4_george_11</td>\n",
       "      <td>george</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>4</td>\n",
       "      <td>speech_data/4_george_11.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8_george_18</td>\n",
       "      <td>george</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>8</td>\n",
       "      <td>speech_data/8_george_18.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8_george_13</td>\n",
       "      <td>george</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>8</td>\n",
       "      <td>speech_data/8_george_13.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2_nicolas_16</td>\n",
       "      <td>nicolas</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>2</td>\n",
       "      <td>speech_data/2_nicolas_16.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>7_nicolas_38</td>\n",
       "      <td>nicolas</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>7</td>\n",
       "      <td>speech_data/7_nicolas_38.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>2_theo_5</td>\n",
       "      <td>theo</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>2</td>\n",
       "      <td>speech_data/2_theo_5.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>8_george_29</td>\n",
       "      <td>george</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>8</td>\n",
       "      <td>speech_data/8_george_29.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>1_theo_24</td>\n",
       "      <td>theo</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>1</td>\n",
       "      <td>speech_data/1_theo_24.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>8_george_4</td>\n",
       "      <td>george</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>8</td>\n",
       "      <td>speech_data/8_george_4.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        identifier  speaker  split  label                          file\n",
       "0        5_theo_23     theo  TRAIN      5     speech_data/5_theo_23.wav\n",
       "6      4_george_11   george  TRAIN      4   speech_data/4_george_11.wav\n",
       "7      8_george_18   george  TRAIN      8   speech_data/8_george_18.wav\n",
       "8      8_george_13   george  TRAIN      8   speech_data/8_george_13.wav\n",
       "9     2_nicolas_16  nicolas  TRAIN      2  speech_data/2_nicolas_16.wav\n",
       "...            ...      ...    ...    ...                           ...\n",
       "2988  7_nicolas_38  nicolas  TRAIN      7  speech_data/7_nicolas_38.wav\n",
       "2989      2_theo_5     theo  TRAIN      2      speech_data/2_theo_5.wav\n",
       "2990   8_george_29   george  TRAIN      8   speech_data/8_george_29.wav\n",
       "2996     1_theo_24     theo  TRAIN      1     speech_data/1_theo_24.wav\n",
       "2998    8_george_4   george  TRAIN      8    speech_data/8_george_4.wav\n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('SDR_metadata.tsv', sep='\\t', header=0, index_col='Unnamed: 0')\n",
    "SPEAKERS = {'nicolas', 'theo', 'jackson', 'george'}\n",
    "train_data = df[df['split'] == 'TRAIN']\n",
    "train_data= train_data[train_data['speaker'].isin(SPEAKERS)]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7926b346",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7926b346",
    "outputId": "428c5bb8-ccd4-4253-f638-29986d9b97e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.29820824, -1.3744365 , -1.61253488, -1.24872828, -1.15347362,\n",
       "        -1.24340522, -1.13429594, -1.30677485, -1.29151225, -1.24618852,\n",
       "        -1.41901994, -0.09279197,  1.2014972 , -1.30307019, -1.08670282],\n",
       "       [-1.00433004, -1.01307344, -1.09100413, -1.14931357, -0.700441  ,\n",
       "        -1.03920555, -0.91356844, -1.15730405, -1.01307368,  0.14182295,\n",
       "         1.06214368, -1.34155333, -1.35620737, -1.25946927, -1.06108952],\n",
       "       [-0.81231391, -0.66905463, -1.13086808, -1.03441083, -0.90014553,\n",
       "        -0.84952277, -0.78761774,  0.08512487,  1.49080431, -1.25219226,\n",
       "        -1.08767605, -1.10495591, -1.024279  , -0.64926952, -0.51752555],\n",
       "       [-0.52999651, -0.81421137, -0.81806874, -0.43992501, -0.20980451,\n",
       "         0.38499504,  1.50711679, -1.23554969, -1.28545487, -0.96520734,\n",
       "        -1.06414819, -0.75656754, -0.48631352, -0.79764211, -0.99345982],\n",
       "       [-0.81002593, -0.64683026, -0.52124715,  0.20611912,  1.07834458,\n",
       "        -1.10473347, -0.96677846, -1.08586097, -1.12319517, -1.34309137,\n",
       "        -0.9289    , -0.85631549, -0.99759519, -0.95014346, -0.2911306 ],\n",
       "       [-0.6341325 ,  0.07665377,  0.49915379, -1.29080701, -1.09657145,\n",
       "        -0.98245919, -1.02098453, -0.97074723, -1.05832064, -0.95665419,\n",
       "        -0.83965969, -0.57491481, -0.53411794, -0.49440145,  0.13415727],\n",
       "       [ 0.75255048, -1.19308507, -0.92289591, -0.74612272, -0.87091768,\n",
       "        -1.06439209, -0.9745627 , -0.76265556, -0.85247946, -0.78222573,\n",
       "        -0.56033069, -0.99563491, -0.50156581,  0.04690005,  0.61525846],\n",
       "       [ 0.69669271,  0.47741872,  0.18662345,  0.12729982, -0.0745911 ,\n",
       "         0.06753293,  0.09945574,  0.19204764, -0.38324329, -0.08884954,\n",
       "        -0.24737881, -0.84896374,  1.01501679,  1.52227521,  1.54788327],\n",
       "       [ 0.8267777 ,  1.06938398,  1.08840597,  1.08422375,  1.45166314,\n",
       "         1.57660627,  1.2964133 ,  1.4972856 ,  1.70815241,  0.12956381,\n",
       "         1.02133834,  1.37084496,  1.31639957,  1.27787137,  1.38777626],\n",
       "       [ 1.62728226,  1.40091634,  1.39840341,  1.37888563,  1.58302045,\n",
       "         1.37661457,  1.65144396,  0.5520131 ,  0.9480378 ,  1.16673887,\n",
       "         1.33694005,  1.60757327,  1.70938206,  1.88989019,  1.48193145],\n",
       "       [ 1.28920197,  1.49390888,  1.71912003,  1.67456424,  1.94074321,\n",
       "         0.60803133,  1.0459199 ,  1.13583469,  1.25511861,  1.49349952,\n",
       "         1.6839335 ,  1.50216985,  1.64749861,  1.50814891,  1.74052978],\n",
       "       [ 1.57223272,  1.33626807,  1.13888347,  0.42199457,  1.01424837,\n",
       "         1.0119884 ,  1.03814745,  1.36454916,  1.41156507,  1.34384608,\n",
       "         1.2931565 ,  1.39972878,  1.24619412,  1.11675036,  1.2754786 ],\n",
       "       [ 0.76739585, -0.23540473,  1.01910353,  0.89816672,  0.81591463,\n",
       "         0.96970665,  0.72006738,  0.64950627,  1.2332263 ,  0.81541723,\n",
       "         0.6224851 ,  0.6847353 ,  0.83405805, -0.48271334, -0.61091977]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsample_spectrogram(melspectrogram, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a9105e9",
   "metadata": {
    "id": "0a9105e9"
   },
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    # Load the data into a pandas dataframe\n",
    "    df = pd.read_csv(filepath, sep='\\t')\n",
    "    SPEAKERS = {'nicolas', 'theo', 'jackson', 'george'}\n",
    "    \n",
    "    # Split the data into train, dev, and test sets\n",
    "    train_data = df[df['split'] == 'TRAIN']\n",
    "    train_data= train_data[train_data['speaker'].isin(SPEAKERS)]\n",
    "    dev_data = df[df['split'] == 'DEV']\n",
    "    test_data = df[df['split'] == 'TEST']\n",
    "    \n",
    "    # Extract the X and y data for each split\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for x in train_data['file'].tolist():\n",
    "        X = extract_melspectrogram(librosa.load(x)[0],sr=8000, num_mels=13)\n",
    "        X_train.append(X)\n",
    "        y_train.append(train_data.loc[train_data['file'] == x, 'label'].iloc[0])\n",
    "    \n",
    "    X_dev = []\n",
    "    y_dev = []\n",
    "    for x in dev_data['file'].tolist():\n",
    "        X = extract_melspectrogram(librosa.load(x)[0],sr=8000, num_mels=13)\n",
    "        X_dev.append(X)\n",
    "        y_dev.append(dev_data.loc[dev_data['file'] == x, 'label'].iloc[0])\n",
    "    \n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for x in test_data['file'].tolist():\n",
    "        X = extract_melspectrogram(librosa.load(x)[0],sr=8000, num_mels=13)\n",
    "        X_test.append(X)\n",
    "        y_test.append(test_data.loc[test_data['file'] == x, 'label'].iloc[0])\n",
    "    \n",
    "    # Return the data as a tuple of lists\n",
    "    return X_train, y_train, X_dev, y_dev, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75db1700",
   "metadata": {
    "id": "75db1700"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_dev, y_dev, X_test, y_test = load_data('SDR_metadata.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bac6f4c4",
   "metadata": {
    "id": "bac6f4c4"
   },
   "outputs": [],
   "source": [
    "N = 10  # Desired length of the downsampled representation\n",
    "\n",
    "X_train_downsampled = np.array([downsample_spectrogram(X, N) for X in X_train])\n",
    "max_length = max([len(X) for X in X_train_downsampled])\n",
    "X_train_downsampled_padded = np.zeros((len(X_train), max_length*N))\n",
    "for i, x in enumerate(X_train_downsampled):\n",
    "    x_padded = np.pad(x, ((0, max_length - len(x)), (0, 0)), mode='constant')\n",
    "    X_train_downsampled_padded[i, :] = x_padded.reshape(-1)\n",
    "\n",
    "X_dev_downsampled = np.array([downsample_spectrogram(X, N) for X in X_dev])\n",
    "X_dev_downsampled_padded = np.zeros((len(X_dev), max_length*N))\n",
    "for i, x in enumerate(X_dev_downsampled):\n",
    "    x_padded = np.pad(x, ((0, max_length - len(x)), (0, 0)), mode='constant')\n",
    "    X_dev_downsampled_padded[i, :] = x_padded.reshape(-1)\n",
    "\n",
    "X_test_downsampled = np.array([downsample_spectrogram(X, N) for X in X_test])\n",
    "X_test_downsampled_padded = np.zeros((len(X_test), max_length*N))\n",
    "for i, x in enumerate(X_test_downsampled):\n",
    "    x_padded = np.pad(x, ((0, max_length - len(x)), (0, 0)), mode='constant')\n",
    "    X_test_downsampled_padded[i, :] = x_padded.reshape(-1)\n",
    "\n",
    "# Convert data types\n",
    "X_train_downsampled_padded = X_train_downsampled_padded.astype(np.float64)\n",
    "X_dev_downsampled_padded = X_dev_downsampled_padded.astype(np.float64)\n",
    "X_test_downsampled_padded = X_test_downsampled_padded.astype(np.float64)\n",
    "y_train = np.array([y_train])\n",
    "y_train = y_train.ravel()\n",
    "y_train_1 = y_train.astype(np.float64)\n",
    "\n",
    "y_dev = np.array([y_dev])\n",
    "y_dev = y_dev.ravel()\n",
    "y_dev_1 = y_dev.astype(np.float64)\n",
    "\n",
    "y_test = np.array([y_test])\n",
    "y_test = y_test.ravel()\n",
    "y_test_1 = y_test.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2445a4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "f2445a4e",
    "outputId": "e6944b65-ff73-4203-9216-334da616e7e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(loss='log', random_state=42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a linear model using scikit-learn's SGDClassifier\n",
    "model = SGDClassifier(loss='log', max_iter=1000, random_state=42)\n",
    "\n",
    "# Fit the model on the training samples\n",
    "model.fit(X_train_downsampled_padded,y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7233b9b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7233b9b5",
    "outputId": "046b19a8-125f-47a7-eb79-0cbf9a2e7ee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev accuracy: 0.376\n",
      "Test accuracy: 0.419\n",
      "Dev confusion matrix:\n",
      "[[38  0  2  0  0  0  2  1  0  4]\n",
      " [ 0 21  0  0  2  2 11  1  4  4]\n",
      " [15  0  5  0  2  0 16  5  3  0]\n",
      " [ 0  0  0 15  0  1 25  5  3  5]\n",
      " [32  1  1  0 13  0  4  2  1  0]\n",
      " [ 0  1  0  1  0  3 41  2  2  0]\n",
      " [ 0  3  0  2  0  0 27  6  8  8]\n",
      " [ 2  0  1  0  0  0 19 28  2  1]\n",
      " [ 0  0  0  1  0  0 25  2 13  3]\n",
      " [ 0  1  0  0  0 10 13  1  1 24]]\n",
      "Test confusion matrix:\n",
      "[[43  1  0  0  0  0  3  4  1  1]\n",
      " [ 0 38  0  0  1  0  9  2  4  1]\n",
      " [13  1  8  0  1  0 15 14  2  0]\n",
      " [ 0  1  0 12  0  0 17  6  1  9]\n",
      " [19  3  0  0  7  0  7  8  2  0]\n",
      " [ 0  2  0  0  0  9 33  5  0  1]\n",
      " [ 1  0  1  0  0  0 26  6  7  5]\n",
      " [ 2  2  1  0  0  1  7 28  6  0]\n",
      " [ 0  0  0  0  0  3 25  4 18  6]\n",
      " [ 0  0  0  0  0  3 13 10  2 22]]\n",
      "Dev classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.81      0.57        47\n",
      "         1.0       0.78      0.47      0.58        45\n",
      "         2.0       0.56      0.11      0.18        46\n",
      "         3.0       0.79      0.28      0.41        54\n",
      "         4.0       0.76      0.24      0.37        54\n",
      "         5.0       0.19      0.06      0.09        50\n",
      "         6.0       0.15      0.50      0.23        54\n",
      "         7.0       0.53      0.53      0.53        53\n",
      "         8.0       0.35      0.30      0.32        44\n",
      "         9.0       0.49      0.48      0.48        50\n",
      "\n",
      "    accuracy                           0.38       497\n",
      "   macro avg       0.50      0.38      0.38       497\n",
      "weighted avg       0.50      0.38      0.38       497\n",
      "\n",
      "Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.81      0.66        53\n",
      "         1.0       0.79      0.69      0.74        55\n",
      "         2.0       0.80      0.15      0.25        54\n",
      "         3.0       1.00      0.26      0.41        46\n",
      "         4.0       0.78      0.15      0.25        46\n",
      "         5.0       0.56      0.18      0.27        50\n",
      "         6.0       0.17      0.57      0.26        46\n",
      "         7.0       0.32      0.60      0.42        47\n",
      "         8.0       0.42      0.32      0.36        56\n",
      "         9.0       0.49      0.44      0.46        50\n",
      "\n",
      "    accuracy                           0.42       503\n",
      "   macro avg       0.59      0.42      0.41       503\n",
      "weighted avg       0.59      0.42      0.41       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Evaluate the model on the dev and test splits\n",
    "y_dev_pred = model.predict(X_dev_downsampled_padded)\n",
    "y_test_pred = model.predict(X_test_downsampled_padded)\n",
    "\n",
    "dev_accuracy = accuracy_score(y_dev_1, y_dev_pred)\n",
    "test_accuracy = accuracy_score(y_test_1, y_test_pred)\n",
    "\n",
    "dev_confusion_matrix = confusion_matrix(y_dev_1, y_dev_pred)\n",
    "test_confusion_matrix = confusion_matrix(y_test_1, y_test_pred)\n",
    "\n",
    "dev_classification_report = classification_report(y_dev_1, y_dev_pred)\n",
    "test_classification_report = classification_report(y_test_1, y_test_pred)\n",
    "\n",
    "print(f\"Dev accuracy: {dev_accuracy:.3f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.3f}\")\n",
    "print(f\"Dev confusion matrix:\\n{dev_confusion_matrix}\")\n",
    "print(f\"Test confusion matrix:\\n{test_confusion_matrix}\")\n",
    "print(f\"Dev classification report:\\n{dev_classification_report}\")\n",
    "print(f\"Test classification report:\\n{test_classification_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "rhcS1rIwjldh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "rhcS1rIwjldh",
    "outputId": "5936d12d-91d0-48b7-f2f5-a4c12de9d23f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(test_confusion_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "ax.set(xticks=np.arange(test_confusion_matrix.shape[1]),\n",
    "       yticks=np.arange(test_confusion_matrix.shape[0]),\n",
    "       xticklabels=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
    "       yticklabels=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
    "       xlabel='Predicted label',\n",
    "       ylabel='True label')\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "fmt = 'd'\n",
    "thresh = test_confusion_matrix.max() / 2.\n",
    "for i in range(test_confusion_matrix.shape[0]):\n",
    "    for j in range(test_confusion_matrix.shape[1]):\n",
    "        ax.text(j, i, format(test_confusion_matrix[i, j], fmt),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if test_confusion_matrix[i, j] > thresh else \"black\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KnskL0ZIp2Bb",
   "metadata": {
    "id": "KnskL0ZIp2Bb"
   },
   "source": [
    "In the baseline model, we got a Dev accuracy of 0.342 and Test accuracy of 0.386. \n",
    "When we look at the Classification report, we can see that the precision, recall and f1-score is highest for 1, 0 and 0 repectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d62c9",
   "metadata": {
    "id": "435d62c9"
   },
   "source": [
    "## Task II\n",
    "1. Having established a baseline with a linear model trained on a downsampled signal representation of the speech segment, this task aims to learn a classifier based on the full speech segment. To this end, you will implement a neural model that is suitable for sequential data such as recurrent DNN, convolutional DNN with 1-D temporal convolution, or an audio transformer. The model should take the acoustic sample as it is (i.e., the Mel spectrogram could have an arbitrary length) without the need to downsample the segment. You need to implement at least two of the aforementioned models. Do the neural models improve accuracy over the baseline model? Do you observe any signs of overfitting to the training data? How do the hyperparameters affect the model performance? Report and discuss your observations.        \n",
    "\n",
    "2. Evaluate your (best) neural models and compare to the baseline model using the same evalution process as in task I.4. \n",
    "\n",
    "3. Use a dimensionality reduction algorithm such as t-SNE \\[[1](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding),[2](https://pypi.org/project/tsne-torch/),[3](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)\\] or [UMAP](https://umap-learn.readthedocs.io/en/latest/basic_usage.html) to analyze how the different models seperate the different classes (the last non-linear layer in your model). Compare to the downsampled representation you used in the baseline and report your observations.\n",
    "\n",
    "4. Are the differences between the different models statistically significant? To answer this question, you need to implement a statistical significance test based on bootstrapping method. To read more how to estiame p-values based on bootstrapping, we recommend the materials on this paper https://aclanthology.org/D12-1091.pdf. Include the baseline model in your evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af2d25cb",
   "metadata": {
    "id": "af2d25cb"
   },
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "sdr_df = pd.read_csv('SDR_metadata.tsv', sep='\\t', header=0, index_col='Unnamed: 0')\n",
    "\n",
    "# Load data for each audio file, downsample and extract mel-spectrogram features\n",
    "def load_downsample_melspec(audio_file, sr=8000, num_mels=13, hop_length=80):\n",
    "    signal, _ = librosa.load(audio_file, sr=sr)\n",
    "    mel_features = extract_melspectrogram(signal,sr=8000, num_mels=13)\n",
    "    return mel_features\n",
    "\n",
    "\n",
    "max_length = 0\n",
    "for _, row in sdr_df.iterrows():\n",
    "    mel_spec = load_downsample_melspec(row['file'])\n",
    "    if mel_spec.shape[1] > max_length:\n",
    "        max_length = mel_spec.shape[1]\n",
    "\n",
    "# Load data and labels for all files in the metadata\n",
    "X = []\n",
    "y = []\n",
    "for _, row in sdr_df.iterrows():\n",
    "    mel_features = load_downsample_melspec(row['file'])\n",
    "    padded_mel_features = np.pad(mel_features, ((0, 0), (0, max_length - mel_features.shape[1])), mode='constant')\n",
    "    X.append(padded_mel_features)\n",
    "    y.append(row['label'])\n",
    "\n",
    "# Split data into train, dev, and test sets\n",
    "train_indices = sdr_df[sdr_df['split'] == 'TRAIN'].index\n",
    "dev_indices = sdr_df[sdr_df['split'] == 'DEV'].index\n",
    "test_indices = sdr_df[sdr_df['split'] == 'TEST'].index\n",
    "\n",
    "X_train = [X[i] for i in train_indices]\n",
    "y_train = [y[i] for i in train_indices]\n",
    "\n",
    "X_dev = [X[i] for i in dev_indices]\n",
    "y_dev = [y[i] for i in dev_indices]\n",
    "\n",
    "X_test = [X[i] for i in test_indices]\n",
    "y_test = [y[i] for i in test_indices]\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_dev = torch.tensor(X_dev, dtype=torch.float32)\n",
    "y_dev = torch.tensor(y_dev, dtype=torch.long)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96135609",
   "metadata": {
    "id": "96135609"
   },
   "outputs": [],
   "source": [
    "#function to load data for RNN and TCN\n",
    "def loader(X_train,y_train,X_dev,y_dev,X_test,y_test):\n",
    "    batch_size=32\n",
    "# Create data loader objects\n",
    "    train_data = TensorDataset(X_train, y_train)\n",
    "    dev_data = TensorDataset(X_dev, y_dev)\n",
    "    test_data = TensorDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    dev_loader = DataLoader(dev_data, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader,dev_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c71a039d",
   "metadata": {
    "id": "c71a039d"
   },
   "outputs": [],
   "source": [
    "train_loader,dev_loader,test_loader=loader(X_train,y_train,X_dev,y_dev,X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "360cabef",
   "metadata": {
    "id": "360cabef"
   },
   "outputs": [],
   "source": [
    "# Defining input size and output size\n",
    "input_size = X_train.shape[2]\n",
    "output_size = len(torch.unique(y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0927615",
   "metadata": {
    "id": "b0927615"
   },
   "source": [
    "TCN MODEL: Convolutional DNN with 1-D temporal convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44dec32f",
   "metadata": {
    "id": "44dec32f"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n",
    "        super(TCN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.num_channels = num_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.conv_layers = self.create_conv_layers()\n",
    "        self.fc_layer = nn.Linear(num_channels[-1], output_size)\n",
    "\n",
    "    def create_conv_layers(self):\n",
    "        layers = []\n",
    "        input_channels = self.input_size\n",
    "        for num_channels in self.num_channels:\n",
    "            layers += [weight_norm(nn.Conv1d(input_channels, num_channels, self.kernel_size, stride=1, dilation=1, padding=(self.kernel_size-1)//2))]\n",
    "            layers += [nn.BatchNorm1d(num_channels)]\n",
    "            layers += [nn.ReLU()]\n",
    "            layers += [nn.Dropout(p=self.dropout)]\n",
    "            input_channels = num_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x,use_lastlayer=False):\n",
    "        # input shape: (batch_size, input_size, sequence_length)\n",
    "        x = x.permute(0, 2, 1) # shape: (batch_size, sequence_length, input_size)\n",
    "        out = self.conv_layers(x)\n",
    "        out = out.max(dim=-1)[0] # global max pooling\n",
    "        out = self.fc_layer(out)\n",
    "        if use_lastlayer==True:\n",
    "            out = torch.softmax(out,dim=1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f47422",
   "metadata": {
    "id": "48f47422"
   },
   "source": [
    "RNN MODEL: Recurrent DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1acdc015",
   "metadata": {
    "id": "1acdc015"
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_rate):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x,use_lastlayer=False):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        if use_lastlayer==True:\n",
    "            out = torch.softmax(out,dim=1)\n",
    "            \n",
    "            \n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca6b42d3",
   "metadata": {
    "id": "ca6b42d3"
   },
   "outputs": [],
   "source": [
    "def train_model(model,train_loader,n_epochs,learning_rate):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(n_epochs):\n",
    "        # Train for one epoch\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "            train_acc += (output.argmax(1) == target).sum().item()\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc /= len(train_loader.dataset)\n",
    "\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {train_loss:.3f}Train Acc: {train_acc:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40f13ea4",
   "metadata": {
    "id": "40f13ea4"
   },
   "outputs": [],
   "source": [
    "def test(model,test_loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    tcn_test_preds = []\n",
    "    tcn_test_targets = []\n",
    "    tcn_test_loss = 0.0\n",
    "    tcn_test_acc = 0.0\n",
    "    max_tcn_test_acc=0.0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            tcn_test_output = model(data)\n",
    "            preds = tcn_test_output.argmax(1)\n",
    "            tcn_test_preds.extend(preds.cpu().numpy())\n",
    "            tcn_test_targets.extend(target.cpu().numpy())\n",
    "            tcn_test_loss = criterion(tcn_test_output, target)\n",
    "            tcn_test_loss += tcn_test_loss.item() * data.size(0)\n",
    "            tcn_test_acc += (tcn_test_output.argmax(1) == target).sum().item()\n",
    "             \n",
    "              \n",
    "    tcn_test_loss /= len(test_loader.dataset)\n",
    "    tcn_test_acc /= len(test_loader.dataset)\n",
    "    test_cm = confusion_matrix(tcn_test_targets,tcn_test_preds)\n",
    "    test_cr = classification_report(tcn_test_targets, tcn_test_preds)\n",
    "\n",
    "    if tcn_test_acc > max_tcn_test_acc:\n",
    "         max_tcn_test_acc = tcn_test_acc\n",
    "    print(f\"Test Loss: {tcn_test_loss:.3f}, Test Acc: {max_tcn_test_acc:.3f}\")\n",
    "    print(f\"Test confusion matrix:\\n{test_cm}\")\n",
    "    print(f\"Test classification report:\\n{test_cr}\")\n",
    "    return test_cr\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f174a795",
   "metadata": {
    "id": "f174a795"
   },
   "outputs": [],
   "source": [
    "def dev(model,dev_loader,flag=0):\n",
    "\n",
    "    \n",
    "#Evaluate on dev set\n",
    "        model.eval()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        tcn_dev_preds = []\n",
    "        tcn_dev_targets = []\n",
    "        tcn_dev_loss = 0.0\n",
    "        tcn_dev_acc = 0.0\n",
    "        max_tcn_dev_acc=0\n",
    "        with torch.no_grad():\n",
    "            for data, target in dev_loader:\n",
    "\n",
    "                output = model(data)\n",
    "                preds = output.argmax(1)\n",
    "                tcn_dev_preds.extend(preds.cpu().numpy())\n",
    "                tcn_dev_targets.extend(target.cpu().numpy())\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "                tcn_dev_loss += loss.item() * data.size(0)\n",
    "                tcn_dev_acc += (output.argmax(1) == target).sum().item()\n",
    "        tcn_dev_loss /= len(dev_loader.dataset)\n",
    "        tcn_dev_acc /= len(dev_loader.dataset)\n",
    "      \n",
    "        if flag==1:\n",
    "            dev_cm = confusion_matrix(tcn_dev_targets,tcn_dev_preds)\n",
    "            dev_cr = classification_report(tcn_dev_targets, tcn_dev_preds)\n",
    "            print(f\"Dev confusion matrix:\\n{dev_cm}\")\n",
    "            print(f\"Dev classification report:\\n{dev_cr}\")\n",
    "            return tcn_dev_acc\n",
    "        else:\n",
    "            return tcn_dev_acc\n",
    "            \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d1b859",
   "metadata": {
    "id": "03d1b859"
   },
   "source": [
    "RNN AND TCN: Training using best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd2271c2",
   "metadata": {
    "id": "fd2271c2"
   },
   "outputs": [],
   "source": [
    "def best_param1( train_loader, dev_loader, test_loader, \n",
    "                input_size, output_size, num_layers, dropout_rate, \n",
    "                hidden_size_range, learning_rate_range, num_epochs_range,model=None):\n",
    "  \n",
    "    # Use grid search or random search to try different combinations of hyperparameters\n",
    "    if (model!=None):\n",
    "        param_grid = itertools.product(hidden_size_range, learning_rate_range, num_epochs_range,num_layers,dropout_rate)\n",
    "    else:\n",
    "        param_grid = itertools.product(learning_rate_range, num_epochs_range,dropout_rate)\n",
    "        \n",
    "    param_grid = list(param_grid)\n",
    "    random.shuffle(param_grid)\n",
    "    model1=model\n",
    "    best_params = None\n",
    "    best_dev_acc = 0.0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for i, params in enumerate(param_grid):\n",
    "        # Unpack hyperparameters\n",
    "        if (model1!=None):\n",
    "            hidden_size, learning_rate, num_epochs, num_layers,dropout_rate = params\n",
    "        else:\n",
    "            learning_rate,num_epochs,dropout_rate=params\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "        # Create model and optimizer\n",
    "        if (model1==\"rnn\"):\n",
    "            model = RNNModel(input_size, hidden_size, num_layers, output_size, dropout_rate)\n",
    "        else:\n",
    "            model = TCN(input_size, output_size, num_channels=[64, 64, 64], kernel_size=3,dropout=dropout_rate)\n",
    "            \n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Train model and evaluate on validation set\n",
    "        train_model(model,train_loader,num_epochs,learning_rate)\n",
    "        dev_acc=dev(model,dev_loader,flag=0)\n",
    "        if dev_acc > best_dev_acc:\n",
    "            best_params = params\n",
    "            best_dev_acc = dev_acc\n",
    "\n",
    "        print(f\"Finished {i+1} of {len(param_grid)} parameter combinations\")\n",
    "        print(\"best parameters are\",best_params)\n",
    "        print(\"dev accuracy for the given set of parameters\", dev_acc)\n",
    "        \n",
    "       \n",
    "    # Train the final model using the best hyperparameters on the combined training and validation sets\n",
    "    if(model1!=None):\n",
    "        hidden_size, learning_rate, num_epochs,num_layers,dropout_rate = best_params\n",
    "    else:\n",
    "        learning_rate,num_epochs,dropout_rate=best_params\n",
    "    print(\"best dev accuracy\",best_dev_acc)\n",
    "        \n",
    "        \n",
    "    \n",
    "    if (model1==\"rnn\"):\n",
    "        model_rnn = RNNModel(input_size, hidden_size, num_layers, output_size, dropout_rate)\n",
    "        train_model(model_rnn,train_loader,num_epochs,learning_rate)\n",
    "        t=test(model_rnn,test_loader)\n",
    "        dev(model_rnn,dev_loader,flag=1)\n",
    "        \n",
    "    else:\n",
    "        model_TCN = TCN(input_size, output_size, num_channels=[64, 64, 64], kernel_size=3,dropout=dropout_rate)\n",
    "        train_model(model_TCN,train_loader,num_epochs,learning_rate)\n",
    "        t=test(model_TCN,test_loader)\n",
    "        dev(model_TCN,dev_loader,flag=1)\n",
    "\n",
    "    if(model1!=None):\n",
    "        return model_rnn\n",
    "    else:\n",
    "        return model_TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3488708",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3488708",
    "outputId": "80adcccc-715e-48b6-a439-aa48d4ca1cd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 1.713Train Acc: 0.423\n",
      "Epoch 2/10, Train Loss: 1.271Train Acc: 0.594\n",
      "Epoch 3/10, Train Loss: 1.085Train Acc: 0.661\n",
      "Epoch 4/10, Train Loss: 1.193Train Acc: 0.616\n",
      "Epoch 5/10, Train Loss: 1.131Train Acc: 0.633\n",
      "Epoch 6/10, Train Loss: 1.252Train Acc: 0.581\n",
      "Epoch 7/10, Train Loss: 1.099Train Acc: 0.644\n",
      "Epoch 8/10, Train Loss: 1.091Train Acc: 0.641\n",
      "Epoch 9/10, Train Loss: 1.088Train Acc: 0.645\n",
      "Epoch 10/10, Train Loss: 1.145Train Acc: 0.613\n",
      "Finished 1 of 144 parameter combinations\n",
      "best parameters are (50, 0.01, 10, 2, 0.5)\n",
      "dev accuracy for the given set of parameters 0.24346076458752516\n",
      "Epoch 1/10, Train Loss: 2.235Train Acc: 0.186\n",
      "Epoch 2/10, Train Loss: 1.887Train Acc: 0.321\n",
      "Epoch 3/10, Train Loss: 2.010Train Acc: 0.258\n",
      "Epoch 4/10, Train Loss: 1.938Train Acc: 0.282\n",
      "Epoch 5/10, Train Loss: 1.954Train Acc: 0.265\n",
      "Epoch 6/10, Train Loss: 1.861Train Acc: 0.315\n",
      "Epoch 7/10, Train Loss: 1.772Train Acc: 0.367\n",
      "Epoch 8/10, Train Loss: 1.766Train Acc: 0.364\n",
      "Epoch 9/10, Train Loss: 1.835Train Acc: 0.360\n",
      "Epoch 10/10, Train Loss: 2.117Train Acc: 0.245\n",
      "Finished 2 of 144 parameter combinations\n",
      "best parameters are (50, 0.01, 10, 2, 0.5)\n",
      "dev accuracy for the given set of parameters 0.13078470824949698\n",
      "Epoch 1/50, Train Loss: 2.112Train Acc: 0.225\n",
      "Epoch 2/50, Train Loss: 1.853Train Acc: 0.343\n",
      "Epoch 3/50, Train Loss: 1.698Train Acc: 0.429\n",
      "Epoch 4/50, Train Loss: 1.534Train Acc: 0.497\n",
      "Epoch 5/50, Train Loss: 1.403Train Acc: 0.559\n",
      "Epoch 6/50, Train Loss: 1.251Train Acc: 0.630\n",
      "Epoch 7/50, Train Loss: 1.114Train Acc: 0.667\n",
      "Epoch 8/50, Train Loss: 0.989Train Acc: 0.706\n",
      "Epoch 9/50, Train Loss: 0.887Train Acc: 0.741\n",
      "Epoch 10/50, Train Loss: 0.799Train Acc: 0.769\n",
      "Epoch 11/50, Train Loss: 0.730Train Acc: 0.792\n",
      "Epoch 12/50, Train Loss: 0.677Train Acc: 0.809\n",
      "Epoch 13/50, Train Loss: 0.620Train Acc: 0.826\n",
      "Epoch 14/50, Train Loss: 0.578Train Acc: 0.839\n",
      "Epoch 15/50, Train Loss: 0.536Train Acc: 0.847\n",
      "Epoch 16/50, Train Loss: 0.503Train Acc: 0.866\n",
      "Epoch 17/50, Train Loss: 0.466Train Acc: 0.877\n",
      "Epoch 18/50, Train Loss: 0.461Train Acc: 0.868\n",
      "Epoch 19/50, Train Loss: 0.416Train Acc: 0.887\n",
      "Epoch 20/50, Train Loss: 0.390Train Acc: 0.894\n",
      "Epoch 21/50, Train Loss: 0.381Train Acc: 0.890\n",
      "Epoch 22/50, Train Loss: 0.352Train Acc: 0.912\n",
      "Epoch 23/50, Train Loss: 0.334Train Acc: 0.908\n",
      "Epoch 24/50, Train Loss: 0.317Train Acc: 0.912\n",
      "Epoch 25/50, Train Loss: 0.297Train Acc: 0.926\n",
      "Epoch 26/50, Train Loss: 0.292Train Acc: 0.924\n",
      "Epoch 27/50, Train Loss: 0.288Train Acc: 0.925\n",
      "Epoch 28/50, Train Loss: 0.277Train Acc: 0.924\n",
      "Epoch 29/50, Train Loss: 0.272Train Acc: 0.929\n",
      "Epoch 30/50, Train Loss: 0.240Train Acc: 0.939\n",
      "Epoch 31/50, Train Loss: 0.235Train Acc: 0.936\n",
      "Epoch 32/50, Train Loss: 0.221Train Acc: 0.942\n",
      "Epoch 33/50, Train Loss: 0.211Train Acc: 0.948\n",
      "Epoch 34/50, Train Loss: 0.214Train Acc: 0.943\n",
      "Epoch 35/50, Train Loss: 0.204Train Acc: 0.946\n",
      "Epoch 36/50, Train Loss: 0.202Train Acc: 0.947\n",
      "Epoch 37/50, Train Loss: 0.197Train Acc: 0.951\n",
      "Epoch 38/50, Train Loss: 0.185Train Acc: 0.949\n",
      "Epoch 39/50, Train Loss: 0.171Train Acc: 0.957\n",
      "Epoch 40/50, Train Loss: 0.187Train Acc: 0.950\n",
      "Epoch 41/50, Train Loss: 0.164Train Acc: 0.958\n",
      "Epoch 42/50, Train Loss: 0.162Train Acc: 0.960\n",
      "Epoch 43/50, Train Loss: 0.153Train Acc: 0.963\n",
      "Epoch 44/50, Train Loss: 0.144Train Acc: 0.966\n",
      "Epoch 45/50, Train Loss: 0.148Train Acc: 0.962\n",
      "Epoch 46/50, Train Loss: 0.154Train Acc: 0.956\n",
      "Epoch 47/50, Train Loss: 0.140Train Acc: 0.965\n",
      "Epoch 48/50, Train Loss: 0.127Train Acc: 0.968\n",
      "Epoch 49/50, Train Loss: 0.135Train Acc: 0.960\n",
      "Epoch 50/50, Train Loss: 0.143Train Acc: 0.966\n",
      "Finished 3 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.40643863179074446\n",
      "Epoch 1/10, Train Loss: 2.314Train Acc: 0.099\n",
      "Epoch 2/10, Train Loss: 2.309Train Acc: 0.102\n",
      "Epoch 3/10, Train Loss: 2.314Train Acc: 0.097\n",
      "Epoch 4/10, Train Loss: 2.313Train Acc: 0.096\n",
      "Epoch 5/10, Train Loss: 2.313Train Acc: 0.103\n",
      "Epoch 6/10, Train Loss: 2.313Train Acc: 0.100\n",
      "Epoch 7/10, Train Loss: 2.310Train Acc: 0.107\n",
      "Epoch 8/10, Train Loss: 2.313Train Acc: 0.101\n",
      "Epoch 9/10, Train Loss: 2.314Train Acc: 0.087\n",
      "Epoch 10/10, Train Loss: 2.311Train Acc: 0.094\n",
      "Finished 4 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.09456740442655935\n",
      "Epoch 1/20, Train Loss: 2.315Train Acc: 0.092\n",
      "Epoch 2/20, Train Loss: 2.313Train Acc: 0.095\n",
      "Epoch 3/20, Train Loss: 2.308Train Acc: 0.099\n",
      "Epoch 4/20, Train Loss: 2.312Train Acc: 0.091\n",
      "Epoch 5/20, Train Loss: 2.311Train Acc: 0.087\n",
      "Epoch 6/20, Train Loss: 2.308Train Acc: 0.096\n",
      "Epoch 7/20, Train Loss: 2.309Train Acc: 0.090\n",
      "Epoch 8/20, Train Loss: 2.306Train Acc: 0.102\n",
      "Epoch 9/20, Train Loss: 2.306Train Acc: 0.094\n",
      "Epoch 10/20, Train Loss: 2.306Train Acc: 0.087\n",
      "Epoch 11/20, Train Loss: 2.307Train Acc: 0.101\n",
      "Epoch 12/20, Train Loss: 2.306Train Acc: 0.099\n",
      "Epoch 13/20, Train Loss: 2.307Train Acc: 0.097\n",
      "Epoch 14/20, Train Loss: 2.307Train Acc: 0.097\n",
      "Epoch 15/20, Train Loss: 2.306Train Acc: 0.097\n",
      "Epoch 16/20, Train Loss: 2.307Train Acc: 0.096\n",
      "Epoch 17/20, Train Loss: 2.306Train Acc: 0.096\n",
      "Epoch 18/20, Train Loss: 2.306Train Acc: 0.091\n",
      "Epoch 19/20, Train Loss: 2.305Train Acc: 0.102\n",
      "Epoch 20/20, Train Loss: 2.304Train Acc: 0.103\n",
      "Finished 5 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.1006036217303823\n",
      "Epoch 1/20, Train Loss: 1.788Train Acc: 0.365\n",
      "Epoch 2/20, Train Loss: 1.258Train Acc: 0.592\n",
      "Epoch 3/20, Train Loss: 1.145Train Acc: 0.632\n",
      "Epoch 4/20, Train Loss: 1.046Train Acc: 0.667\n",
      "Epoch 5/20, Train Loss: 0.998Train Acc: 0.678\n",
      "Epoch 6/20, Train Loss: 0.995Train Acc: 0.674\n",
      "Epoch 7/20, Train Loss: 1.051Train Acc: 0.653\n",
      "Epoch 8/20, Train Loss: 1.140Train Acc: 0.632\n",
      "Epoch 9/20, Train Loss: 1.056Train Acc: 0.661\n",
      "Epoch 10/20, Train Loss: 1.091Train Acc: 0.642\n",
      "Epoch 11/20, Train Loss: 1.047Train Acc: 0.660\n",
      "Epoch 12/20, Train Loss: 1.061Train Acc: 0.667\n",
      "Epoch 13/20, Train Loss: 1.111Train Acc: 0.639\n",
      "Epoch 14/20, Train Loss: 1.178Train Acc: 0.605\n",
      "Epoch 15/20, Train Loss: 1.215Train Acc: 0.609\n",
      "Epoch 16/20, Train Loss: 1.283Train Acc: 0.576\n",
      "Epoch 17/20, Train Loss: 1.466Train Acc: 0.519\n",
      "Epoch 18/20, Train Loss: 1.382Train Acc: 0.546\n",
      "Epoch 19/20, Train Loss: 1.304Train Acc: 0.560\n",
      "Epoch 20/20, Train Loss: 1.232Train Acc: 0.579\n",
      "Finished 6 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.2515090543259557\n",
      "Epoch 1/20, Train Loss: 2.049Train Acc: 0.241\n",
      "Epoch 2/20, Train Loss: 1.748Train Acc: 0.390\n",
      "Epoch 3/20, Train Loss: 1.606Train Acc: 0.458\n",
      "Epoch 4/20, Train Loss: 1.512Train Acc: 0.487\n",
      "Epoch 5/20, Train Loss: 1.384Train Acc: 0.545\n",
      "Epoch 6/20, Train Loss: 1.327Train Acc: 0.563\n",
      "Epoch 7/20, Train Loss: 1.244Train Acc: 0.596\n",
      "Epoch 8/20, Train Loss: 1.313Train Acc: 0.572\n",
      "Epoch 9/20, Train Loss: 1.312Train Acc: 0.572\n",
      "Epoch 10/20, Train Loss: 1.274Train Acc: 0.581\n",
      "Epoch 11/20, Train Loss: 1.222Train Acc: 0.602\n",
      "Epoch 12/20, Train Loss: 1.212Train Acc: 0.604\n",
      "Epoch 13/20, Train Loss: 1.269Train Acc: 0.583\n",
      "Epoch 14/20, Train Loss: 1.408Train Acc: 0.541\n",
      "Epoch 15/20, Train Loss: 1.286Train Acc: 0.568\n",
      "Epoch 16/20, Train Loss: 1.307Train Acc: 0.571\n",
      "Epoch 17/20, Train Loss: 1.334Train Acc: 0.570\n",
      "Epoch 18/20, Train Loss: 1.332Train Acc: 0.568\n",
      "Epoch 19/20, Train Loss: 1.288Train Acc: 0.570\n",
      "Epoch 20/20, Train Loss: 1.373Train Acc: 0.540\n",
      "Finished 7 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.19919517102615694\n",
      "Epoch 1/50, Train Loss: 2.103Train Acc: 0.227\n",
      "Epoch 2/50, Train Loss: 1.488Train Acc: 0.545\n",
      "Epoch 3/50, Train Loss: 1.189Train Acc: 0.637\n",
      "Epoch 4/50, Train Loss: 1.036Train Acc: 0.680\n",
      "Epoch 5/50, Train Loss: 0.901Train Acc: 0.716\n",
      "Epoch 6/50, Train Loss: 0.848Train Acc: 0.731\n",
      "Epoch 7/50, Train Loss: 0.770Train Acc: 0.754\n",
      "Epoch 8/50, Train Loss: 0.734Train Acc: 0.762\n",
      "Epoch 9/50, Train Loss: 0.676Train Acc: 0.790\n",
      "Epoch 10/50, Train Loss: 0.643Train Acc: 0.795\n",
      "Epoch 11/50, Train Loss: 0.619Train Acc: 0.794\n",
      "Epoch 12/50, Train Loss: 0.580Train Acc: 0.810\n",
      "Epoch 13/50, Train Loss: 0.509Train Acc: 0.830\n",
      "Epoch 14/50, Train Loss: 0.511Train Acc: 0.828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Train Loss: 0.476Train Acc: 0.846\n",
      "Epoch 16/50, Train Loss: 0.454Train Acc: 0.860\n",
      "Epoch 17/50, Train Loss: 0.457Train Acc: 0.857\n",
      "Epoch 18/50, Train Loss: 0.434Train Acc: 0.855\n",
      "Epoch 19/50, Train Loss: 0.424Train Acc: 0.858\n",
      "Epoch 20/50, Train Loss: 0.377Train Acc: 0.881\n",
      "Epoch 21/50, Train Loss: 0.365Train Acc: 0.885\n",
      "Epoch 22/50, Train Loss: 0.325Train Acc: 0.902\n",
      "Epoch 23/50, Train Loss: 0.361Train Acc: 0.879\n",
      "Epoch 24/50, Train Loss: 0.295Train Acc: 0.902\n",
      "Epoch 25/50, Train Loss: 0.322Train Acc: 0.895\n",
      "Epoch 26/50, Train Loss: 0.341Train Acc: 0.895\n",
      "Epoch 27/50, Train Loss: 0.311Train Acc: 0.903\n",
      "Epoch 28/50, Train Loss: 0.260Train Acc: 0.919\n",
      "Epoch 29/50, Train Loss: 0.274Train Acc: 0.913\n",
      "Epoch 30/50, Train Loss: 0.242Train Acc: 0.924\n",
      "Epoch 31/50, Train Loss: 0.260Train Acc: 0.917\n",
      "Epoch 32/50, Train Loss: 0.236Train Acc: 0.923\n",
      "Epoch 33/50, Train Loss: 0.248Train Acc: 0.922\n",
      "Epoch 34/50, Train Loss: 0.271Train Acc: 0.916\n",
      "Epoch 35/50, Train Loss: 0.215Train Acc: 0.929\n",
      "Epoch 36/50, Train Loss: 0.218Train Acc: 0.928\n",
      "Epoch 37/50, Train Loss: 0.239Train Acc: 0.923\n",
      "Epoch 38/50, Train Loss: 0.218Train Acc: 0.930\n",
      "Epoch 39/50, Train Loss: 0.206Train Acc: 0.936\n",
      "Epoch 40/50, Train Loss: 0.202Train Acc: 0.940\n",
      "Epoch 41/50, Train Loss: 0.162Train Acc: 0.946\n",
      "Epoch 42/50, Train Loss: 0.220Train Acc: 0.932\n",
      "Epoch 43/50, Train Loss: 0.170Train Acc: 0.946\n",
      "Epoch 44/50, Train Loss: 0.141Train Acc: 0.956\n",
      "Epoch 45/50, Train Loss: 0.158Train Acc: 0.950\n",
      "Epoch 46/50, Train Loss: 0.222Train Acc: 0.931\n",
      "Epoch 47/50, Train Loss: 0.220Train Acc: 0.923\n",
      "Epoch 48/50, Train Loss: 0.161Train Acc: 0.953\n",
      "Epoch 49/50, Train Loss: 0.157Train Acc: 0.948\n",
      "Epoch 50/50, Train Loss: 0.185Train Acc: 0.935\n",
      "Finished 8 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.39235412474849096\n",
      "Epoch 1/20, Train Loss: 2.306Train Acc: 0.114\n",
      "Epoch 2/20, Train Loss: 2.159Train Acc: 0.214\n",
      "Epoch 3/20, Train Loss: 1.918Train Acc: 0.324\n",
      "Epoch 4/20, Train Loss: 1.715Train Acc: 0.408\n",
      "Epoch 5/20, Train Loss: 1.569Train Acc: 0.472\n",
      "Epoch 6/20, Train Loss: 1.449Train Acc: 0.526\n",
      "Epoch 7/20, Train Loss: 1.325Train Acc: 0.571\n",
      "Epoch 8/20, Train Loss: 1.275Train Acc: 0.586\n",
      "Epoch 9/20, Train Loss: 1.232Train Acc: 0.597\n",
      "Epoch 10/20, Train Loss: 1.153Train Acc: 0.616\n",
      "Epoch 11/20, Train Loss: 1.089Train Acc: 0.635\n",
      "Epoch 12/20, Train Loss: 1.094Train Acc: 0.644\n",
      "Epoch 13/20, Train Loss: 1.075Train Acc: 0.647\n",
      "Epoch 14/20, Train Loss: 1.047Train Acc: 0.650\n",
      "Epoch 15/20, Train Loss: 0.974Train Acc: 0.691\n",
      "Epoch 16/20, Train Loss: 0.974Train Acc: 0.684\n",
      "Epoch 17/20, Train Loss: 0.933Train Acc: 0.697\n",
      "Epoch 18/20, Train Loss: 0.909Train Acc: 0.714\n",
      "Epoch 19/20, Train Loss: 0.922Train Acc: 0.710\n",
      "Epoch 20/20, Train Loss: 0.896Train Acc: 0.710\n",
      "Finished 9 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.3118712273641851\n",
      "Epoch 1/20, Train Loss: 2.357Train Acc: 0.099\n",
      "Epoch 2/20, Train Loss: 2.343Train Acc: 0.108\n",
      "Epoch 3/20, Train Loss: 2.339Train Acc: 0.103\n",
      "Epoch 4/20, Train Loss: 2.341Train Acc: 0.090\n",
      "Epoch 5/20, Train Loss: 2.337Train Acc: 0.093\n",
      "Epoch 6/20, Train Loss: 2.348Train Acc: 0.102\n",
      "Epoch 7/20, Train Loss: 2.332Train Acc: 0.107\n",
      "Epoch 8/20, Train Loss: 2.339Train Acc: 0.089\n",
      "Epoch 9/20, Train Loss: 2.338Train Acc: 0.102\n",
      "Epoch 10/20, Train Loss: 2.341Train Acc: 0.100\n",
      "Epoch 11/20, Train Loss: 2.346Train Acc: 0.093\n",
      "Epoch 12/20, Train Loss: 2.351Train Acc: 0.100\n",
      "Epoch 13/20, Train Loss: 2.342Train Acc: 0.098\n",
      "Epoch 14/20, Train Loss: 2.339Train Acc: 0.092\n",
      "Epoch 15/20, Train Loss: 2.343Train Acc: 0.104\n",
      "Epoch 16/20, Train Loss: 2.337Train Acc: 0.097\n",
      "Epoch 17/20, Train Loss: 2.339Train Acc: 0.106\n",
      "Epoch 18/20, Train Loss: 2.342Train Acc: 0.086\n",
      "Epoch 19/20, Train Loss: 2.333Train Acc: 0.103\n",
      "Epoch 20/20, Train Loss: 2.351Train Acc: 0.097\n",
      "Finished 10 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.09054325955734406\n",
      "Epoch 1/10, Train Loss: 1.780Train Acc: 0.379\n",
      "Epoch 2/10, Train Loss: 1.256Train Acc: 0.586\n",
      "Epoch 3/10, Train Loss: 1.122Train Acc: 0.629\n",
      "Epoch 4/10, Train Loss: 1.044Train Acc: 0.637\n",
      "Epoch 5/10, Train Loss: 1.000Train Acc: 0.685\n",
      "Epoch 6/10, Train Loss: 0.992Train Acc: 0.686\n",
      "Epoch 7/10, Train Loss: 1.025Train Acc: 0.665\n",
      "Epoch 8/10, Train Loss: 1.233Train Acc: 0.610\n",
      "Epoch 9/10, Train Loss: 1.110Train Acc: 0.649\n",
      "Epoch 10/10, Train Loss: 1.258Train Acc: 0.591\n",
      "Finished 11 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.2977867203219316\n",
      "Epoch 1/20, Train Loss: 1.674Train Acc: 0.419\n",
      "Epoch 2/20, Train Loss: 1.138Train Acc: 0.634\n",
      "Epoch 3/20, Train Loss: 0.944Train Acc: 0.704\n",
      "Epoch 4/20, Train Loss: 0.980Train Acc: 0.691\n",
      "Epoch 5/20, Train Loss: 0.843Train Acc: 0.726\n",
      "Epoch 6/20, Train Loss: 0.855Train Acc: 0.737\n",
      "Epoch 7/20, Train Loss: 0.833Train Acc: 0.737\n",
      "Epoch 8/20, Train Loss: 0.871Train Acc: 0.724\n",
      "Epoch 9/20, Train Loss: 0.819Train Acc: 0.737\n",
      "Epoch 10/20, Train Loss: 0.844Train Acc: 0.735\n",
      "Epoch 11/20, Train Loss: 0.807Train Acc: 0.751\n",
      "Epoch 12/20, Train Loss: 0.807Train Acc: 0.744\n",
      "Epoch 13/20, Train Loss: 1.124Train Acc: 0.666\n",
      "Epoch 14/20, Train Loss: 1.107Train Acc: 0.628\n",
      "Epoch 15/20, Train Loss: 0.917Train Acc: 0.721\n",
      "Epoch 16/20, Train Loss: 0.983Train Acc: 0.678\n",
      "Epoch 17/20, Train Loss: 1.010Train Acc: 0.682\n",
      "Epoch 18/20, Train Loss: 0.998Train Acc: 0.669\n",
      "Epoch 19/20, Train Loss: 0.914Train Acc: 0.700\n",
      "Epoch 20/20, Train Loss: 1.013Train Acc: 0.684\n",
      "Finished 12 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.3038229376257545\n",
      "Epoch 1/10, Train Loss: 2.363Train Acc: 0.104\n",
      "Epoch 2/10, Train Loss: 2.374Train Acc: 0.104\n",
      "Epoch 3/10, Train Loss: 2.372Train Acc: 0.105\n",
      "Epoch 4/10, Train Loss: 2.367Train Acc: 0.103\n",
      "Epoch 5/10, Train Loss: 2.358Train Acc: 0.088\n",
      "Epoch 6/10, Train Loss: 2.356Train Acc: 0.098\n",
      "Epoch 7/10, Train Loss: 2.344Train Acc: 0.090\n",
      "Epoch 8/10, Train Loss: 2.352Train Acc: 0.096\n",
      "Epoch 9/10, Train Loss: 2.353Train Acc: 0.108\n",
      "Epoch 10/10, Train Loss: 2.380Train Acc: 0.102\n",
      "Finished 13 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.10865191146881288\n",
      "Epoch 1/50, Train Loss: 2.319Train Acc: 0.100\n",
      "Epoch 2/50, Train Loss: 2.306Train Acc: 0.106\n",
      "Epoch 3/50, Train Loss: 2.171Train Acc: 0.193\n",
      "Epoch 4/50, Train Loss: 2.046Train Acc: 0.242\n",
      "Epoch 5/50, Train Loss: 1.896Train Acc: 0.315\n",
      "Epoch 6/50, Train Loss: 1.729Train Acc: 0.406\n",
      "Epoch 7/50, Train Loss: 1.603Train Acc: 0.472\n",
      "Epoch 8/50, Train Loss: 1.479Train Acc: 0.523\n",
      "Epoch 9/50, Train Loss: 1.413Train Acc: 0.519\n",
      "Epoch 10/50, Train Loss: 1.325Train Acc: 0.559\n",
      "Epoch 11/50, Train Loss: 1.330Train Acc: 0.564\n",
      "Epoch 12/50, Train Loss: 1.286Train Acc: 0.566\n",
      "Epoch 13/50, Train Loss: 1.254Train Acc: 0.578\n",
      "Epoch 14/50, Train Loss: 1.215Train Acc: 0.598\n",
      "Epoch 15/50, Train Loss: 1.175Train Acc: 0.604\n",
      "Epoch 16/50, Train Loss: 1.152Train Acc: 0.612\n",
      "Epoch 17/50, Train Loss: 1.129Train Acc: 0.628\n",
      "Epoch 18/50, Train Loss: 1.124Train Acc: 0.621\n",
      "Epoch 19/50, Train Loss: 1.101Train Acc: 0.639\n",
      "Epoch 20/50, Train Loss: 1.082Train Acc: 0.639\n",
      "Epoch 21/50, Train Loss: 1.080Train Acc: 0.627\n",
      "Epoch 22/50, Train Loss: 1.079Train Acc: 0.638\n",
      "Epoch 23/50, Train Loss: 1.031Train Acc: 0.652\n",
      "Epoch 24/50, Train Loss: 0.999Train Acc: 0.667\n",
      "Epoch 25/50, Train Loss: 0.974Train Acc: 0.686\n",
      "Epoch 26/50, Train Loss: 0.972Train Acc: 0.681\n",
      "Epoch 27/50, Train Loss: 0.978Train Acc: 0.669\n",
      "Epoch 28/50, Train Loss: 0.997Train Acc: 0.662\n",
      "Epoch 29/50, Train Loss: 0.950Train Acc: 0.692\n",
      "Epoch 30/50, Train Loss: 0.933Train Acc: 0.687\n",
      "Epoch 31/50, Train Loss: 0.947Train Acc: 0.686\n",
      "Epoch 32/50, Train Loss: 0.917Train Acc: 0.700\n",
      "Epoch 33/50, Train Loss: 0.917Train Acc: 0.698\n",
      "Epoch 34/50, Train Loss: 0.908Train Acc: 0.695\n",
      "Epoch 35/50, Train Loss: 0.892Train Acc: 0.707\n",
      "Epoch 36/50, Train Loss: 0.876Train Acc: 0.712\n",
      "Epoch 37/50, Train Loss: 0.880Train Acc: 0.708\n",
      "Epoch 38/50, Train Loss: 0.854Train Acc: 0.724\n",
      "Epoch 39/50, Train Loss: 0.865Train Acc: 0.719\n",
      "Epoch 40/50, Train Loss: 0.876Train Acc: 0.719\n",
      "Epoch 41/50, Train Loss: 0.886Train Acc: 0.714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Train Loss: 0.836Train Acc: 0.734\n",
      "Epoch 43/50, Train Loss: 0.865Train Acc: 0.715\n",
      "Epoch 44/50, Train Loss: 0.836Train Acc: 0.726\n",
      "Epoch 45/50, Train Loss: 0.821Train Acc: 0.733\n",
      "Epoch 46/50, Train Loss: 0.810Train Acc: 0.749\n",
      "Epoch 47/50, Train Loss: 0.798Train Acc: 0.739\n",
      "Epoch 48/50, Train Loss: 0.794Train Acc: 0.750\n",
      "Epoch 49/50, Train Loss: 0.831Train Acc: 0.733\n",
      "Epoch 50/50, Train Loss: 0.816Train Acc: 0.736\n",
      "Finished 14 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.3299798792756539\n",
      "Epoch 1/20, Train Loss: 2.331Train Acc: 0.105\n",
      "Epoch 2/20, Train Loss: 2.325Train Acc: 0.104\n",
      "Epoch 3/20, Train Loss: 2.255Train Acc: 0.156\n",
      "Epoch 4/20, Train Loss: 2.248Train Acc: 0.156\n",
      "Epoch 5/20, Train Loss: 2.220Train Acc: 0.166\n",
      "Epoch 6/20, Train Loss: 2.227Train Acc: 0.163\n",
      "Epoch 7/20, Train Loss: 2.208Train Acc: 0.169\n",
      "Epoch 8/20, Train Loss: 2.226Train Acc: 0.152\n",
      "Epoch 9/20, Train Loss: 2.143Train Acc: 0.203\n",
      "Epoch 10/20, Train Loss: 2.092Train Acc: 0.239\n",
      "Epoch 11/20, Train Loss: 2.137Train Acc: 0.210\n",
      "Epoch 12/20, Train Loss: 2.093Train Acc: 0.232\n",
      "Epoch 13/20, Train Loss: 2.089Train Acc: 0.233\n",
      "Epoch 14/20, Train Loss: 2.353Train Acc: 0.122\n",
      "Epoch 15/20, Train Loss: 2.337Train Acc: 0.106\n",
      "Epoch 16/20, Train Loss: 2.331Train Acc: 0.088\n",
      "Epoch 17/20, Train Loss: 2.318Train Acc: 0.113\n",
      "Epoch 18/20, Train Loss: 2.339Train Acc: 0.112\n",
      "Epoch 19/20, Train Loss: 2.329Train Acc: 0.101\n",
      "Epoch 20/20, Train Loss: 2.326Train Acc: 0.096\n",
      "Finished 15 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.11066398390342053\n",
      "Epoch 1/50, Train Loss: 2.386Train Acc: 0.105\n",
      "Epoch 2/50, Train Loss: 2.386Train Acc: 0.086\n",
      "Epoch 3/50, Train Loss: 2.397Train Acc: 0.091\n",
      "Epoch 4/50, Train Loss: 2.390Train Acc: 0.101\n",
      "Epoch 5/50, Train Loss: 2.361Train Acc: 0.108\n",
      "Epoch 6/50, Train Loss: 2.398Train Acc: 0.098\n",
      "Epoch 7/50, Train Loss: 2.376Train Acc: 0.088\n",
      "Epoch 8/50, Train Loss: 2.370Train Acc: 0.091\n",
      "Epoch 9/50, Train Loss: 2.379Train Acc: 0.097\n",
      "Epoch 10/50, Train Loss: 2.396Train Acc: 0.101\n",
      "Epoch 11/50, Train Loss: 2.386Train Acc: 0.102\n",
      "Epoch 12/50, Train Loss: 2.365Train Acc: 0.109\n",
      "Epoch 13/50, Train Loss: 2.366Train Acc: 0.096\n",
      "Epoch 14/50, Train Loss: 2.379Train Acc: 0.102\n",
      "Epoch 15/50, Train Loss: 2.373Train Acc: 0.094\n",
      "Epoch 16/50, Train Loss: 2.388Train Acc: 0.096\n",
      "Epoch 17/50, Train Loss: 2.385Train Acc: 0.093\n",
      "Epoch 18/50, Train Loss: 2.374Train Acc: 0.093\n",
      "Epoch 19/50, Train Loss: 2.398Train Acc: 0.104\n",
      "Epoch 20/50, Train Loss: 2.390Train Acc: 0.097\n",
      "Epoch 21/50, Train Loss: 2.381Train Acc: 0.087\n",
      "Epoch 22/50, Train Loss: 2.373Train Acc: 0.102\n",
      "Epoch 23/50, Train Loss: 2.381Train Acc: 0.108\n",
      "Epoch 24/50, Train Loss: 2.360Train Acc: 0.111\n",
      "Epoch 25/50, Train Loss: 2.393Train Acc: 0.095\n",
      "Epoch 26/50, Train Loss: 2.374Train Acc: 0.095\n",
      "Epoch 27/50, Train Loss: 2.385Train Acc: 0.107\n",
      "Epoch 28/50, Train Loss: 2.394Train Acc: 0.101\n",
      "Epoch 29/50, Train Loss: 2.373Train Acc: 0.102\n",
      "Epoch 30/50, Train Loss: 2.363Train Acc: 0.090\n",
      "Epoch 31/50, Train Loss: 2.371Train Acc: 0.102\n",
      "Epoch 32/50, Train Loss: 2.379Train Acc: 0.087\n",
      "Epoch 33/50, Train Loss: 2.395Train Acc: 0.091\n",
      "Epoch 34/50, Train Loss: 2.367Train Acc: 0.095\n",
      "Epoch 35/50, Train Loss: 2.377Train Acc: 0.100\n",
      "Epoch 36/50, Train Loss: 2.391Train Acc: 0.102\n",
      "Epoch 37/50, Train Loss: 2.368Train Acc: 0.102\n",
      "Epoch 38/50, Train Loss: 2.372Train Acc: 0.101\n",
      "Epoch 39/50, Train Loss: 2.391Train Acc: 0.097\n",
      "Epoch 40/50, Train Loss: 2.368Train Acc: 0.092\n",
      "Epoch 41/50, Train Loss: 2.388Train Acc: 0.104\n",
      "Epoch 42/50, Train Loss: 2.400Train Acc: 0.101\n",
      "Epoch 43/50, Train Loss: 2.390Train Acc: 0.107\n",
      "Epoch 44/50, Train Loss: 2.419Train Acc: 0.098\n",
      "Epoch 45/50, Train Loss: 2.378Train Acc: 0.100\n",
      "Epoch 46/50, Train Loss: 2.391Train Acc: 0.102\n",
      "Epoch 47/50, Train Loss: 2.381Train Acc: 0.090\n",
      "Epoch 48/50, Train Loss: 2.365Train Acc: 0.086\n",
      "Epoch 49/50, Train Loss: 2.363Train Acc: 0.105\n",
      "Epoch 50/50, Train Loss: 2.404Train Acc: 0.107\n",
      "Finished 16 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.10865191146881288\n",
      "Epoch 1/10, Train Loss: 2.112Train Acc: 0.213\n",
      "Epoch 2/10, Train Loss: 2.112Train Acc: 0.225\n",
      "Epoch 3/10, Train Loss: 1.924Train Acc: 0.280\n",
      "Epoch 4/10, Train Loss: 1.842Train Acc: 0.338\n",
      "Epoch 5/10, Train Loss: 1.918Train Acc: 0.333\n",
      "Epoch 6/10, Train Loss: 2.049Train Acc: 0.266\n",
      "Epoch 7/10, Train Loss: 1.857Train Acc: 0.325\n",
      "Epoch 8/10, Train Loss: 1.805Train Acc: 0.344\n",
      "Epoch 9/10, Train Loss: 1.783Train Acc: 0.344\n",
      "Epoch 10/10, Train Loss: 1.824Train Acc: 0.331\n",
      "Finished 17 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.15694164989939638\n",
      "Epoch 1/20, Train Loss: 2.206Train Acc: 0.161\n",
      "Epoch 2/20, Train Loss: 2.097Train Acc: 0.241\n",
      "Epoch 3/20, Train Loss: 2.033Train Acc: 0.259\n",
      "Epoch 4/20, Train Loss: 2.205Train Acc: 0.177\n",
      "Epoch 5/20, Train Loss: 2.146Train Acc: 0.180\n",
      "Epoch 6/20, Train Loss: 2.158Train Acc: 0.184\n",
      "Epoch 7/20, Train Loss: 2.132Train Acc: 0.213\n",
      "Epoch 8/20, Train Loss: 2.041Train Acc: 0.261\n",
      "Epoch 9/20, Train Loss: 2.051Train Acc: 0.261\n",
      "Epoch 10/20, Train Loss: 2.003Train Acc: 0.271\n",
      "Epoch 11/20, Train Loss: 1.957Train Acc: 0.285\n",
      "Epoch 12/20, Train Loss: 1.997Train Acc: 0.272\n",
      "Epoch 13/20, Train Loss: 1.925Train Acc: 0.297\n",
      "Epoch 14/20, Train Loss: 1.852Train Acc: 0.338\n",
      "Epoch 15/20, Train Loss: 1.829Train Acc: 0.325\n",
      "Epoch 16/20, Train Loss: 1.808Train Acc: 0.346\n",
      "Epoch 17/20, Train Loss: 1.812Train Acc: 0.357\n",
      "Epoch 18/20, Train Loss: 1.744Train Acc: 0.364\n",
      "Epoch 19/20, Train Loss: 1.721Train Acc: 0.363\n",
      "Epoch 20/20, Train Loss: 1.750Train Acc: 0.344\n",
      "Finished 18 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.16901408450704225\n",
      "Epoch 1/10, Train Loss: 1.695Train Acc: 0.428\n",
      "Epoch 2/10, Train Loss: 1.127Train Acc: 0.650\n",
      "Epoch 3/10, Train Loss: 0.956Train Acc: 0.690\n",
      "Epoch 4/10, Train Loss: 0.853Train Acc: 0.723\n",
      "Epoch 5/10, Train Loss: 0.931Train Acc: 0.705\n",
      "Epoch 6/10, Train Loss: 0.993Train Acc: 0.680\n",
      "Epoch 7/10, Train Loss: 1.114Train Acc: 0.646\n",
      "Epoch 8/10, Train Loss: 1.052Train Acc: 0.670\n",
      "Epoch 9/10, Train Loss: 1.074Train Acc: 0.651\n",
      "Epoch 10/10, Train Loss: 1.128Train Acc: 0.643\n",
      "Finished 19 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.2414486921529175\n",
      "Epoch 1/50, Train Loss: 1.842Train Acc: 0.360\n",
      "Epoch 2/50, Train Loss: 1.332Train Acc: 0.560\n",
      "Epoch 3/50, Train Loss: 1.138Train Acc: 0.633\n",
      "Epoch 4/50, Train Loss: 0.997Train Acc: 0.677\n",
      "Epoch 5/50, Train Loss: 0.931Train Acc: 0.716\n",
      "Epoch 6/50, Train Loss: 0.937Train Acc: 0.696\n",
      "Epoch 7/50, Train Loss: 1.026Train Acc: 0.669\n",
      "Epoch 8/50, Train Loss: 0.833Train Acc: 0.738\n",
      "Epoch 9/50, Train Loss: 0.838Train Acc: 0.731\n",
      "Epoch 10/50, Train Loss: 0.916Train Acc: 0.706\n",
      "Epoch 11/50, Train Loss: 0.855Train Acc: 0.724\n",
      "Epoch 12/50, Train Loss: 0.951Train Acc: 0.700\n",
      "Epoch 13/50, Train Loss: 0.925Train Acc: 0.703\n",
      "Epoch 14/50, Train Loss: 0.920Train Acc: 0.709\n",
      "Epoch 15/50, Train Loss: 0.991Train Acc: 0.686\n",
      "Epoch 16/50, Train Loss: 1.012Train Acc: 0.671\n",
      "Epoch 17/50, Train Loss: 0.986Train Acc: 0.679\n",
      "Epoch 18/50, Train Loss: 1.146Train Acc: 0.638\n",
      "Epoch 19/50, Train Loss: 1.033Train Acc: 0.649\n",
      "Epoch 20/50, Train Loss: 0.982Train Acc: 0.674\n",
      "Epoch 21/50, Train Loss: 1.014Train Acc: 0.671\n",
      "Epoch 22/50, Train Loss: 1.155Train Acc: 0.614\n",
      "Epoch 23/50, Train Loss: 1.175Train Acc: 0.624\n",
      "Epoch 24/50, Train Loss: 1.198Train Acc: 0.609\n",
      "Epoch 25/50, Train Loss: 1.029Train Acc: 0.675\n",
      "Epoch 26/50, Train Loss: 1.071Train Acc: 0.642\n",
      "Epoch 27/50, Train Loss: 1.203Train Acc: 0.612\n",
      "Epoch 28/50, Train Loss: 1.219Train Acc: 0.598\n",
      "Epoch 29/50, Train Loss: 1.148Train Acc: 0.629\n",
      "Epoch 30/50, Train Loss: 1.072Train Acc: 0.659\n",
      "Epoch 31/50, Train Loss: 1.131Train Acc: 0.632\n",
      "Epoch 32/50, Train Loss: 1.111Train Acc: 0.651\n",
      "Epoch 33/50, Train Loss: 1.043Train Acc: 0.670\n",
      "Epoch 34/50, Train Loss: 1.213Train Acc: 0.609\n",
      "Epoch 35/50, Train Loss: 1.147Train Acc: 0.633\n",
      "Epoch 36/50, Train Loss: 1.190Train Acc: 0.612\n",
      "Epoch 37/50, Train Loss: 1.367Train Acc: 0.541\n",
      "Epoch 38/50, Train Loss: 1.360Train Acc: 0.527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Train Loss: 1.326Train Acc: 0.541\n",
      "Epoch 40/50, Train Loss: 1.347Train Acc: 0.522\n",
      "Epoch 41/50, Train Loss: 1.312Train Acc: 0.563\n",
      "Epoch 42/50, Train Loss: 1.314Train Acc: 0.572\n",
      "Epoch 43/50, Train Loss: 1.315Train Acc: 0.561\n",
      "Epoch 44/50, Train Loss: 1.313Train Acc: 0.578\n",
      "Epoch 45/50, Train Loss: 1.312Train Acc: 0.577\n",
      "Epoch 46/50, Train Loss: 1.509Train Acc: 0.472\n",
      "Epoch 47/50, Train Loss: 1.543Train Acc: 0.452\n",
      "Epoch 48/50, Train Loss: 1.514Train Acc: 0.474\n",
      "Epoch 49/50, Train Loss: 1.522Train Acc: 0.480\n",
      "Epoch 50/50, Train Loss: 1.477Train Acc: 0.509\n",
      "Finished 20 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.158953722334004\n",
      "Epoch 1/20, Train Loss: 2.374Train Acc: 0.103\n",
      "Epoch 2/20, Train Loss: 2.358Train Acc: 0.096\n",
      "Epoch 3/20, Train Loss: 2.356Train Acc: 0.088\n",
      "Epoch 4/20, Train Loss: 2.357Train Acc: 0.092\n",
      "Epoch 5/20, Train Loss: 2.362Train Acc: 0.097\n",
      "Epoch 6/20, Train Loss: 2.354Train Acc: 0.112\n",
      "Epoch 7/20, Train Loss: 2.379Train Acc: 0.114\n",
      "Epoch 8/20, Train Loss: 2.384Train Acc: 0.095\n",
      "Epoch 9/20, Train Loss: 2.359Train Acc: 0.106\n",
      "Epoch 10/20, Train Loss: 2.364Train Acc: 0.101\n",
      "Epoch 11/20, Train Loss: 2.362Train Acc: 0.098\n",
      "Epoch 12/20, Train Loss: 2.362Train Acc: 0.110\n",
      "Epoch 13/20, Train Loss: 2.370Train Acc: 0.096\n",
      "Epoch 14/20, Train Loss: 2.369Train Acc: 0.097\n",
      "Epoch 15/20, Train Loss: 2.368Train Acc: 0.095\n",
      "Epoch 16/20, Train Loss: 2.358Train Acc: 0.104\n",
      "Epoch 17/20, Train Loss: 2.359Train Acc: 0.110\n",
      "Epoch 18/20, Train Loss: 2.362Train Acc: 0.107\n",
      "Epoch 19/20, Train Loss: 2.360Train Acc: 0.095\n",
      "Epoch 20/20, Train Loss: 2.369Train Acc: 0.093\n",
      "Finished 21 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.1006036217303823\n",
      "Epoch 1/10, Train Loss: 1.937Train Acc: 0.332\n",
      "Epoch 2/10, Train Loss: 1.405Train Acc: 0.561\n",
      "Epoch 3/10, Train Loss: 1.065Train Acc: 0.699\n",
      "Epoch 4/10, Train Loss: 0.838Train Acc: 0.767\n",
      "Epoch 5/10, Train Loss: 0.651Train Acc: 0.823\n",
      "Epoch 6/10, Train Loss: 0.561Train Acc: 0.847\n",
      "Epoch 7/10, Train Loss: 0.475Train Acc: 0.871\n",
      "Epoch 8/10, Train Loss: 0.402Train Acc: 0.890\n",
      "Epoch 9/10, Train Loss: 0.384Train Acc: 0.880\n",
      "Epoch 10/10, Train Loss: 0.325Train Acc: 0.908\n",
      "Finished 22 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.38028169014084506\n",
      "Epoch 1/50, Train Loss: 2.322Train Acc: 0.103\n",
      "Epoch 2/50, Train Loss: 2.327Train Acc: 0.107\n",
      "Epoch 3/50, Train Loss: 2.319Train Acc: 0.101\n",
      "Epoch 4/50, Train Loss: 2.322Train Acc: 0.085\n",
      "Epoch 5/50, Train Loss: 2.312Train Acc: 0.106\n",
      "Epoch 6/50, Train Loss: 2.321Train Acc: 0.093\n",
      "Epoch 7/50, Train Loss: 2.318Train Acc: 0.088\n",
      "Epoch 8/50, Train Loss: 2.316Train Acc: 0.099\n",
      "Epoch 9/50, Train Loss: 2.315Train Acc: 0.102\n",
      "Epoch 10/50, Train Loss: 2.314Train Acc: 0.099\n",
      "Epoch 11/50, Train Loss: 2.317Train Acc: 0.110\n",
      "Epoch 12/50, Train Loss: 2.322Train Acc: 0.092\n",
      "Epoch 13/50, Train Loss: 2.321Train Acc: 0.095\n",
      "Epoch 14/50, Train Loss: 2.324Train Acc: 0.101\n",
      "Epoch 15/50, Train Loss: 2.323Train Acc: 0.079\n",
      "Epoch 16/50, Train Loss: 2.317Train Acc: 0.098\n",
      "Epoch 17/50, Train Loss: 2.316Train Acc: 0.105\n",
      "Epoch 18/50, Train Loss: 2.324Train Acc: 0.096\n",
      "Epoch 19/50, Train Loss: 2.325Train Acc: 0.102\n",
      "Epoch 20/50, Train Loss: 2.321Train Acc: 0.097\n",
      "Epoch 21/50, Train Loss: 2.325Train Acc: 0.104\n",
      "Epoch 22/50, Train Loss: 2.326Train Acc: 0.095\n",
      "Epoch 23/50, Train Loss: 2.331Train Acc: 0.097\n",
      "Epoch 24/50, Train Loss: 2.320Train Acc: 0.115\n",
      "Epoch 25/50, Train Loss: 2.330Train Acc: 0.094\n",
      "Epoch 26/50, Train Loss: 2.328Train Acc: 0.092\n",
      "Epoch 27/50, Train Loss: 2.327Train Acc: 0.092\n",
      "Epoch 28/50, Train Loss: 2.331Train Acc: 0.102\n",
      "Epoch 29/50, Train Loss: 2.338Train Acc: 0.101\n",
      "Epoch 30/50, Train Loss: 2.333Train Acc: 0.086\n",
      "Epoch 31/50, Train Loss: 2.336Train Acc: 0.096\n",
      "Epoch 32/50, Train Loss: 2.330Train Acc: 0.098\n",
      "Epoch 33/50, Train Loss: 2.328Train Acc: 0.095\n",
      "Epoch 34/50, Train Loss: 2.329Train Acc: 0.091\n",
      "Epoch 35/50, Train Loss: 2.342Train Acc: 0.100\n",
      "Epoch 36/50, Train Loss: 2.332Train Acc: 0.101\n",
      "Epoch 37/50, Train Loss: 2.334Train Acc: 0.089\n",
      "Epoch 38/50, Train Loss: 2.322Train Acc: 0.108\n",
      "Epoch 39/50, Train Loss: 2.335Train Acc: 0.098\n",
      "Epoch 40/50, Train Loss: 2.319Train Acc: 0.102\n",
      "Epoch 41/50, Train Loss: 2.327Train Acc: 0.101\n",
      "Epoch 42/50, Train Loss: 2.325Train Acc: 0.099\n",
      "Epoch 43/50, Train Loss: 2.330Train Acc: 0.101\n",
      "Epoch 44/50, Train Loss: 2.321Train Acc: 0.097\n",
      "Epoch 45/50, Train Loss: 2.327Train Acc: 0.092\n",
      "Epoch 46/50, Train Loss: 2.328Train Acc: 0.102\n",
      "Epoch 47/50, Train Loss: 2.323Train Acc: 0.108\n",
      "Epoch 48/50, Train Loss: 2.333Train Acc: 0.086\n",
      "Epoch 49/50, Train Loss: 2.327Train Acc: 0.095\n",
      "Epoch 50/50, Train Loss: 2.322Train Acc: 0.112\n",
      "Finished 23 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.10865191146881288\n",
      "Epoch 1/10, Train Loss: 2.176Train Acc: 0.200\n",
      "Epoch 2/10, Train Loss: 1.944Train Acc: 0.285\n",
      "Epoch 3/10, Train Loss: 1.801Train Acc: 0.381\n",
      "Epoch 4/10, Train Loss: 1.701Train Acc: 0.416\n",
      "Epoch 5/10, Train Loss: 1.590Train Acc: 0.469\n",
      "Epoch 6/10, Train Loss: 1.494Train Acc: 0.503\n",
      "Epoch 7/10, Train Loss: 1.378Train Acc: 0.543\n",
      "Epoch 8/10, Train Loss: 1.258Train Acc: 0.606\n",
      "Epoch 9/10, Train Loss: 1.146Train Acc: 0.658\n",
      "Epoch 10/10, Train Loss: 1.049Train Acc: 0.695\n",
      "Finished 24 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.2635814889336016\n",
      "Epoch 1/10, Train Loss: 2.318Train Acc: 0.098\n",
      "Epoch 2/10, Train Loss: 2.316Train Acc: 0.096\n",
      "Epoch 3/10, Train Loss: 2.315Train Acc: 0.096\n",
      "Epoch 4/10, Train Loss: 2.313Train Acc: 0.097\n",
      "Epoch 5/10, Train Loss: 2.316Train Acc: 0.102\n",
      "Epoch 6/10, Train Loss: 2.312Train Acc: 0.100\n",
      "Epoch 7/10, Train Loss: 2.316Train Acc: 0.105\n",
      "Epoch 8/10, Train Loss: 2.312Train Acc: 0.110\n",
      "Epoch 9/10, Train Loss: 2.320Train Acc: 0.089\n",
      "Epoch 10/10, Train Loss: 2.313Train Acc: 0.101\n",
      "Finished 25 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.09456740442655935\n",
      "Epoch 1/10, Train Loss: 2.316Train Acc: 0.098\n",
      "Epoch 2/10, Train Loss: 2.310Train Acc: 0.098\n",
      "Epoch 3/10, Train Loss: 2.311Train Acc: 0.098\n",
      "Epoch 4/10, Train Loss: 2.311Train Acc: 0.090\n",
      "Epoch 5/10, Train Loss: 2.312Train Acc: 0.089\n",
      "Epoch 6/10, Train Loss: 2.312Train Acc: 0.104\n",
      "Epoch 7/10, Train Loss: 2.308Train Acc: 0.100\n",
      "Epoch 8/10, Train Loss: 2.308Train Acc: 0.104\n",
      "Epoch 9/10, Train Loss: 2.308Train Acc: 0.098\n",
      "Epoch 10/10, Train Loss: 2.314Train Acc: 0.083\n",
      "Finished 26 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.10865191146881288\n",
      "Epoch 1/50, Train Loss: 1.669Train Acc: 0.418\n",
      "Epoch 2/50, Train Loss: 1.077Train Acc: 0.665\n",
      "Epoch 3/50, Train Loss: 0.925Train Acc: 0.711\n",
      "Epoch 4/50, Train Loss: 0.963Train Acc: 0.692\n",
      "Epoch 5/50, Train Loss: 0.870Train Acc: 0.717\n",
      "Epoch 6/50, Train Loss: 0.826Train Acc: 0.747\n",
      "Epoch 7/50, Train Loss: 0.774Train Acc: 0.751\n",
      "Epoch 8/50, Train Loss: 0.833Train Acc: 0.739\n",
      "Epoch 9/50, Train Loss: 0.822Train Acc: 0.740\n",
      "Epoch 10/50, Train Loss: 0.836Train Acc: 0.729\n",
      "Epoch 11/50, Train Loss: 0.902Train Acc: 0.724\n",
      "Epoch 12/50, Train Loss: 1.272Train Acc: 0.580\n",
      "Epoch 13/50, Train Loss: 1.173Train Acc: 0.618\n",
      "Epoch 14/50, Train Loss: 1.188Train Acc: 0.625\n",
      "Epoch 15/50, Train Loss: 1.041Train Acc: 0.651\n",
      "Epoch 16/50, Train Loss: 1.080Train Acc: 0.640\n",
      "Epoch 17/50, Train Loss: 1.235Train Acc: 0.596\n",
      "Epoch 18/50, Train Loss: 1.002Train Acc: 0.669\n",
      "Epoch 19/50, Train Loss: 1.101Train Acc: 0.670\n",
      "Epoch 20/50, Train Loss: 1.177Train Acc: 0.625\n",
      "Epoch 21/50, Train Loss: 1.284Train Acc: 0.581\n",
      "Epoch 22/50, Train Loss: 1.169Train Acc: 0.625\n",
      "Epoch 23/50, Train Loss: 1.248Train Acc: 0.600\n",
      "Epoch 24/50, Train Loss: 1.365Train Acc: 0.552\n",
      "Epoch 25/50, Train Loss: 1.274Train Acc: 0.604\n",
      "Epoch 26/50, Train Loss: 1.229Train Acc: 0.584\n",
      "Epoch 27/50, Train Loss: 1.275Train Acc: 0.577\n",
      "Epoch 28/50, Train Loss: 1.274Train Acc: 0.587\n",
      "Epoch 29/50, Train Loss: 1.390Train Acc: 0.538\n",
      "Epoch 30/50, Train Loss: 1.406Train Acc: 0.544\n",
      "Epoch 31/50, Train Loss: 1.398Train Acc: 0.529\n",
      "Epoch 32/50, Train Loss: 1.435Train Acc: 0.518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Train Loss: 1.403Train Acc: 0.549\n",
      "Epoch 34/50, Train Loss: 1.401Train Acc: 0.544\n",
      "Epoch 35/50, Train Loss: 1.493Train Acc: 0.501\n",
      "Epoch 36/50, Train Loss: 1.588Train Acc: 0.464\n",
      "Epoch 37/50, Train Loss: 1.736Train Acc: 0.410\n",
      "Epoch 38/50, Train Loss: 1.772Train Acc: 0.407\n",
      "Epoch 39/50, Train Loss: 1.820Train Acc: 0.387\n",
      "Epoch 40/50, Train Loss: 1.641Train Acc: 0.442\n",
      "Epoch 41/50, Train Loss: 1.594Train Acc: 0.457\n",
      "Epoch 42/50, Train Loss: 1.554Train Acc: 0.463\n",
      "Epoch 43/50, Train Loss: 1.446Train Acc: 0.498\n",
      "Epoch 44/50, Train Loss: 1.436Train Acc: 0.506\n",
      "Epoch 45/50, Train Loss: 1.406Train Acc: 0.512\n",
      "Epoch 46/50, Train Loss: 1.401Train Acc: 0.519\n",
      "Epoch 47/50, Train Loss: 1.438Train Acc: 0.505\n",
      "Epoch 48/50, Train Loss: 1.417Train Acc: 0.513\n",
      "Epoch 49/50, Train Loss: 1.506Train Acc: 0.458\n",
      "Epoch 50/50, Train Loss: 1.634Train Acc: 0.435\n",
      "Finished 27 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.15694164989939638\n",
      "Epoch 1/10, Train Loss: 2.306Train Acc: 0.098\n",
      "Epoch 2/10, Train Loss: 2.125Train Acc: 0.218\n",
      "Epoch 3/10, Train Loss: 1.909Train Acc: 0.345\n",
      "Epoch 4/10, Train Loss: 1.742Train Acc: 0.430\n",
      "Epoch 5/10, Train Loss: 1.605Train Acc: 0.494\n",
      "Epoch 6/10, Train Loss: 1.493Train Acc: 0.526\n",
      "Epoch 7/10, Train Loss: 1.427Train Acc: 0.538\n",
      "Epoch 8/10, Train Loss: 1.345Train Acc: 0.575\n",
      "Epoch 9/10, Train Loss: 1.273Train Acc: 0.603\n",
      "Epoch 10/10, Train Loss: 1.239Train Acc: 0.598\n",
      "Finished 28 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.352112676056338\n",
      "Epoch 1/50, Train Loss: 1.674Train Acc: 0.427\n",
      "Epoch 2/50, Train Loss: 1.076Train Acc: 0.663\n",
      "Epoch 3/50, Train Loss: 0.956Train Acc: 0.706\n",
      "Epoch 4/50, Train Loss: 0.902Train Acc: 0.715\n",
      "Epoch 5/50, Train Loss: 0.830Train Acc: 0.746\n",
      "Epoch 6/50, Train Loss: 0.872Train Acc: 0.726\n",
      "Epoch 7/50, Train Loss: 0.797Train Acc: 0.747\n",
      "Epoch 8/50, Train Loss: 0.784Train Acc: 0.764\n",
      "Epoch 9/50, Train Loss: 0.959Train Acc: 0.698\n",
      "Epoch 10/50, Train Loss: 0.843Train Acc: 0.735\n",
      "Epoch 11/50, Train Loss: 0.970Train Acc: 0.695\n",
      "Epoch 12/50, Train Loss: 1.034Train Acc: 0.668\n",
      "Epoch 13/50, Train Loss: 0.894Train Acc: 0.711\n",
      "Epoch 14/50, Train Loss: 0.988Train Acc: 0.689\n",
      "Epoch 15/50, Train Loss: 0.964Train Acc: 0.685\n",
      "Epoch 16/50, Train Loss: 0.979Train Acc: 0.677\n",
      "Epoch 17/50, Train Loss: 0.963Train Acc: 0.686\n",
      "Epoch 18/50, Train Loss: 1.022Train Acc: 0.676\n",
      "Epoch 19/50, Train Loss: 1.041Train Acc: 0.668\n",
      "Epoch 20/50, Train Loss: 1.093Train Acc: 0.636\n",
      "Epoch 21/50, Train Loss: 1.157Train Acc: 0.615\n",
      "Epoch 22/50, Train Loss: 1.403Train Acc: 0.552\n",
      "Epoch 23/50, Train Loss: 1.309Train Acc: 0.569\n",
      "Epoch 24/50, Train Loss: 1.258Train Acc: 0.587\n",
      "Epoch 25/50, Train Loss: 1.264Train Acc: 0.585\n",
      "Epoch 26/50, Train Loss: 1.348Train Acc: 0.556\n",
      "Epoch 27/50, Train Loss: 1.244Train Acc: 0.593\n",
      "Epoch 28/50, Train Loss: 1.257Train Acc: 0.573\n",
      "Epoch 29/50, Train Loss: 1.260Train Acc: 0.586\n",
      "Epoch 30/50, Train Loss: 1.279Train Acc: 0.564\n",
      "Epoch 31/50, Train Loss: 1.222Train Acc: 0.587\n",
      "Epoch 32/50, Train Loss: 1.264Train Acc: 0.575\n",
      "Epoch 33/50, Train Loss: 1.394Train Acc: 0.549\n",
      "Epoch 34/50, Train Loss: 1.235Train Acc: 0.577\n",
      "Epoch 35/50, Train Loss: 1.373Train Acc: 0.531\n",
      "Epoch 36/50, Train Loss: 1.360Train Acc: 0.521\n",
      "Epoch 37/50, Train Loss: 1.387Train Acc: 0.528\n",
      "Epoch 38/50, Train Loss: 1.286Train Acc: 0.562\n",
      "Epoch 39/50, Train Loss: 1.533Train Acc: 0.468\n",
      "Epoch 40/50, Train Loss: 1.528Train Acc: 0.477\n",
      "Epoch 41/50, Train Loss: 1.492Train Acc: 0.481\n",
      "Epoch 42/50, Train Loss: 1.571Train Acc: 0.462\n",
      "Epoch 43/50, Train Loss: 1.506Train Acc: 0.476\n",
      "Epoch 44/50, Train Loss: 1.475Train Acc: 0.481\n",
      "Epoch 45/50, Train Loss: 1.604Train Acc: 0.443\n",
      "Epoch 46/50, Train Loss: 1.553Train Acc: 0.456\n",
      "Epoch 47/50, Train Loss: 1.547Train Acc: 0.465\n",
      "Epoch 48/50, Train Loss: 1.624Train Acc: 0.430\n",
      "Epoch 49/50, Train Loss: 1.572Train Acc: 0.450\n",
      "Epoch 50/50, Train Loss: 1.551Train Acc: 0.453\n",
      "Finished 29 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.19517102615694165\n",
      "Epoch 1/50, Train Loss: 2.235Train Acc: 0.158\n",
      "Epoch 2/50, Train Loss: 1.962Train Acc: 0.300\n",
      "Epoch 3/50, Train Loss: 1.638Train Acc: 0.452\n",
      "Epoch 4/50, Train Loss: 1.385Train Acc: 0.582\n",
      "Epoch 5/50, Train Loss: 1.225Train Acc: 0.628\n",
      "Epoch 6/50, Train Loss: 1.120Train Acc: 0.659\n",
      "Epoch 7/50, Train Loss: 1.045Train Acc: 0.676\n",
      "Epoch 8/50, Train Loss: 0.980Train Acc: 0.696\n",
      "Epoch 9/50, Train Loss: 0.918Train Acc: 0.716\n",
      "Epoch 10/50, Train Loss: 0.895Train Acc: 0.725\n",
      "Epoch 11/50, Train Loss: 0.835Train Acc: 0.735\n",
      "Epoch 12/50, Train Loss: 0.805Train Acc: 0.750\n",
      "Epoch 13/50, Train Loss: 0.776Train Acc: 0.757\n",
      "Epoch 14/50, Train Loss: 0.786Train Acc: 0.748\n",
      "Epoch 15/50, Train Loss: 0.728Train Acc: 0.767\n",
      "Epoch 16/50, Train Loss: 0.691Train Acc: 0.785\n",
      "Epoch 17/50, Train Loss: 0.685Train Acc: 0.784\n",
      "Epoch 18/50, Train Loss: 0.673Train Acc: 0.780\n",
      "Epoch 19/50, Train Loss: 0.638Train Acc: 0.798\n",
      "Epoch 20/50, Train Loss: 0.628Train Acc: 0.796\n",
      "Epoch 21/50, Train Loss: 0.617Train Acc: 0.807\n",
      "Epoch 22/50, Train Loss: 0.579Train Acc: 0.820\n",
      "Epoch 23/50, Train Loss: 0.546Train Acc: 0.830\n",
      "Epoch 24/50, Train Loss: 0.533Train Acc: 0.830\n",
      "Epoch 25/50, Train Loss: 0.520Train Acc: 0.833\n",
      "Epoch 26/50, Train Loss: 0.524Train Acc: 0.837\n",
      "Epoch 27/50, Train Loss: 0.544Train Acc: 0.826\n",
      "Epoch 28/50, Train Loss: 0.517Train Acc: 0.830\n",
      "Epoch 29/50, Train Loss: 0.483Train Acc: 0.851\n",
      "Epoch 30/50, Train Loss: 0.480Train Acc: 0.848\n",
      "Epoch 31/50, Train Loss: 0.467Train Acc: 0.858\n",
      "Epoch 32/50, Train Loss: 0.444Train Acc: 0.862\n",
      "Epoch 33/50, Train Loss: 0.491Train Acc: 0.848\n",
      "Epoch 34/50, Train Loss: 0.458Train Acc: 0.855\n",
      "Epoch 35/50, Train Loss: 0.395Train Acc: 0.874\n",
      "Epoch 36/50, Train Loss: 0.392Train Acc: 0.876\n",
      "Epoch 37/50, Train Loss: 0.383Train Acc: 0.877\n",
      "Epoch 38/50, Train Loss: 0.375Train Acc: 0.876\n",
      "Epoch 39/50, Train Loss: 0.355Train Acc: 0.884\n",
      "Epoch 40/50, Train Loss: 0.349Train Acc: 0.889\n",
      "Epoch 41/50, Train Loss: 0.361Train Acc: 0.889\n",
      "Epoch 42/50, Train Loss: 0.357Train Acc: 0.886\n",
      "Epoch 43/50, Train Loss: 0.357Train Acc: 0.888\n",
      "Epoch 44/50, Train Loss: 0.389Train Acc: 0.873\n",
      "Epoch 45/50, Train Loss: 0.359Train Acc: 0.882\n",
      "Epoch 46/50, Train Loss: 0.347Train Acc: 0.890\n",
      "Epoch 47/50, Train Loss: 0.329Train Acc: 0.892\n",
      "Epoch 48/50, Train Loss: 0.314Train Acc: 0.897\n",
      "Epoch 49/50, Train Loss: 0.307Train Acc: 0.902\n",
      "Epoch 50/50, Train Loss: 0.293Train Acc: 0.911\n",
      "Finished 30 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.3702213279678068\n",
      "Epoch 1/10, Train Loss: 2.377Train Acc: 0.103\n",
      "Epoch 2/10, Train Loss: 2.286Train Acc: 0.140\n",
      "Epoch 3/10, Train Loss: 2.269Train Acc: 0.135\n",
      "Epoch 4/10, Train Loss: 2.302Train Acc: 0.154\n",
      "Epoch 5/10, Train Loss: 2.295Train Acc: 0.142\n",
      "Epoch 6/10, Train Loss: 2.297Train Acc: 0.133\n",
      "Epoch 7/10, Train Loss: 2.321Train Acc: 0.141\n",
      "Epoch 8/10, Train Loss: 2.311Train Acc: 0.117\n",
      "Epoch 9/10, Train Loss: 2.326Train Acc: 0.132\n",
      "Epoch 10/10, Train Loss: 2.305Train Acc: 0.131\n",
      "Finished 31 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.09456740442655935\n",
      "Epoch 1/10, Train Loss: 2.282Train Acc: 0.143\n",
      "Epoch 2/10, Train Loss: 2.139Train Acc: 0.247\n",
      "Epoch 3/10, Train Loss: 1.965Train Acc: 0.323\n",
      "Epoch 4/10, Train Loss: 1.836Train Acc: 0.372\n",
      "Epoch 5/10, Train Loss: 1.708Train Acc: 0.426\n",
      "Epoch 6/10, Train Loss: 1.608Train Acc: 0.476\n",
      "Epoch 7/10, Train Loss: 1.509Train Acc: 0.516\n",
      "Epoch 8/10, Train Loss: 1.425Train Acc: 0.547\n",
      "Epoch 9/10, Train Loss: 1.350Train Acc: 0.594\n",
      "Epoch 10/10, Train Loss: 1.289Train Acc: 0.603\n",
      "Finished 32 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.23340040241448692\n",
      "Epoch 1/50, Train Loss: 2.299Train Acc: 0.113\n",
      "Epoch 2/50, Train Loss: 2.063Train Acc: 0.257\n",
      "Epoch 3/50, Train Loss: 1.860Train Acc: 0.332\n",
      "Epoch 4/50, Train Loss: 1.719Train Acc: 0.393\n",
      "Epoch 5/50, Train Loss: 1.627Train Acc: 0.449\n",
      "Epoch 6/50, Train Loss: 1.547Train Acc: 0.458\n",
      "Epoch 7/50, Train Loss: 1.434Train Acc: 0.512\n",
      "Epoch 8/50, Train Loss: 1.374Train Acc: 0.539\n",
      "Epoch 9/50, Train Loss: 1.304Train Acc: 0.580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Train Loss: 1.245Train Acc: 0.589\n",
      "Epoch 11/50, Train Loss: 1.158Train Acc: 0.625\n",
      "Epoch 12/50, Train Loss: 1.130Train Acc: 0.631\n",
      "Epoch 13/50, Train Loss: 1.075Train Acc: 0.649\n",
      "Epoch 14/50, Train Loss: 1.087Train Acc: 0.640\n",
      "Epoch 15/50, Train Loss: 1.041Train Acc: 0.660\n",
      "Epoch 16/50, Train Loss: 0.961Train Acc: 0.682\n",
      "Epoch 17/50, Train Loss: 0.967Train Acc: 0.693\n",
      "Epoch 18/50, Train Loss: 0.964Train Acc: 0.697\n",
      "Epoch 19/50, Train Loss: 0.933Train Acc: 0.697\n",
      "Epoch 20/50, Train Loss: 0.891Train Acc: 0.717\n",
      "Epoch 21/50, Train Loss: 0.869Train Acc: 0.721\n",
      "Epoch 22/50, Train Loss: 0.850Train Acc: 0.722\n",
      "Epoch 23/50, Train Loss: 0.819Train Acc: 0.730\n",
      "Epoch 24/50, Train Loss: 0.836Train Acc: 0.730\n",
      "Epoch 25/50, Train Loss: 0.790Train Acc: 0.755\n",
      "Epoch 26/50, Train Loss: 0.848Train Acc: 0.733\n",
      "Epoch 27/50, Train Loss: 0.851Train Acc: 0.737\n",
      "Epoch 28/50, Train Loss: 0.791Train Acc: 0.741\n",
      "Epoch 29/50, Train Loss: 0.811Train Acc: 0.739\n",
      "Epoch 30/50, Train Loss: 0.779Train Acc: 0.749\n",
      "Epoch 31/50, Train Loss: 0.761Train Acc: 0.757\n",
      "Epoch 32/50, Train Loss: 0.742Train Acc: 0.754\n",
      "Epoch 33/50, Train Loss: 0.770Train Acc: 0.752\n",
      "Epoch 34/50, Train Loss: 0.705Train Acc: 0.774\n",
      "Epoch 35/50, Train Loss: 0.708Train Acc: 0.777\n",
      "Epoch 36/50, Train Loss: 0.664Train Acc: 0.785\n",
      "Epoch 37/50, Train Loss: 0.683Train Acc: 0.783\n",
      "Epoch 38/50, Train Loss: 0.810Train Acc: 0.743\n",
      "Epoch 39/50, Train Loss: 0.682Train Acc: 0.783\n",
      "Epoch 40/50, Train Loss: 0.669Train Acc: 0.788\n",
      "Epoch 41/50, Train Loss: 0.678Train Acc: 0.779\n",
      "Epoch 42/50, Train Loss: 0.706Train Acc: 0.775\n",
      "Epoch 43/50, Train Loss: 0.667Train Acc: 0.792\n",
      "Epoch 44/50, Train Loss: 0.699Train Acc: 0.762\n",
      "Epoch 45/50, Train Loss: 0.734Train Acc: 0.759\n",
      "Epoch 46/50, Train Loss: 0.665Train Acc: 0.784\n",
      "Epoch 47/50, Train Loss: 0.680Train Acc: 0.782\n",
      "Epoch 48/50, Train Loss: 0.643Train Acc: 0.785\n",
      "Epoch 49/50, Train Loss: 0.622Train Acc: 0.804\n",
      "Epoch 50/50, Train Loss: 0.648Train Acc: 0.786\n",
      "Finished 33 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.30985915492957744\n",
      "Epoch 1/10, Train Loss: 1.917Train Acc: 0.311\n",
      "Epoch 2/10, Train Loss: 1.415Train Acc: 0.536\n",
      "Epoch 3/10, Train Loss: 1.054Train Acc: 0.666\n",
      "Epoch 4/10, Train Loss: 0.910Train Acc: 0.711\n",
      "Epoch 5/10, Train Loss: 0.865Train Acc: 0.727\n",
      "Epoch 6/10, Train Loss: 0.935Train Acc: 0.707\n",
      "Epoch 7/10, Train Loss: 0.814Train Acc: 0.737\n",
      "Epoch 8/10, Train Loss: 0.901Train Acc: 0.716\n",
      "Epoch 9/10, Train Loss: 0.891Train Acc: 0.713\n",
      "Epoch 10/10, Train Loss: 0.893Train Acc: 0.721\n",
      "Finished 34 of 144 parameter combinations\n",
      "best parameters are (32, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.19919517102615694\n",
      "Epoch 1/20, Train Loss: 2.014Train Acc: 0.276\n",
      "Epoch 2/20, Train Loss: 1.549Train Acc: 0.501\n",
      "Epoch 3/20, Train Loss: 1.199Train Acc: 0.652\n",
      "Epoch 4/20, Train Loss: 0.954Train Acc: 0.731\n",
      "Epoch 5/20, Train Loss: 0.793Train Acc: 0.762\n",
      "Epoch 6/20, Train Loss: 0.663Train Acc: 0.811\n",
      "Epoch 7/20, Train Loss: 0.581Train Acc: 0.832\n",
      "Epoch 8/20, Train Loss: 0.515Train Acc: 0.855\n",
      "Epoch 9/20, Train Loss: 0.467Train Acc: 0.866\n",
      "Epoch 10/20, Train Loss: 0.416Train Acc: 0.885\n",
      "Epoch 11/20, Train Loss: 0.389Train Acc: 0.881\n",
      "Epoch 12/20, Train Loss: 0.333Train Acc: 0.903\n",
      "Epoch 13/20, Train Loss: 0.337Train Acc: 0.908\n",
      "Epoch 14/20, Train Loss: 0.310Train Acc: 0.915\n",
      "Epoch 15/20, Train Loss: 0.291Train Acc: 0.912\n",
      "Epoch 16/20, Train Loss: 0.239Train Acc: 0.935\n",
      "Epoch 17/20, Train Loss: 0.255Train Acc: 0.924\n",
      "Epoch 18/20, Train Loss: 0.240Train Acc: 0.928\n",
      "Epoch 19/20, Train Loss: 0.213Train Acc: 0.941\n",
      "Epoch 20/20, Train Loss: 0.197Train Acc: 0.939\n",
      "Finished 35 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 20, 2, 0.5)\n",
      "dev accuracy for the given set of parameters 0.42857142857142855\n",
      "Epoch 1/10, Train Loss: 1.988Train Acc: 0.288\n",
      "Epoch 2/10, Train Loss: 1.494Train Acc: 0.540\n",
      "Epoch 3/10, Train Loss: 1.140Train Acc: 0.684\n",
      "Epoch 4/10, Train Loss: 0.920Train Acc: 0.732\n",
      "Epoch 5/10, Train Loss: 0.805Train Acc: 0.762\n",
      "Epoch 6/10, Train Loss: 0.702Train Acc: 0.793\n",
      "Epoch 7/10, Train Loss: 0.612Train Acc: 0.808\n",
      "Epoch 8/10, Train Loss: 0.551Train Acc: 0.840\n",
      "Epoch 9/10, Train Loss: 0.512Train Acc: 0.841\n",
      "Epoch 10/10, Train Loss: 0.472Train Acc: 0.863\n",
      "Finished 36 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 20, 2, 0.5)\n",
      "dev accuracy for the given set of parameters 0.37424547283702214\n",
      "Epoch 1/10, Train Loss: 2.238Train Acc: 0.162\n",
      "Epoch 2/10, Train Loss: 2.011Train Acc: 0.281\n",
      "Epoch 3/10, Train Loss: 1.817Train Acc: 0.356\n",
      "Epoch 4/10, Train Loss: 1.929Train Acc: 0.322\n",
      "Epoch 5/10, Train Loss: 1.654Train Acc: 0.420\n",
      "Epoch 6/10, Train Loss: 1.876Train Acc: 0.361\n",
      "Epoch 7/10, Train Loss: 1.731Train Acc: 0.387\n",
      "Epoch 8/10, Train Loss: 2.054Train Acc: 0.278\n",
      "Epoch 9/10, Train Loss: 2.182Train Acc: 0.176\n",
      "Epoch 10/10, Train Loss: 2.123Train Acc: 0.223\n",
      "Finished 37 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 20, 2, 0.5)\n",
      "dev accuracy for the given set of parameters 0.19517102615694165\n",
      "Epoch 1/10, Train Loss: 2.319Train Acc: 0.101\n",
      "Epoch 2/10, Train Loss: 2.317Train Acc: 0.094\n",
      "Epoch 3/10, Train Loss: 2.317Train Acc: 0.081\n",
      "Epoch 4/10, Train Loss: 2.310Train Acc: 0.087\n",
      "Epoch 5/10, Train Loss: 2.305Train Acc: 0.100\n",
      "Epoch 6/10, Train Loss: 2.268Train Acc: 0.135\n",
      "Epoch 7/10, Train Loss: 2.183Train Acc: 0.183\n",
      "Epoch 8/10, Train Loss: 2.124Train Acc: 0.217\n",
      "Epoch 9/10, Train Loss: 2.073Train Acc: 0.234\n",
      "Epoch 10/10, Train Loss: 1.988Train Acc: 0.281\n",
      "Finished 38 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 20, 2, 0.5)\n",
      "dev accuracy for the given set of parameters 0.12877263581488935\n",
      "Epoch 1/10, Train Loss: 1.926Train Acc: 0.309\n",
      "Epoch 2/10, Train Loss: 1.607Train Acc: 0.452\n",
      "Epoch 3/10, Train Loss: 1.444Train Acc: 0.510\n",
      "Epoch 4/10, Train Loss: 1.222Train Acc: 0.602\n",
      "Epoch 5/10, Train Loss: 1.197Train Acc: 0.600\n",
      "Epoch 6/10, Train Loss: 1.121Train Acc: 0.642\n",
      "Epoch 7/10, Train Loss: 1.135Train Acc: 0.635\n",
      "Epoch 8/10, Train Loss: 1.125Train Acc: 0.647\n",
      "Epoch 9/10, Train Loss: 1.331Train Acc: 0.555\n",
      "Epoch 10/10, Train Loss: 1.144Train Acc: 0.637\n",
      "Finished 39 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 20, 2, 0.5)\n",
      "dev accuracy for the given set of parameters 0.23943661971830985\n",
      "Epoch 1/50, Train Loss: 2.316Train Acc: 0.095\n",
      "Epoch 2/50, Train Loss: 2.106Train Acc: 0.203\n",
      "Epoch 3/50, Train Loss: 1.813Train Acc: 0.315\n",
      "Epoch 4/50, Train Loss: 1.766Train Acc: 0.351\n",
      "Epoch 5/50, Train Loss: 1.714Train Acc: 0.366\n",
      "Epoch 6/50, Train Loss: 1.595Train Acc: 0.421\n",
      "Epoch 7/50, Train Loss: 1.508Train Acc: 0.469\n",
      "Epoch 8/50, Train Loss: 1.497Train Acc: 0.480\n",
      "Epoch 9/50, Train Loss: 1.416Train Acc: 0.514\n",
      "Epoch 10/50, Train Loss: 1.472Train Acc: 0.494\n",
      "Epoch 11/50, Train Loss: 1.491Train Acc: 0.473\n",
      "Epoch 12/50, Train Loss: 1.489Train Acc: 0.471\n",
      "Epoch 13/50, Train Loss: 1.677Train Acc: 0.397\n",
      "Epoch 14/50, Train Loss: 1.845Train Acc: 0.308\n",
      "Epoch 15/50, Train Loss: 1.738Train Acc: 0.335\n",
      "Epoch 16/50, Train Loss: 1.664Train Acc: 0.365\n",
      "Epoch 17/50, Train Loss: 1.589Train Acc: 0.418\n",
      "Epoch 18/50, Train Loss: 1.581Train Acc: 0.402\n",
      "Epoch 19/50, Train Loss: 1.506Train Acc: 0.433\n",
      "Epoch 20/50, Train Loss: 1.554Train Acc: 0.442\n",
      "Epoch 21/50, Train Loss: 1.500Train Acc: 0.461\n",
      "Epoch 22/50, Train Loss: 1.490Train Acc: 0.469\n",
      "Epoch 23/50, Train Loss: 1.545Train Acc: 0.426\n",
      "Epoch 24/50, Train Loss: 1.532Train Acc: 0.433\n",
      "Epoch 25/50, Train Loss: 1.530Train Acc: 0.442\n",
      "Epoch 26/50, Train Loss: 2.036Train Acc: 0.296\n",
      "Epoch 27/50, Train Loss: 1.763Train Acc: 0.364\n",
      "Epoch 28/50, Train Loss: 1.713Train Acc: 0.365\n",
      "Epoch 29/50, Train Loss: 1.769Train Acc: 0.351\n",
      "Epoch 30/50, Train Loss: 1.810Train Acc: 0.339\n",
      "Epoch 31/50, Train Loss: 1.670Train Acc: 0.387\n",
      "Epoch 32/50, Train Loss: 1.767Train Acc: 0.367\n",
      "Epoch 33/50, Train Loss: 1.705Train Acc: 0.384\n",
      "Epoch 34/50, Train Loss: 1.741Train Acc: 0.372\n",
      "Epoch 35/50, Train Loss: 1.712Train Acc: 0.371\n",
      "Epoch 36/50, Train Loss: 1.786Train Acc: 0.325\n",
      "Epoch 37/50, Train Loss: 1.916Train Acc: 0.294\n",
      "Epoch 38/50, Train Loss: 1.939Train Acc: 0.259\n",
      "Epoch 39/50, Train Loss: 1.877Train Acc: 0.286\n",
      "Epoch 40/50, Train Loss: 1.841Train Acc: 0.305\n",
      "Epoch 41/50, Train Loss: 1.821Train Acc: 0.299\n",
      "Epoch 42/50, Train Loss: 1.823Train Acc: 0.302\n",
      "Epoch 43/50, Train Loss: 1.834Train Acc: 0.307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Train Loss: 1.956Train Acc: 0.253\n",
      "Epoch 45/50, Train Loss: 1.983Train Acc: 0.232\n",
      "Epoch 46/50, Train Loss: 1.984Train Acc: 0.219\n",
      "Epoch 47/50, Train Loss: 1.975Train Acc: 0.227\n",
      "Epoch 48/50, Train Loss: 1.949Train Acc: 0.231\n",
      "Epoch 49/50, Train Loss: 1.939Train Acc: 0.241\n",
      "Epoch 50/50, Train Loss: 1.958Train Acc: 0.247\n",
      "Finished 40 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 20, 2, 0.5)\n",
      "dev accuracy for the given set of parameters 0.11468812877263582\n",
      "Epoch 1/50, Train Loss: 2.342Train Acc: 0.121\n",
      "Epoch 2/50, Train Loss: 2.232Train Acc: 0.178\n",
      "Epoch 3/50, Train Loss: 2.223Train Acc: 0.176\n",
      "Epoch 4/50, Train Loss: 2.302Train Acc: 0.136\n",
      "Epoch 5/50, Train Loss: 2.356Train Acc: 0.116\n",
      "Epoch 6/50, Train Loss: 2.328Train Acc: 0.106\n",
      "Epoch 7/50, Train Loss: 2.304Train Acc: 0.130\n",
      "Epoch 8/50, Train Loss: 2.170Train Acc: 0.210\n",
      "Epoch 9/50, Train Loss: 2.047Train Acc: 0.248\n",
      "Epoch 10/50, Train Loss: 2.058Train Acc: 0.251\n",
      "Epoch 11/50, Train Loss: 2.003Train Acc: 0.277\n",
      "Epoch 12/50, Train Loss: 2.150Train Acc: 0.206\n",
      "Epoch 13/50, Train Loss: 2.195Train Acc: 0.198\n",
      "Epoch 14/50, Train Loss: 2.119Train Acc: 0.226\n",
      "Epoch 15/50, Train Loss: 2.088Train Acc: 0.244\n",
      "Epoch 16/50, Train Loss: 2.138Train Acc: 0.204\n",
      "Epoch 17/50, Train Loss: 2.165Train Acc: 0.192\n",
      "Epoch 18/50, Train Loss: 2.115Train Acc: 0.232\n",
      "Epoch 19/50, Train Loss: 2.068Train Acc: 0.224\n",
      "Epoch 20/50, Train Loss: 2.119Train Acc: 0.221\n",
      "Epoch 21/50, Train Loss: 2.281Train Acc: 0.178\n",
      "Epoch 22/50, Train Loss: 2.252Train Acc: 0.169\n",
      "Epoch 23/50, Train Loss: 2.173Train Acc: 0.200\n",
      "Epoch 24/50, Train Loss: 2.222Train Acc: 0.192\n",
      "Epoch 25/50, Train Loss: 2.308Train Acc: 0.149\n",
      "Epoch 26/50, Train Loss: 2.238Train Acc: 0.173\n",
      "Epoch 27/50, Train Loss: 2.334Train Acc: 0.126\n",
      "Epoch 28/50, Train Loss: 2.366Train Acc: 0.105\n",
      "Epoch 29/50, Train Loss: 2.328Train Acc: 0.123\n",
      "Epoch 30/50, Train Loss: 2.338Train Acc: 0.116\n",
      "Epoch 31/50, Train Loss: 2.365Train Acc: 0.095\n",
      "Epoch 32/50, Train Loss: 2.354Train Acc: 0.102\n",
      "Epoch 33/50, Train Loss: 2.287Train Acc: 0.150\n",
      "Epoch 34/50, Train Loss: 2.220Train Acc: 0.184\n",
      "Epoch 35/50, Train Loss: 2.223Train Acc: 0.181\n",
      "Epoch 36/50, Train Loss: 2.262Train Acc: 0.145\n",
      "Epoch 37/50, Train Loss: 2.235Train Acc: 0.176\n",
      "Epoch 38/50, Train Loss: 2.188Train Acc: 0.192\n",
      "Epoch 39/50, Train Loss: 2.259Train Acc: 0.142\n",
      "Epoch 40/50, Train Loss: 2.333Train Acc: 0.119\n",
      "Epoch 41/50, Train Loss: 2.339Train Acc: 0.139\n",
      "Epoch 42/50, Train Loss: 2.350Train Acc: 0.117\n",
      "Epoch 43/50, Train Loss: 2.318Train Acc: 0.123\n",
      "Epoch 44/50, Train Loss: 2.320Train Acc: 0.135\n",
      "Epoch 45/50, Train Loss: 2.320Train Acc: 0.135\n",
      "Epoch 46/50, Train Loss: 2.318Train Acc: 0.132\n",
      "Epoch 47/50, Train Loss: 2.282Train Acc: 0.154\n",
      "Epoch 48/50, Train Loss: 2.238Train Acc: 0.176\n",
      "Epoch 49/50, Train Loss: 2.308Train Acc: 0.146\n",
      "Epoch 50/50, Train Loss: 2.357Train Acc: 0.114\n",
      "Finished 41 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 20, 2, 0.5)\n",
      "dev accuracy for the given set of parameters 0.10462776659959759\n",
      "Epoch 1/10, Train Loss: 2.325Train Acc: 0.096\n",
      "Epoch 2/10, Train Loss: 2.322Train Acc: 0.102\n",
      "Epoch 3/10, Train Loss: 2.316Train Acc: 0.101\n",
      "Epoch 4/10, Train Loss: 2.321Train Acc: 0.098\n",
      "Epoch 5/10, Train Loss: 2.318Train Acc: 0.102\n",
      "Epoch 6/10, Train Loss: 2.319Train Acc: 0.103\n",
      "Epoch 7/10, Train Loss: 2.318Train Acc: 0.100\n",
      "Epoch 8/10, Train Loss: 2.315Train Acc: 0.095\n",
      "Epoch 9/10, Train Loss: 2.319Train Acc: 0.090\n",
      "Epoch 10/10, Train Loss: 2.317Train Acc: 0.097\n",
      "Finished 42 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 20, 2, 0.5)\n",
      "dev accuracy for the given set of parameters 0.09054325955734406\n",
      "Epoch 1/20, Train Loss: 2.320Train Acc: 0.102\n",
      "Epoch 2/20, Train Loss: 2.316Train Acc: 0.094\n",
      "Epoch 3/20, Train Loss: 2.149Train Acc: 0.199\n",
      "Epoch 4/20, Train Loss: 1.975Train Acc: 0.273\n",
      "Epoch 5/20, Train Loss: 1.829Train Acc: 0.339\n",
      "Epoch 6/20, Train Loss: 1.745Train Acc: 0.392\n",
      "Epoch 7/20, Train Loss: 1.630Train Acc: 0.434\n",
      "Epoch 8/20, Train Loss: 1.574Train Acc: 0.463\n",
      "Epoch 9/20, Train Loss: 1.491Train Acc: 0.503\n",
      "Epoch 10/20, Train Loss: 1.443Train Acc: 0.519\n",
      "Epoch 11/20, Train Loss: 1.403Train Acc: 0.526\n",
      "Epoch 12/20, Train Loss: 1.349Train Acc: 0.553\n",
      "Epoch 13/20, Train Loss: 1.318Train Acc: 0.576\n",
      "Epoch 14/20, Train Loss: 1.289Train Acc: 0.583\n",
      "Epoch 15/20, Train Loss: 1.236Train Acc: 0.602\n",
      "Epoch 16/20, Train Loss: 1.192Train Acc: 0.616\n",
      "Epoch 17/20, Train Loss: 1.157Train Acc: 0.629\n",
      "Epoch 18/20, Train Loss: 1.162Train Acc: 0.622\n",
      "Epoch 19/20, Train Loss: 1.116Train Acc: 0.645\n",
      "Epoch 20/20, Train Loss: 1.084Train Acc: 0.644\n",
      "Finished 43 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 20, 2, 0.5)\n",
      "dev accuracy for the given set of parameters 0.2837022132796781\n",
      "Epoch 1/50, Train Loss: 2.056Train Acc: 0.275\n",
      "Epoch 2/50, Train Loss: 1.618Train Acc: 0.489\n",
      "Epoch 3/50, Train Loss: 1.237Train Acc: 0.650\n",
      "Epoch 4/50, Train Loss: 0.961Train Acc: 0.745\n",
      "Epoch 5/50, Train Loss: 0.770Train Acc: 0.787\n",
      "Epoch 6/50, Train Loss: 0.640Train Acc: 0.828\n",
      "Epoch 7/50, Train Loss: 0.562Train Acc: 0.841\n",
      "Epoch 8/50, Train Loss: 0.499Train Acc: 0.863\n",
      "Epoch 9/50, Train Loss: 0.423Train Acc: 0.887\n",
      "Epoch 10/50, Train Loss: 0.376Train Acc: 0.897\n",
      "Epoch 11/50, Train Loss: 0.342Train Acc: 0.907\n",
      "Epoch 12/50, Train Loss: 0.312Train Acc: 0.917\n",
      "Epoch 13/50, Train Loss: 0.272Train Acc: 0.932\n",
      "Epoch 14/50, Train Loss: 0.252Train Acc: 0.935\n",
      "Epoch 15/50, Train Loss: 0.225Train Acc: 0.940\n",
      "Epoch 16/50, Train Loss: 0.221Train Acc: 0.938\n",
      "Epoch 17/50, Train Loss: 0.210Train Acc: 0.940\n",
      "Epoch 18/50, Train Loss: 0.171Train Acc: 0.952\n",
      "Epoch 19/50, Train Loss: 0.166Train Acc: 0.958\n",
      "Epoch 20/50, Train Loss: 0.144Train Acc: 0.969\n",
      "Epoch 21/50, Train Loss: 0.137Train Acc: 0.969\n",
      "Epoch 22/50, Train Loss: 0.121Train Acc: 0.975\n",
      "Epoch 23/50, Train Loss: 0.123Train Acc: 0.970\n",
      "Epoch 24/50, Train Loss: 0.114Train Acc: 0.975\n",
      "Epoch 25/50, Train Loss: 0.099Train Acc: 0.976\n",
      "Epoch 26/50, Train Loss: 0.087Train Acc: 0.982\n",
      "Epoch 27/50, Train Loss: 0.087Train Acc: 0.980\n",
      "Epoch 28/50, Train Loss: 0.102Train Acc: 0.973\n",
      "Epoch 29/50, Train Loss: 0.081Train Acc: 0.981\n",
      "Epoch 30/50, Train Loss: 0.077Train Acc: 0.983\n",
      "Epoch 31/50, Train Loss: 0.068Train Acc: 0.986\n",
      "Epoch 32/50, Train Loss: 0.063Train Acc: 0.987\n",
      "Epoch 33/50, Train Loss: 0.055Train Acc: 0.990\n",
      "Epoch 34/50, Train Loss: 0.049Train Acc: 0.990\n",
      "Epoch 35/50, Train Loss: 0.066Train Acc: 0.985\n",
      "Epoch 36/50, Train Loss: 0.053Train Acc: 0.989\n",
      "Epoch 37/50, Train Loss: 0.057Train Acc: 0.987\n",
      "Epoch 38/50, Train Loss: 0.085Train Acc: 0.975\n",
      "Epoch 39/50, Train Loss: 0.044Train Acc: 0.992\n",
      "Epoch 40/50, Train Loss: 0.038Train Acc: 0.993\n",
      "Epoch 41/50, Train Loss: 0.035Train Acc: 0.993\n",
      "Epoch 42/50, Train Loss: 0.028Train Acc: 0.996\n",
      "Epoch 43/50, Train Loss: 0.032Train Acc: 0.994\n",
      "Epoch 44/50, Train Loss: 0.076Train Acc: 0.979\n",
      "Epoch 45/50, Train Loss: 0.070Train Acc: 0.981\n",
      "Epoch 46/50, Train Loss: 0.045Train Acc: 0.989\n",
      "Epoch 47/50, Train Loss: 0.024Train Acc: 0.998\n",
      "Epoch 48/50, Train Loss: 0.046Train Acc: 0.987\n",
      "Epoch 49/50, Train Loss: 0.041Train Acc: 0.990\n",
      "Epoch 50/50, Train Loss: 0.021Train Acc: 0.998\n",
      "Finished 44 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.4426559356136821\n",
      "Epoch 1/20, Train Loss: 2.343Train Acc: 0.101\n",
      "Epoch 2/20, Train Loss: 2.103Train Acc: 0.217\n",
      "Epoch 3/20, Train Loss: 1.954Train Acc: 0.279\n",
      "Epoch 4/20, Train Loss: 1.916Train Acc: 0.279\n",
      "Epoch 5/20, Train Loss: 2.246Train Acc: 0.169\n",
      "Epoch 6/20, Train Loss: 2.337Train Acc: 0.107\n",
      "Epoch 7/20, Train Loss: 2.297Train Acc: 0.118\n",
      "Epoch 8/20, Train Loss: 2.249Train Acc: 0.146\n",
      "Epoch 9/20, Train Loss: 2.165Train Acc: 0.184\n",
      "Epoch 10/20, Train Loss: 1.973Train Acc: 0.261\n",
      "Epoch 11/20, Train Loss: 1.891Train Acc: 0.291\n",
      "Epoch 12/20, Train Loss: 1.877Train Acc: 0.291\n",
      "Epoch 13/20, Train Loss: 1.756Train Acc: 0.345\n",
      "Epoch 14/20, Train Loss: 1.776Train Acc: 0.344\n",
      "Epoch 15/20, Train Loss: 1.749Train Acc: 0.356\n",
      "Epoch 16/20, Train Loss: 1.781Train Acc: 0.330\n",
      "Epoch 17/20, Train Loss: 1.876Train Acc: 0.298\n",
      "Epoch 18/20, Train Loss: 2.040Train Acc: 0.239\n",
      "Epoch 19/20, Train Loss: 1.955Train Acc: 0.259\n",
      "Epoch 20/20, Train Loss: 2.107Train Acc: 0.226\n",
      "Finished 45 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.12877263581488935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 2.260Train Acc: 0.154\n",
      "Epoch 2/10, Train Loss: 2.059Train Acc: 0.281\n",
      "Epoch 3/10, Train Loss: 1.889Train Acc: 0.371\n",
      "Epoch 4/10, Train Loss: 1.764Train Acc: 0.427\n",
      "Epoch 5/10, Train Loss: 1.663Train Acc: 0.459\n",
      "Epoch 6/10, Train Loss: 1.592Train Acc: 0.484\n",
      "Epoch 7/10, Train Loss: 1.503Train Acc: 0.521\n",
      "Epoch 8/10, Train Loss: 1.449Train Acc: 0.543\n",
      "Epoch 9/10, Train Loss: 1.383Train Acc: 0.563\n",
      "Epoch 10/10, Train Loss: 1.326Train Acc: 0.585\n",
      "Finished 46 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.19114688128772636\n",
      "Epoch 1/50, Train Loss: 2.335Train Acc: 0.088\n",
      "Epoch 2/50, Train Loss: 2.332Train Acc: 0.106\n",
      "Epoch 3/50, Train Loss: 2.345Train Acc: 0.100\n",
      "Epoch 4/50, Train Loss: 2.333Train Acc: 0.096\n",
      "Epoch 5/50, Train Loss: 2.345Train Acc: 0.095\n",
      "Epoch 6/50, Train Loss: 2.351Train Acc: 0.092\n",
      "Epoch 7/50, Train Loss: 2.336Train Acc: 0.104\n",
      "Epoch 8/50, Train Loss: 2.348Train Acc: 0.094\n",
      "Epoch 9/50, Train Loss: 2.334Train Acc: 0.097\n",
      "Epoch 10/50, Train Loss: 2.336Train Acc: 0.099\n",
      "Epoch 11/50, Train Loss: 2.337Train Acc: 0.104\n",
      "Epoch 12/50, Train Loss: 2.339Train Acc: 0.095\n",
      "Epoch 13/50, Train Loss: 2.354Train Acc: 0.098\n",
      "Epoch 14/50, Train Loss: 2.352Train Acc: 0.090\n",
      "Epoch 15/50, Train Loss: 2.341Train Acc: 0.109\n",
      "Epoch 16/50, Train Loss: 2.338Train Acc: 0.088\n",
      "Epoch 17/50, Train Loss: 2.349Train Acc: 0.092\n",
      "Epoch 18/50, Train Loss: 2.340Train Acc: 0.099\n",
      "Epoch 19/50, Train Loss: 2.339Train Acc: 0.099\n",
      "Epoch 20/50, Train Loss: 2.350Train Acc: 0.100\n",
      "Epoch 21/50, Train Loss: 2.344Train Acc: 0.092\n",
      "Epoch 22/50, Train Loss: 2.334Train Acc: 0.105\n",
      "Epoch 23/50, Train Loss: 2.349Train Acc: 0.102\n",
      "Epoch 24/50, Train Loss: 2.343Train Acc: 0.097\n",
      "Epoch 25/50, Train Loss: 2.341Train Acc: 0.084\n",
      "Epoch 26/50, Train Loss: 2.363Train Acc: 0.092\n",
      "Epoch 27/50, Train Loss: 2.344Train Acc: 0.097\n",
      "Epoch 28/50, Train Loss: 2.348Train Acc: 0.098\n",
      "Epoch 29/50, Train Loss: 2.344Train Acc: 0.097\n",
      "Epoch 30/50, Train Loss: 2.347Train Acc: 0.098\n",
      "Epoch 31/50, Train Loss: 2.340Train Acc: 0.108\n",
      "Epoch 32/50, Train Loss: 2.336Train Acc: 0.104\n",
      "Epoch 33/50, Train Loss: 2.344Train Acc: 0.089\n",
      "Epoch 34/50, Train Loss: 2.350Train Acc: 0.084\n",
      "Epoch 35/50, Train Loss: 2.344Train Acc: 0.090\n",
      "Epoch 36/50, Train Loss: 2.348Train Acc: 0.097\n",
      "Epoch 37/50, Train Loss: 2.352Train Acc: 0.090\n",
      "Epoch 38/50, Train Loss: 2.348Train Acc: 0.091\n",
      "Epoch 39/50, Train Loss: 2.367Train Acc: 0.101\n",
      "Epoch 40/50, Train Loss: 2.351Train Acc: 0.102\n",
      "Epoch 41/50, Train Loss: 2.361Train Acc: 0.099\n",
      "Epoch 42/50, Train Loss: 2.341Train Acc: 0.089\n",
      "Epoch 43/50, Train Loss: 2.345Train Acc: 0.095\n",
      "Epoch 44/50, Train Loss: 2.358Train Acc: 0.085\n",
      "Epoch 45/50, Train Loss: 2.350Train Acc: 0.089\n",
      "Epoch 46/50, Train Loss: 2.361Train Acc: 0.099\n",
      "Epoch 47/50, Train Loss: 2.358Train Acc: 0.101\n",
      "Epoch 48/50, Train Loss: 2.344Train Acc: 0.097\n",
      "Epoch 49/50, Train Loss: 2.349Train Acc: 0.097\n",
      "Epoch 50/50, Train Loss: 2.341Train Acc: 0.095\n",
      "Finished 47 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.0925553319919517\n",
      "Epoch 1/20, Train Loss: 2.345Train Acc: 0.127\n",
      "Epoch 2/20, Train Loss: 2.349Train Acc: 0.128\n",
      "Epoch 3/20, Train Loss: 2.317Train Acc: 0.136\n",
      "Epoch 4/20, Train Loss: 2.331Train Acc: 0.148\n",
      "Epoch 5/20, Train Loss: 2.348Train Acc: 0.124\n",
      "Epoch 6/20, Train Loss: 2.345Train Acc: 0.130\n",
      "Epoch 7/20, Train Loss: 2.362Train Acc: 0.130\n",
      "Epoch 8/20, Train Loss: 2.331Train Acc: 0.133\n",
      "Epoch 9/20, Train Loss: 2.314Train Acc: 0.156\n",
      "Epoch 10/20, Train Loss: 2.341Train Acc: 0.138\n",
      "Epoch 11/20, Train Loss: 2.303Train Acc: 0.146\n",
      "Epoch 12/20, Train Loss: 2.359Train Acc: 0.136\n",
      "Epoch 13/20, Train Loss: 2.410Train Acc: 0.095\n",
      "Epoch 14/20, Train Loss: 2.368Train Acc: 0.105\n",
      "Epoch 15/20, Train Loss: 2.409Train Acc: 0.093\n",
      "Epoch 16/20, Train Loss: 2.346Train Acc: 0.104\n",
      "Epoch 17/20, Train Loss: 2.332Train Acc: 0.126\n",
      "Epoch 18/20, Train Loss: 2.347Train Acc: 0.112\n",
      "Epoch 19/20, Train Loss: 2.343Train Acc: 0.126\n",
      "Epoch 20/20, Train Loss: 2.330Train Acc: 0.121\n",
      "Finished 48 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.11670020120724346\n",
      "Epoch 1/10, Train Loss: 1.920Train Acc: 0.302\n",
      "Epoch 2/10, Train Loss: 1.627Train Acc: 0.449\n",
      "Epoch 3/10, Train Loss: 1.363Train Acc: 0.534\n",
      "Epoch 4/10, Train Loss: 1.239Train Acc: 0.597\n",
      "Epoch 5/10, Train Loss: 1.091Train Acc: 0.659\n",
      "Epoch 6/10, Train Loss: 1.030Train Acc: 0.678\n",
      "Epoch 7/10, Train Loss: 1.141Train Acc: 0.626\n",
      "Epoch 8/10, Train Loss: 1.065Train Acc: 0.644\n",
      "Epoch 9/10, Train Loss: 1.001Train Acc: 0.684\n",
      "Epoch 10/10, Train Loss: 1.096Train Acc: 0.634\n",
      "Finished 49 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.2535211267605634\n",
      "Epoch 1/50, Train Loss: 1.945Train Acc: 0.307\n",
      "Epoch 2/50, Train Loss: 1.679Train Acc: 0.428\n",
      "Epoch 3/50, Train Loss: 1.463Train Acc: 0.526\n",
      "Epoch 4/50, Train Loss: 1.385Train Acc: 0.538\n",
      "Epoch 5/50, Train Loss: 1.347Train Acc: 0.550\n",
      "Epoch 6/50, Train Loss: 1.294Train Acc: 0.573\n",
      "Epoch 7/50, Train Loss: 1.315Train Acc: 0.545\n",
      "Epoch 8/50, Train Loss: 1.255Train Acc: 0.586\n",
      "Epoch 9/50, Train Loss: 1.233Train Acc: 0.595\n",
      "Epoch 10/50, Train Loss: 1.246Train Acc: 0.584\n",
      "Epoch 11/50, Train Loss: 1.248Train Acc: 0.583\n",
      "Epoch 12/50, Train Loss: 1.197Train Acc: 0.608\n",
      "Epoch 13/50, Train Loss: 1.297Train Acc: 0.554\n",
      "Epoch 14/50, Train Loss: 1.218Train Acc: 0.591\n",
      "Epoch 15/50, Train Loss: 1.382Train Acc: 0.553\n",
      "Epoch 16/50, Train Loss: 1.365Train Acc: 0.540\n",
      "Epoch 17/50, Train Loss: 1.454Train Acc: 0.526\n",
      "Epoch 18/50, Train Loss: 1.356Train Acc: 0.548\n",
      "Epoch 19/50, Train Loss: 1.253Train Acc: 0.577\n",
      "Epoch 20/50, Train Loss: 1.334Train Acc: 0.552\n",
      "Epoch 21/50, Train Loss: 1.222Train Acc: 0.609\n",
      "Epoch 22/50, Train Loss: 1.385Train Acc: 0.540\n",
      "Epoch 23/50, Train Loss: 1.370Train Acc: 0.557\n",
      "Epoch 24/50, Train Loss: 1.343Train Acc: 0.555\n",
      "Epoch 25/50, Train Loss: 1.318Train Acc: 0.568\n",
      "Epoch 26/50, Train Loss: 1.427Train Acc: 0.508\n",
      "Epoch 27/50, Train Loss: 1.338Train Acc: 0.549\n",
      "Epoch 28/50, Train Loss: 1.408Train Acc: 0.545\n",
      "Epoch 29/50, Train Loss: 1.510Train Acc: 0.506\n",
      "Epoch 30/50, Train Loss: 1.477Train Acc: 0.491\n",
      "Epoch 31/50, Train Loss: 1.457Train Acc: 0.507\n",
      "Epoch 32/50, Train Loss: 1.412Train Acc: 0.521\n",
      "Epoch 33/50, Train Loss: 1.386Train Acc: 0.526\n",
      "Epoch 34/50, Train Loss: 1.358Train Acc: 0.535\n",
      "Epoch 35/50, Train Loss: 1.365Train Acc: 0.535\n",
      "Epoch 36/50, Train Loss: 1.333Train Acc: 0.535\n",
      "Epoch 37/50, Train Loss: 1.586Train Acc: 0.461\n",
      "Epoch 38/50, Train Loss: 1.495Train Acc: 0.473\n",
      "Epoch 39/50, Train Loss: 1.462Train Acc: 0.498\n",
      "Epoch 40/50, Train Loss: 1.341Train Acc: 0.534\n",
      "Epoch 41/50, Train Loss: 1.315Train Acc: 0.552\n",
      "Epoch 42/50, Train Loss: 1.353Train Acc: 0.538\n",
      "Epoch 43/50, Train Loss: 1.372Train Acc: 0.524\n",
      "Epoch 44/50, Train Loss: 1.366Train Acc: 0.532\n",
      "Epoch 45/50, Train Loss: 1.338Train Acc: 0.535\n",
      "Epoch 46/50, Train Loss: 1.336Train Acc: 0.548\n",
      "Epoch 47/50, Train Loss: 1.330Train Acc: 0.538\n",
      "Epoch 48/50, Train Loss: 1.383Train Acc: 0.512\n",
      "Epoch 49/50, Train Loss: 1.420Train Acc: 0.520\n",
      "Epoch 50/50, Train Loss: 1.416Train Acc: 0.522\n",
      "Finished 50 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.1750503018108652\n",
      "Epoch 1/10, Train Loss: 2.381Train Acc: 0.121\n",
      "Epoch 2/10, Train Loss: 2.142Train Acc: 0.234\n",
      "Epoch 3/10, Train Loss: 1.860Train Acc: 0.330\n",
      "Epoch 4/10, Train Loss: 2.083Train Acc: 0.235\n",
      "Epoch 5/10, Train Loss: 2.100Train Acc: 0.234\n",
      "Epoch 6/10, Train Loss: 2.028Train Acc: 0.241\n",
      "Epoch 7/10, Train Loss: 2.020Train Acc: 0.239\n",
      "Epoch 8/10, Train Loss: 1.954Train Acc: 0.268\n",
      "Epoch 9/10, Train Loss: 1.959Train Acc: 0.252\n",
      "Epoch 10/10, Train Loss: 1.920Train Acc: 0.288\n",
      "Finished 51 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.10865191146881288\n",
      "Epoch 1/50, Train Loss: 2.337Train Acc: 0.095\n",
      "Epoch 2/50, Train Loss: 2.322Train Acc: 0.103\n",
      "Epoch 3/50, Train Loss: 2.326Train Acc: 0.095\n",
      "Epoch 4/50, Train Loss: 2.318Train Acc: 0.101\n",
      "Epoch 5/50, Train Loss: 2.321Train Acc: 0.096\n",
      "Epoch 6/50, Train Loss: 2.319Train Acc: 0.090\n",
      "Epoch 7/50, Train Loss: 2.317Train Acc: 0.097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Train Loss: 2.331Train Acc: 0.097\n",
      "Epoch 9/50, Train Loss: 2.323Train Acc: 0.103\n",
      "Epoch 10/50, Train Loss: 2.317Train Acc: 0.101\n",
      "Epoch 11/50, Train Loss: 2.332Train Acc: 0.089\n",
      "Epoch 12/50, Train Loss: 2.326Train Acc: 0.091\n",
      "Epoch 13/50, Train Loss: 2.320Train Acc: 0.108\n",
      "Epoch 14/50, Train Loss: 2.334Train Acc: 0.081\n",
      "Epoch 15/50, Train Loss: 2.321Train Acc: 0.098\n",
      "Epoch 16/50, Train Loss: 2.331Train Acc: 0.101\n",
      "Epoch 17/50, Train Loss: 2.323Train Acc: 0.102\n",
      "Epoch 18/50, Train Loss: 2.323Train Acc: 0.105\n",
      "Epoch 19/50, Train Loss: 2.328Train Acc: 0.094\n",
      "Epoch 20/50, Train Loss: 2.326Train Acc: 0.105\n",
      "Epoch 21/50, Train Loss: 2.309Train Acc: 0.104\n",
      "Epoch 22/50, Train Loss: 2.315Train Acc: 0.109\n",
      "Epoch 23/50, Train Loss: 2.311Train Acc: 0.113\n",
      "Epoch 24/50, Train Loss: 2.330Train Acc: 0.090\n",
      "Epoch 25/50, Train Loss: 2.323Train Acc: 0.108\n",
      "Epoch 26/50, Train Loss: 2.322Train Acc: 0.105\n",
      "Epoch 27/50, Train Loss: 2.320Train Acc: 0.108\n",
      "Epoch 28/50, Train Loss: 2.327Train Acc: 0.089\n",
      "Epoch 29/50, Train Loss: 2.322Train Acc: 0.107\n",
      "Epoch 30/50, Train Loss: 2.335Train Acc: 0.108\n",
      "Epoch 31/50, Train Loss: 2.328Train Acc: 0.100\n",
      "Epoch 32/50, Train Loss: 2.329Train Acc: 0.092\n",
      "Epoch 33/50, Train Loss: 2.321Train Acc: 0.102\n",
      "Epoch 34/50, Train Loss: 2.325Train Acc: 0.106\n",
      "Epoch 35/50, Train Loss: 2.327Train Acc: 0.088\n",
      "Epoch 36/50, Train Loss: 2.332Train Acc: 0.108\n",
      "Epoch 37/50, Train Loss: 2.324Train Acc: 0.113\n",
      "Epoch 38/50, Train Loss: 2.334Train Acc: 0.098\n",
      "Epoch 39/50, Train Loss: 2.331Train Acc: 0.108\n",
      "Epoch 40/50, Train Loss: 2.319Train Acc: 0.106\n",
      "Epoch 41/50, Train Loss: 2.333Train Acc: 0.100\n",
      "Epoch 42/50, Train Loss: 2.324Train Acc: 0.098\n",
      "Epoch 43/50, Train Loss: 2.310Train Acc: 0.112\n",
      "Epoch 44/50, Train Loss: 2.300Train Acc: 0.127\n",
      "Epoch 45/50, Train Loss: 2.310Train Acc: 0.110\n",
      "Epoch 46/50, Train Loss: 2.313Train Acc: 0.119\n",
      "Epoch 47/50, Train Loss: 2.306Train Acc: 0.098\n",
      "Epoch 48/50, Train Loss: 2.316Train Acc: 0.109\n",
      "Epoch 49/50, Train Loss: 2.311Train Acc: 0.115\n",
      "Epoch 50/50, Train Loss: 2.308Train Acc: 0.108\n",
      "Finished 52 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.12072434607645875\n",
      "Epoch 1/10, Train Loss: 2.315Train Acc: 0.096\n",
      "Epoch 2/10, Train Loss: 2.307Train Acc: 0.105\n",
      "Epoch 3/10, Train Loss: 2.308Train Acc: 0.103\n",
      "Epoch 4/10, Train Loss: 2.307Train Acc: 0.092\n",
      "Epoch 5/10, Train Loss: 2.303Train Acc: 0.109\n",
      "Epoch 6/10, Train Loss: 2.306Train Acc: 0.091\n",
      "Epoch 7/10, Train Loss: 2.308Train Acc: 0.087\n",
      "Epoch 8/10, Train Loss: 2.306Train Acc: 0.086\n",
      "Epoch 9/10, Train Loss: 2.304Train Acc: 0.101\n",
      "Epoch 10/10, Train Loss: 2.307Train Acc: 0.088\n",
      "Finished 53 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.1006036217303823\n",
      "Epoch 1/20, Train Loss: 2.306Train Acc: 0.103\n",
      "Epoch 2/20, Train Loss: 2.038Train Acc: 0.253\n",
      "Epoch 3/20, Train Loss: 1.748Train Acc: 0.389\n",
      "Epoch 4/20, Train Loss: 1.524Train Acc: 0.498\n",
      "Epoch 5/20, Train Loss: 1.359Train Acc: 0.552\n",
      "Epoch 6/20, Train Loss: 1.306Train Acc: 0.577\n",
      "Epoch 7/20, Train Loss: 1.174Train Acc: 0.614\n",
      "Epoch 8/20, Train Loss: 1.123Train Acc: 0.640\n",
      "Epoch 9/20, Train Loss: 1.087Train Acc: 0.646\n",
      "Epoch 10/20, Train Loss: 1.066Train Acc: 0.646\n",
      "Epoch 11/20, Train Loss: 0.994Train Acc: 0.675\n",
      "Epoch 12/20, Train Loss: 0.948Train Acc: 0.689\n",
      "Epoch 13/20, Train Loss: 0.904Train Acc: 0.711\n",
      "Epoch 14/20, Train Loss: 0.891Train Acc: 0.720\n",
      "Epoch 15/20, Train Loss: 0.806Train Acc: 0.746\n",
      "Epoch 16/20, Train Loss: 0.805Train Acc: 0.747\n",
      "Epoch 17/20, Train Loss: 0.834Train Acc: 0.725\n",
      "Epoch 18/20, Train Loss: 0.828Train Acc: 0.721\n",
      "Epoch 19/20, Train Loss: 0.738Train Acc: 0.768\n",
      "Epoch 20/20, Train Loss: 0.790Train Acc: 0.734\n",
      "Finished 54 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.3641851106639839\n",
      "Epoch 1/50, Train Loss: 2.320Train Acc: 0.093\n",
      "Epoch 2/50, Train Loss: 2.313Train Acc: 0.099\n",
      "Epoch 3/50, Train Loss: 2.316Train Acc: 0.092\n",
      "Epoch 4/50, Train Loss: 2.309Train Acc: 0.102\n",
      "Epoch 5/50, Train Loss: 2.309Train Acc: 0.101\n",
      "Epoch 6/50, Train Loss: 2.307Train Acc: 0.107\n",
      "Epoch 7/50, Train Loss: 2.308Train Acc: 0.099\n",
      "Epoch 8/50, Train Loss: 2.309Train Acc: 0.108\n",
      "Epoch 9/50, Train Loss: 2.309Train Acc: 0.100\n",
      "Epoch 10/50, Train Loss: 2.311Train Acc: 0.085\n",
      "Epoch 11/50, Train Loss: 2.310Train Acc: 0.097\n",
      "Epoch 12/50, Train Loss: 2.307Train Acc: 0.103\n",
      "Epoch 13/50, Train Loss: 2.307Train Acc: 0.098\n",
      "Epoch 14/50, Train Loss: 2.307Train Acc: 0.097\n",
      "Epoch 15/50, Train Loss: 2.308Train Acc: 0.100\n",
      "Epoch 16/50, Train Loss: 2.307Train Acc: 0.095\n",
      "Epoch 17/50, Train Loss: 2.311Train Acc: 0.079\n",
      "Epoch 18/50, Train Loss: 2.307Train Acc: 0.093\n",
      "Epoch 19/50, Train Loss: 2.307Train Acc: 0.098\n",
      "Epoch 20/50, Train Loss: 2.305Train Acc: 0.093\n",
      "Epoch 21/50, Train Loss: 2.307Train Acc: 0.102\n",
      "Epoch 22/50, Train Loss: 2.305Train Acc: 0.092\n",
      "Epoch 23/50, Train Loss: 2.307Train Acc: 0.096\n",
      "Epoch 24/50, Train Loss: 2.307Train Acc: 0.095\n",
      "Epoch 25/50, Train Loss: 2.306Train Acc: 0.089\n",
      "Epoch 26/50, Train Loss: 2.305Train Acc: 0.101\n",
      "Epoch 27/50, Train Loss: 2.307Train Acc: 0.090\n",
      "Epoch 28/50, Train Loss: 2.306Train Acc: 0.096\n",
      "Epoch 29/50, Train Loss: 2.309Train Acc: 0.089\n",
      "Epoch 30/50, Train Loss: 2.306Train Acc: 0.098\n",
      "Epoch 31/50, Train Loss: 2.306Train Acc: 0.102\n",
      "Epoch 32/50, Train Loss: 2.303Train Acc: 0.110\n",
      "Epoch 33/50, Train Loss: 2.306Train Acc: 0.095\n",
      "Epoch 34/50, Train Loss: 2.304Train Acc: 0.097\n",
      "Epoch 35/50, Train Loss: 2.305Train Acc: 0.105\n",
      "Epoch 36/50, Train Loss: 2.305Train Acc: 0.112\n",
      "Epoch 37/50, Train Loss: 2.304Train Acc: 0.102\n",
      "Epoch 38/50, Train Loss: 2.305Train Acc: 0.101\n",
      "Epoch 39/50, Train Loss: 2.307Train Acc: 0.098\n",
      "Epoch 40/50, Train Loss: 2.305Train Acc: 0.102\n",
      "Epoch 41/50, Train Loss: 2.306Train Acc: 0.093\n",
      "Epoch 42/50, Train Loss: 2.309Train Acc: 0.090\n",
      "Epoch 43/50, Train Loss: 2.304Train Acc: 0.091\n",
      "Epoch 44/50, Train Loss: 2.305Train Acc: 0.095\n",
      "Epoch 45/50, Train Loss: 2.307Train Acc: 0.081\n",
      "Epoch 46/50, Train Loss: 2.308Train Acc: 0.096\n",
      "Epoch 47/50, Train Loss: 2.305Train Acc: 0.091\n",
      "Epoch 48/50, Train Loss: 2.304Train Acc: 0.121\n",
      "Epoch 49/50, Train Loss: 2.305Train Acc: 0.102\n",
      "Epoch 50/50, Train Loss: 2.305Train Acc: 0.102\n",
      "Finished 55 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.1006036217303823\n",
      "Epoch 1/20, Train Loss: 1.913Train Acc: 0.308\n",
      "Epoch 2/20, Train Loss: 1.613Train Acc: 0.461\n",
      "Epoch 3/20, Train Loss: 1.446Train Acc: 0.508\n",
      "Epoch 4/20, Train Loss: 1.256Train Acc: 0.594\n",
      "Epoch 5/20, Train Loss: 1.159Train Acc: 0.637\n",
      "Epoch 6/20, Train Loss: 1.073Train Acc: 0.674\n",
      "Epoch 7/20, Train Loss: 1.005Train Acc: 0.690\n",
      "Epoch 8/20, Train Loss: 0.959Train Acc: 0.709\n",
      "Epoch 9/20, Train Loss: 0.977Train Acc: 0.693\n",
      "Epoch 10/20, Train Loss: 0.926Train Acc: 0.717\n",
      "Epoch 11/20, Train Loss: 0.962Train Acc: 0.696\n",
      "Epoch 12/20, Train Loss: 0.970Train Acc: 0.698\n",
      "Epoch 13/20, Train Loss: 0.918Train Acc: 0.715\n",
      "Epoch 14/20, Train Loss: 0.864Train Acc: 0.728\n",
      "Epoch 15/20, Train Loss: 0.871Train Acc: 0.725\n",
      "Epoch 16/20, Train Loss: 0.916Train Acc: 0.712\n",
      "Epoch 17/20, Train Loss: 0.878Train Acc: 0.710\n",
      "Epoch 18/20, Train Loss: 0.970Train Acc: 0.682\n",
      "Epoch 19/20, Train Loss: 0.896Train Acc: 0.712\n",
      "Epoch 20/20, Train Loss: 0.926Train Acc: 0.703\n",
      "Finished 56 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.2575452716297787\n",
      "Epoch 1/20, Train Loss: 2.179Train Acc: 0.189\n",
      "Epoch 2/20, Train Loss: 1.912Train Acc: 0.330\n",
      "Epoch 3/20, Train Loss: 1.760Train Acc: 0.406\n",
      "Epoch 4/20, Train Loss: 1.620Train Acc: 0.461\n",
      "Epoch 5/20, Train Loss: 1.480Train Acc: 0.508\n",
      "Epoch 6/20, Train Loss: 1.371Train Acc: 0.564\n",
      "Epoch 7/20, Train Loss: 1.269Train Acc: 0.603\n",
      "Epoch 8/20, Train Loss: 1.170Train Acc: 0.644\n",
      "Epoch 9/20, Train Loss: 1.067Train Acc: 0.678\n",
      "Epoch 10/20, Train Loss: 0.978Train Acc: 0.707\n",
      "Epoch 11/20, Train Loss: 0.911Train Acc: 0.721\n",
      "Epoch 12/20, Train Loss: 0.851Train Acc: 0.739\n",
      "Epoch 13/20, Train Loss: 0.794Train Acc: 0.761\n",
      "Epoch 14/20, Train Loss: 0.733Train Acc: 0.781\n",
      "Epoch 15/20, Train Loss: 0.718Train Acc: 0.783\n",
      "Epoch 16/20, Train Loss: 0.668Train Acc: 0.799\n",
      "Epoch 17/20, Train Loss: 0.626Train Acc: 0.817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Train Loss: 0.625Train Acc: 0.811\n",
      "Epoch 19/20, Train Loss: 0.590Train Acc: 0.816\n",
      "Epoch 20/20, Train Loss: 0.567Train Acc: 0.823\n",
      "Finished 57 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.358148893360161\n",
      "Epoch 1/50, Train Loss: 2.306Train Acc: 0.104\n",
      "Epoch 2/50, Train Loss: 2.188Train Acc: 0.203\n",
      "Epoch 3/50, Train Loss: 1.965Train Acc: 0.312\n",
      "Epoch 4/50, Train Loss: 1.762Train Acc: 0.405\n",
      "Epoch 5/50, Train Loss: 1.605Train Acc: 0.468\n",
      "Epoch 6/50, Train Loss: 1.501Train Acc: 0.499\n",
      "Epoch 7/50, Train Loss: 1.451Train Acc: 0.516\n",
      "Epoch 8/50, Train Loss: 1.374Train Acc: 0.544\n",
      "Epoch 9/50, Train Loss: 1.315Train Acc: 0.562\n",
      "Epoch 10/50, Train Loss: 1.239Train Acc: 0.602\n",
      "Epoch 11/50, Train Loss: 1.189Train Acc: 0.619\n",
      "Epoch 12/50, Train Loss: 1.139Train Acc: 0.630\n",
      "Epoch 13/50, Train Loss: 1.111Train Acc: 0.653\n",
      "Epoch 14/50, Train Loss: 1.070Train Acc: 0.652\n",
      "Epoch 15/50, Train Loss: 1.044Train Acc: 0.664\n",
      "Epoch 16/50, Train Loss: 1.031Train Acc: 0.667\n",
      "Epoch 17/50, Train Loss: 0.999Train Acc: 0.685\n",
      "Epoch 18/50, Train Loss: 0.981Train Acc: 0.682\n",
      "Epoch 19/50, Train Loss: 0.960Train Acc: 0.702\n",
      "Epoch 20/50, Train Loss: 0.941Train Acc: 0.707\n",
      "Epoch 21/50, Train Loss: 0.902Train Acc: 0.721\n",
      "Epoch 22/50, Train Loss: 0.901Train Acc: 0.704\n",
      "Epoch 23/50, Train Loss: 0.866Train Acc: 0.721\n",
      "Epoch 24/50, Train Loss: 0.871Train Acc: 0.718\n",
      "Epoch 25/50, Train Loss: 0.832Train Acc: 0.734\n",
      "Epoch 26/50, Train Loss: 0.803Train Acc: 0.747\n",
      "Epoch 27/50, Train Loss: 0.810Train Acc: 0.751\n",
      "Epoch 28/50, Train Loss: 0.776Train Acc: 0.757\n",
      "Epoch 29/50, Train Loss: 0.773Train Acc: 0.764\n",
      "Epoch 30/50, Train Loss: 0.764Train Acc: 0.760\n",
      "Epoch 31/50, Train Loss: 0.742Train Acc: 0.768\n",
      "Epoch 32/50, Train Loss: 0.722Train Acc: 0.781\n",
      "Epoch 33/50, Train Loss: 0.721Train Acc: 0.772\n",
      "Epoch 34/50, Train Loss: 0.708Train Acc: 0.779\n",
      "Epoch 35/50, Train Loss: 0.705Train Acc: 0.778\n",
      "Epoch 36/50, Train Loss: 0.684Train Acc: 0.790\n",
      "Epoch 37/50, Train Loss: 0.703Train Acc: 0.776\n",
      "Epoch 38/50, Train Loss: 0.694Train Acc: 0.779\n",
      "Epoch 39/50, Train Loss: 0.682Train Acc: 0.784\n",
      "Epoch 40/50, Train Loss: 0.655Train Acc: 0.798\n",
      "Epoch 41/50, Train Loss: 0.641Train Acc: 0.802\n",
      "Epoch 42/50, Train Loss: 0.635Train Acc: 0.799\n",
      "Epoch 43/50, Train Loss: 0.633Train Acc: 0.808\n",
      "Epoch 44/50, Train Loss: 0.593Train Acc: 0.818\n",
      "Epoch 45/50, Train Loss: 0.635Train Acc: 0.805\n",
      "Epoch 46/50, Train Loss: 0.624Train Acc: 0.803\n",
      "Epoch 47/50, Train Loss: 0.601Train Acc: 0.817\n",
      "Epoch 48/50, Train Loss: 0.634Train Acc: 0.799\n",
      "Epoch 49/50, Train Loss: 0.605Train Acc: 0.814\n",
      "Epoch 50/50, Train Loss: 0.584Train Acc: 0.822\n",
      "Finished 58 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.3319919517102616\n",
      "Epoch 1/10, Train Loss: 2.352Train Acc: 0.100\n",
      "Epoch 2/10, Train Loss: 2.342Train Acc: 0.107\n",
      "Epoch 3/10, Train Loss: 2.257Train Acc: 0.160\n",
      "Epoch 4/10, Train Loss: 2.192Train Acc: 0.173\n",
      "Epoch 5/10, Train Loss: 2.222Train Acc: 0.171\n",
      "Epoch 6/10, Train Loss: 2.243Train Acc: 0.163\n",
      "Epoch 7/10, Train Loss: 2.345Train Acc: 0.117\n",
      "Epoch 8/10, Train Loss: 2.286Train Acc: 0.127\n",
      "Epoch 9/10, Train Loss: 2.326Train Acc: 0.128\n",
      "Epoch 10/10, Train Loss: 2.337Train Acc: 0.115\n",
      "Finished 59 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.07243460764587525\n",
      "Epoch 1/20, Train Loss: 2.101Train Acc: 0.239\n",
      "Epoch 2/20, Train Loss: 1.684Train Acc: 0.466\n",
      "Epoch 3/20, Train Loss: 1.324Train Acc: 0.604\n",
      "Epoch 4/20, Train Loss: 1.091Train Acc: 0.692\n",
      "Epoch 5/20, Train Loss: 0.922Train Acc: 0.742\n",
      "Epoch 6/20, Train Loss: 0.807Train Acc: 0.777\n",
      "Epoch 7/20, Train Loss: 0.720Train Acc: 0.797\n",
      "Epoch 8/20, Train Loss: 0.675Train Acc: 0.808\n",
      "Epoch 9/20, Train Loss: 0.595Train Acc: 0.833\n",
      "Epoch 10/20, Train Loss: 0.553Train Acc: 0.840\n",
      "Epoch 11/20, Train Loss: 0.519Train Acc: 0.842\n",
      "Epoch 12/20, Train Loss: 0.481Train Acc: 0.863\n",
      "Epoch 13/20, Train Loss: 0.455Train Acc: 0.867\n",
      "Epoch 14/20, Train Loss: 0.413Train Acc: 0.883\n",
      "Epoch 15/20, Train Loss: 0.377Train Acc: 0.892\n",
      "Epoch 16/20, Train Loss: 0.371Train Acc: 0.890\n",
      "Epoch 17/20, Train Loss: 0.342Train Acc: 0.899\n",
      "Epoch 18/20, Train Loss: 0.324Train Acc: 0.908\n",
      "Epoch 19/20, Train Loss: 0.298Train Acc: 0.913\n",
      "Epoch 20/20, Train Loss: 0.287Train Acc: 0.913\n",
      "Finished 60 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.40643863179074446\n",
      "Epoch 1/20, Train Loss: 2.309Train Acc: 0.096\n",
      "Epoch 2/20, Train Loss: 2.308Train Acc: 0.093\n",
      "Epoch 3/20, Train Loss: 2.307Train Acc: 0.089\n",
      "Epoch 4/20, Train Loss: 2.310Train Acc: 0.096\n",
      "Epoch 5/20, Train Loss: 2.307Train Acc: 0.092\n",
      "Epoch 6/20, Train Loss: 2.306Train Acc: 0.090\n",
      "Epoch 7/20, Train Loss: 2.249Train Acc: 0.140\n",
      "Epoch 8/20, Train Loss: 2.165Train Acc: 0.179\n",
      "Epoch 9/20, Train Loss: 2.130Train Acc: 0.172\n",
      "Epoch 10/20, Train Loss: 2.097Train Acc: 0.198\n",
      "Epoch 11/20, Train Loss: 2.083Train Acc: 0.211\n",
      "Epoch 12/20, Train Loss: 2.066Train Acc: 0.213\n",
      "Epoch 13/20, Train Loss: 2.045Train Acc: 0.216\n",
      "Epoch 14/20, Train Loss: 2.051Train Acc: 0.206\n",
      "Epoch 15/20, Train Loss: 2.022Train Acc: 0.227\n",
      "Epoch 16/20, Train Loss: 2.038Train Acc: 0.225\n",
      "Epoch 17/20, Train Loss: 2.025Train Acc: 0.242\n",
      "Epoch 18/20, Train Loss: 1.949Train Acc: 0.245\n",
      "Epoch 19/20, Train Loss: 1.906Train Acc: 0.297\n",
      "Epoch 20/20, Train Loss: 1.863Train Acc: 0.301\n",
      "Finished 61 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.16700201207243462\n",
      "Epoch 1/50, Train Loss: 2.361Train Acc: 0.105\n",
      "Epoch 2/50, Train Loss: 2.341Train Acc: 0.121\n",
      "Epoch 3/50, Train Loss: 2.339Train Acc: 0.110\n",
      "Epoch 4/50, Train Loss: 2.348Train Acc: 0.113\n",
      "Epoch 5/50, Train Loss: 2.337Train Acc: 0.102\n",
      "Epoch 6/50, Train Loss: 2.339Train Acc: 0.115\n",
      "Epoch 7/50, Train Loss: 2.343Train Acc: 0.117\n",
      "Epoch 8/50, Train Loss: 2.348Train Acc: 0.107\n",
      "Epoch 9/50, Train Loss: 2.352Train Acc: 0.108\n",
      "Epoch 10/50, Train Loss: 2.349Train Acc: 0.105\n",
      "Epoch 11/50, Train Loss: 2.339Train Acc: 0.120\n",
      "Epoch 12/50, Train Loss: 2.347Train Acc: 0.107\n",
      "Epoch 13/50, Train Loss: 2.350Train Acc: 0.101\n",
      "Epoch 14/50, Train Loss: 2.350Train Acc: 0.101\n",
      "Epoch 15/50, Train Loss: 2.342Train Acc: 0.112\n",
      "Epoch 16/50, Train Loss: 2.349Train Acc: 0.110\n",
      "Epoch 17/50, Train Loss: 2.360Train Acc: 0.108\n",
      "Epoch 18/50, Train Loss: 2.367Train Acc: 0.102\n",
      "Epoch 19/50, Train Loss: 2.353Train Acc: 0.096\n",
      "Epoch 20/50, Train Loss: 2.363Train Acc: 0.098\n",
      "Epoch 21/50, Train Loss: 2.355Train Acc: 0.097\n",
      "Epoch 22/50, Train Loss: 2.359Train Acc: 0.097\n",
      "Epoch 23/50, Train Loss: 2.362Train Acc: 0.106\n",
      "Epoch 24/50, Train Loss: 2.361Train Acc: 0.104\n",
      "Epoch 25/50, Train Loss: 2.385Train Acc: 0.106\n",
      "Epoch 26/50, Train Loss: 2.388Train Acc: 0.096\n",
      "Epoch 27/50, Train Loss: 2.379Train Acc: 0.101\n",
      "Epoch 28/50, Train Loss: 2.343Train Acc: 0.136\n",
      "Epoch 29/50, Train Loss: 2.301Train Acc: 0.145\n",
      "Epoch 30/50, Train Loss: 2.277Train Acc: 0.129\n",
      "Epoch 31/50, Train Loss: 2.303Train Acc: 0.140\n",
      "Epoch 32/50, Train Loss: 2.372Train Acc: 0.106\n",
      "Epoch 33/50, Train Loss: 2.366Train Acc: 0.085\n",
      "Epoch 34/50, Train Loss: 2.364Train Acc: 0.093\n",
      "Epoch 35/50, Train Loss: 2.360Train Acc: 0.105\n",
      "Epoch 36/50, Train Loss: 2.364Train Acc: 0.113\n",
      "Epoch 37/50, Train Loss: 2.352Train Acc: 0.105\n",
      "Epoch 38/50, Train Loss: 2.335Train Acc: 0.114\n",
      "Epoch 39/50, Train Loss: 2.322Train Acc: 0.124\n",
      "Epoch 40/50, Train Loss: 2.356Train Acc: 0.107\n",
      "Epoch 41/50, Train Loss: 2.333Train Acc: 0.115\n",
      "Epoch 42/50, Train Loss: 2.333Train Acc: 0.114\n",
      "Epoch 43/50, Train Loss: 2.331Train Acc: 0.116\n",
      "Epoch 44/50, Train Loss: 2.340Train Acc: 0.101\n",
      "Epoch 45/50, Train Loss: 2.338Train Acc: 0.102\n",
      "Epoch 46/50, Train Loss: 2.321Train Acc: 0.122\n",
      "Epoch 47/50, Train Loss: 2.320Train Acc: 0.119\n",
      "Epoch 48/50, Train Loss: 2.332Train Acc: 0.117\n",
      "Epoch 49/50, Train Loss: 2.319Train Acc: 0.128\n",
      "Epoch 50/50, Train Loss: 2.335Train Acc: 0.122\n",
      "Finished 62 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.13480885311871227\n",
      "Epoch 1/50, Train Loss: 2.026Train Acc: 0.265\n",
      "Epoch 2/50, Train Loss: 1.650Train Acc: 0.467\n",
      "Epoch 3/50, Train Loss: 1.278Train Acc: 0.612\n",
      "Epoch 4/50, Train Loss: 1.017Train Acc: 0.714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Train Loss: 0.865Train Acc: 0.739\n",
      "Epoch 6/50, Train Loss: 0.754Train Acc: 0.788\n",
      "Epoch 7/50, Train Loss: 0.655Train Acc: 0.808\n",
      "Epoch 8/50, Train Loss: 0.574Train Acc: 0.830\n",
      "Epoch 9/50, Train Loss: 0.515Train Acc: 0.848\n",
      "Epoch 10/50, Train Loss: 0.484Train Acc: 0.859\n",
      "Epoch 11/50, Train Loss: 0.435Train Acc: 0.870\n",
      "Epoch 12/50, Train Loss: 0.395Train Acc: 0.885\n",
      "Epoch 13/50, Train Loss: 0.368Train Acc: 0.893\n",
      "Epoch 14/50, Train Loss: 0.354Train Acc: 0.896\n",
      "Epoch 15/50, Train Loss: 0.314Train Acc: 0.908\n",
      "Epoch 16/50, Train Loss: 0.289Train Acc: 0.916\n",
      "Epoch 17/50, Train Loss: 0.262Train Acc: 0.926\n",
      "Epoch 18/50, Train Loss: 0.254Train Acc: 0.928\n",
      "Epoch 19/50, Train Loss: 0.260Train Acc: 0.923\n",
      "Epoch 20/50, Train Loss: 0.231Train Acc: 0.926\n",
      "Epoch 21/50, Train Loss: 0.214Train Acc: 0.934\n",
      "Epoch 22/50, Train Loss: 0.214Train Acc: 0.933\n",
      "Epoch 23/50, Train Loss: 0.176Train Acc: 0.950\n",
      "Epoch 24/50, Train Loss: 0.185Train Acc: 0.942\n",
      "Epoch 25/50, Train Loss: 0.162Train Acc: 0.954\n",
      "Epoch 26/50, Train Loss: 0.139Train Acc: 0.961\n",
      "Epoch 27/50, Train Loss: 0.139Train Acc: 0.965\n",
      "Epoch 28/50, Train Loss: 0.137Train Acc: 0.962\n",
      "Epoch 29/50, Train Loss: 0.121Train Acc: 0.966\n",
      "Epoch 30/50, Train Loss: 0.155Train Acc: 0.950\n",
      "Epoch 31/50, Train Loss: 0.130Train Acc: 0.962\n",
      "Epoch 32/50, Train Loss: 0.130Train Acc: 0.961\n",
      "Epoch 33/50, Train Loss: 0.105Train Acc: 0.968\n",
      "Epoch 34/50, Train Loss: 0.086Train Acc: 0.977\n",
      "Epoch 35/50, Train Loss: 0.098Train Acc: 0.971\n",
      "Epoch 36/50, Train Loss: 0.076Train Acc: 0.979\n",
      "Epoch 37/50, Train Loss: 0.078Train Acc: 0.977\n",
      "Epoch 38/50, Train Loss: 0.081Train Acc: 0.975\n",
      "Epoch 39/50, Train Loss: 0.074Train Acc: 0.978\n",
      "Epoch 40/50, Train Loss: 0.076Train Acc: 0.974\n",
      "Epoch 41/50, Train Loss: 0.073Train Acc: 0.979\n",
      "Epoch 42/50, Train Loss: 0.096Train Acc: 0.973\n",
      "Epoch 43/50, Train Loss: 0.081Train Acc: 0.977\n",
      "Epoch 44/50, Train Loss: 0.102Train Acc: 0.969\n",
      "Epoch 45/50, Train Loss: 0.083Train Acc: 0.974\n",
      "Epoch 46/50, Train Loss: 0.057Train Acc: 0.984\n",
      "Epoch 47/50, Train Loss: 0.042Train Acc: 0.991\n",
      "Epoch 48/50, Train Loss: 0.051Train Acc: 0.983\n",
      "Epoch 49/50, Train Loss: 0.080Train Acc: 0.979\n",
      "Epoch 50/50, Train Loss: 0.082Train Acc: 0.974\n",
      "Finished 63 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.42655935613682094\n",
      "Epoch 1/50, Train Loss: 2.145Train Acc: 0.208\n",
      "Epoch 2/50, Train Loss: 2.005Train Acc: 0.296\n",
      "Epoch 3/50, Train Loss: 2.314Train Acc: 0.132\n",
      "Epoch 4/50, Train Loss: 2.282Train Acc: 0.143\n",
      "Epoch 5/50, Train Loss: 2.232Train Acc: 0.144\n",
      "Epoch 6/50, Train Loss: 2.181Train Acc: 0.170\n",
      "Epoch 7/50, Train Loss: 2.025Train Acc: 0.256\n",
      "Epoch 8/50, Train Loss: 1.857Train Acc: 0.325\n",
      "Epoch 9/50, Train Loss: 1.778Train Acc: 0.340\n",
      "Epoch 10/50, Train Loss: 1.747Train Acc: 0.362\n",
      "Epoch 11/50, Train Loss: 1.719Train Acc: 0.367\n",
      "Epoch 12/50, Train Loss: 1.720Train Acc: 0.384\n",
      "Epoch 13/50, Train Loss: 1.769Train Acc: 0.365\n",
      "Epoch 14/50, Train Loss: 1.732Train Acc: 0.389\n",
      "Epoch 15/50, Train Loss: 1.679Train Acc: 0.395\n",
      "Epoch 16/50, Train Loss: 1.617Train Acc: 0.430\n",
      "Epoch 17/50, Train Loss: 1.722Train Acc: 0.388\n",
      "Epoch 18/50, Train Loss: 1.646Train Acc: 0.408\n",
      "Epoch 19/50, Train Loss: 1.635Train Acc: 0.408\n",
      "Epoch 20/50, Train Loss: 1.794Train Acc: 0.381\n",
      "Epoch 21/50, Train Loss: 1.964Train Acc: 0.290\n",
      "Epoch 22/50, Train Loss: 1.890Train Acc: 0.309\n",
      "Epoch 23/50, Train Loss: 1.863Train Acc: 0.319\n",
      "Epoch 24/50, Train Loss: 1.800Train Acc: 0.372\n",
      "Epoch 25/50, Train Loss: 1.848Train Acc: 0.328\n",
      "Epoch 26/50, Train Loss: 1.959Train Acc: 0.296\n",
      "Epoch 27/50, Train Loss: 2.018Train Acc: 0.260\n",
      "Epoch 28/50, Train Loss: 1.923Train Acc: 0.300\n",
      "Epoch 29/50, Train Loss: 1.856Train Acc: 0.326\n",
      "Epoch 30/50, Train Loss: 2.134Train Acc: 0.204\n",
      "Epoch 31/50, Train Loss: 2.184Train Acc: 0.172\n",
      "Epoch 32/50, Train Loss: 2.156Train Acc: 0.186\n",
      "Epoch 33/50, Train Loss: 2.149Train Acc: 0.186\n",
      "Epoch 34/50, Train Loss: 2.140Train Acc: 0.186\n",
      "Epoch 35/50, Train Loss: 2.111Train Acc: 0.196\n",
      "Epoch 36/50, Train Loss: 2.124Train Acc: 0.194\n",
      "Epoch 37/50, Train Loss: 2.215Train Acc: 0.167\n",
      "Epoch 38/50, Train Loss: 2.237Train Acc: 0.157\n",
      "Epoch 39/50, Train Loss: 2.212Train Acc: 0.149\n",
      "Epoch 40/50, Train Loss: 2.188Train Acc: 0.164\n",
      "Epoch 41/50, Train Loss: 2.361Train Acc: 0.144\n",
      "Epoch 42/50, Train Loss: 2.179Train Acc: 0.197\n",
      "Epoch 43/50, Train Loss: 2.015Train Acc: 0.249\n",
      "Epoch 44/50, Train Loss: 2.020Train Acc: 0.250\n",
      "Epoch 45/50, Train Loss: 1.981Train Acc: 0.261\n",
      "Epoch 46/50, Train Loss: 1.965Train Acc: 0.273\n",
      "Epoch 47/50, Train Loss: 2.008Train Acc: 0.250\n",
      "Epoch 48/50, Train Loss: 2.040Train Acc: 0.236\n",
      "Epoch 49/50, Train Loss: 2.010Train Acc: 0.233\n",
      "Epoch 50/50, Train Loss: 2.071Train Acc: 0.206\n",
      "Finished 64 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.11871227364185111\n",
      "Epoch 1/10, Train Loss: 2.325Train Acc: 0.097\n",
      "Epoch 2/10, Train Loss: 2.313Train Acc: 0.103\n",
      "Epoch 3/10, Train Loss: 2.312Train Acc: 0.097\n",
      "Epoch 4/10, Train Loss: 2.309Train Acc: 0.105\n",
      "Epoch 5/10, Train Loss: 2.309Train Acc: 0.100\n",
      "Epoch 6/10, Train Loss: 2.311Train Acc: 0.098\n",
      "Epoch 7/10, Train Loss: 2.308Train Acc: 0.098\n",
      "Epoch 8/10, Train Loss: 2.310Train Acc: 0.100\n",
      "Epoch 9/10, Train Loss: 2.309Train Acc: 0.096\n",
      "Epoch 10/10, Train Loss: 2.305Train Acc: 0.103\n",
      "Finished 65 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.1006036217303823\n",
      "Epoch 1/20, Train Loss: 1.927Train Acc: 0.298\n",
      "Epoch 2/20, Train Loss: 1.583Train Acc: 0.462\n",
      "Epoch 3/20, Train Loss: 1.354Train Acc: 0.556\n",
      "Epoch 4/20, Train Loss: 1.240Train Acc: 0.594\n",
      "Epoch 5/20, Train Loss: 1.160Train Acc: 0.622\n",
      "Epoch 6/20, Train Loss: 1.148Train Acc: 0.634\n",
      "Epoch 7/20, Train Loss: 1.084Train Acc: 0.647\n",
      "Epoch 8/20, Train Loss: 1.237Train Acc: 0.588\n",
      "Epoch 9/20, Train Loss: 1.209Train Acc: 0.594\n",
      "Epoch 10/20, Train Loss: 1.178Train Acc: 0.614\n",
      "Epoch 11/20, Train Loss: 1.198Train Acc: 0.592\n",
      "Epoch 12/20, Train Loss: 1.237Train Acc: 0.598\n",
      "Epoch 13/20, Train Loss: 1.361Train Acc: 0.542\n",
      "Epoch 14/20, Train Loss: 1.286Train Acc: 0.570\n",
      "Epoch 15/20, Train Loss: 1.285Train Acc: 0.543\n",
      "Epoch 16/20, Train Loss: 1.307Train Acc: 0.560\n",
      "Epoch 17/20, Train Loss: 1.462Train Acc: 0.517\n",
      "Epoch 18/20, Train Loss: 1.394Train Acc: 0.521\n",
      "Epoch 19/20, Train Loss: 1.412Train Acc: 0.514\n",
      "Epoch 20/20, Train Loss: 1.413Train Acc: 0.511\n",
      "Finished 66 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.18108651911468812\n",
      "Epoch 1/20, Train Loss: 2.256Train Acc: 0.165\n",
      "Epoch 2/20, Train Loss: 2.171Train Acc: 0.223\n",
      "Epoch 3/20, Train Loss: 2.332Train Acc: 0.143\n",
      "Epoch 4/20, Train Loss: 2.294Train Acc: 0.153\n",
      "Epoch 5/20, Train Loss: 2.316Train Acc: 0.134\n",
      "Epoch 6/20, Train Loss: 2.304Train Acc: 0.128\n",
      "Epoch 7/20, Train Loss: 2.284Train Acc: 0.144\n",
      "Epoch 8/20, Train Loss: 2.289Train Acc: 0.134\n",
      "Epoch 9/20, Train Loss: 2.292Train Acc: 0.128\n",
      "Epoch 10/20, Train Loss: 2.272Train Acc: 0.138\n",
      "Epoch 11/20, Train Loss: 2.298Train Acc: 0.122\n",
      "Epoch 12/20, Train Loss: 2.285Train Acc: 0.128\n",
      "Epoch 13/20, Train Loss: 2.263Train Acc: 0.136\n",
      "Epoch 14/20, Train Loss: 2.297Train Acc: 0.132\n",
      "Epoch 15/20, Train Loss: 2.310Train Acc: 0.131\n",
      "Epoch 16/20, Train Loss: 2.269Train Acc: 0.142\n",
      "Epoch 17/20, Train Loss: 2.334Train Acc: 0.131\n",
      "Epoch 18/20, Train Loss: 2.386Train Acc: 0.114\n",
      "Epoch 19/20, Train Loss: 2.329Train Acc: 0.142\n",
      "Epoch 20/20, Train Loss: 2.240Train Acc: 0.167\n",
      "Finished 67 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.09054325955734406\n",
      "Epoch 1/50, Train Loss: 2.389Train Acc: 0.111\n",
      "Epoch 2/50, Train Loss: 2.383Train Acc: 0.113\n",
      "Epoch 3/50, Train Loss: 2.337Train Acc: 0.123\n",
      "Epoch 4/50, Train Loss: 2.330Train Acc: 0.137\n",
      "Epoch 5/50, Train Loss: 2.320Train Acc: 0.135\n",
      "Epoch 6/50, Train Loss: 2.373Train Acc: 0.124\n",
      "Epoch 7/50, Train Loss: 2.326Train Acc: 0.121\n",
      "Epoch 8/50, Train Loss: 2.333Train Acc: 0.130\n",
      "Epoch 9/50, Train Loss: 2.342Train Acc: 0.130\n",
      "Epoch 10/50, Train Loss: 2.334Train Acc: 0.118\n",
      "Epoch 11/50, Train Loss: 2.345Train Acc: 0.131\n",
      "Epoch 12/50, Train Loss: 2.359Train Acc: 0.122\n",
      "Epoch 13/50, Train Loss: 2.332Train Acc: 0.120\n",
      "Epoch 14/50, Train Loss: 2.336Train Acc: 0.116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Train Loss: 2.352Train Acc: 0.122\n",
      "Epoch 16/50, Train Loss: 2.326Train Acc: 0.122\n",
      "Epoch 17/50, Train Loss: 2.345Train Acc: 0.115\n",
      "Epoch 18/50, Train Loss: 2.388Train Acc: 0.102\n",
      "Epoch 19/50, Train Loss: 2.342Train Acc: 0.123\n",
      "Epoch 20/50, Train Loss: 2.339Train Acc: 0.132\n",
      "Epoch 21/50, Train Loss: 2.336Train Acc: 0.124\n",
      "Epoch 22/50, Train Loss: 2.376Train Acc: 0.131\n",
      "Epoch 23/50, Train Loss: 2.310Train Acc: 0.131\n",
      "Epoch 24/50, Train Loss: 2.325Train Acc: 0.136\n",
      "Epoch 25/50, Train Loss: 2.316Train Acc: 0.130\n",
      "Epoch 26/50, Train Loss: 2.336Train Acc: 0.129\n",
      "Epoch 27/50, Train Loss: 2.322Train Acc: 0.133\n",
      "Epoch 28/50, Train Loss: 2.315Train Acc: 0.131\n",
      "Epoch 29/50, Train Loss: 2.355Train Acc: 0.124\n",
      "Epoch 30/50, Train Loss: 2.312Train Acc: 0.124\n",
      "Epoch 31/50, Train Loss: 2.325Train Acc: 0.133\n",
      "Epoch 32/50, Train Loss: 2.333Train Acc: 0.138\n",
      "Epoch 33/50, Train Loss: 2.308Train Acc: 0.135\n",
      "Epoch 34/50, Train Loss: 2.336Train Acc: 0.120\n",
      "Epoch 35/50, Train Loss: 2.302Train Acc: 0.145\n",
      "Epoch 36/50, Train Loss: 2.295Train Acc: 0.138\n",
      "Epoch 37/50, Train Loss: 2.316Train Acc: 0.123\n",
      "Epoch 38/50, Train Loss: 2.320Train Acc: 0.144\n",
      "Epoch 39/50, Train Loss: 2.309Train Acc: 0.130\n",
      "Epoch 40/50, Train Loss: 2.324Train Acc: 0.133\n",
      "Epoch 41/50, Train Loss: 2.322Train Acc: 0.133\n",
      "Epoch 42/50, Train Loss: 2.329Train Acc: 0.121\n",
      "Epoch 43/50, Train Loss: 2.344Train Acc: 0.128\n",
      "Epoch 44/50, Train Loss: 2.314Train Acc: 0.135\n",
      "Epoch 45/50, Train Loss: 2.334Train Acc: 0.113\n",
      "Epoch 46/50, Train Loss: 2.343Train Acc: 0.135\n",
      "Epoch 47/50, Train Loss: 2.333Train Acc: 0.141\n",
      "Epoch 48/50, Train Loss: 2.327Train Acc: 0.119\n",
      "Epoch 49/50, Train Loss: 2.346Train Acc: 0.106\n",
      "Epoch 50/50, Train Loss: 2.318Train Acc: 0.139\n",
      "Finished 68 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.10462776659959759\n",
      "Epoch 1/20, Train Loss: 2.107Train Acc: 0.226\n",
      "Epoch 2/20, Train Loss: 1.734Train Acc: 0.386\n",
      "Epoch 3/20, Train Loss: 1.435Train Acc: 0.538\n",
      "Epoch 4/20, Train Loss: 1.191Train Acc: 0.638\n",
      "Epoch 5/20, Train Loss: 1.059Train Acc: 0.670\n",
      "Epoch 6/20, Train Loss: 0.975Train Acc: 0.700\n",
      "Epoch 7/20, Train Loss: 0.912Train Acc: 0.708\n",
      "Epoch 8/20, Train Loss: 0.828Train Acc: 0.742\n",
      "Epoch 9/20, Train Loss: 0.804Train Acc: 0.750\n",
      "Epoch 10/20, Train Loss: 0.757Train Acc: 0.766\n",
      "Epoch 11/20, Train Loss: 0.678Train Acc: 0.789\n",
      "Epoch 12/20, Train Loss: 0.691Train Acc: 0.779\n",
      "Epoch 13/20, Train Loss: 0.634Train Acc: 0.802\n",
      "Epoch 14/20, Train Loss: 0.677Train Acc: 0.781\n",
      "Epoch 15/20, Train Loss: 0.580Train Acc: 0.831\n",
      "Epoch 16/20, Train Loss: 0.522Train Acc: 0.844\n",
      "Epoch 17/20, Train Loss: 0.532Train Acc: 0.839\n",
      "Epoch 18/20, Train Loss: 0.519Train Acc: 0.836\n",
      "Epoch 19/20, Train Loss: 0.495Train Acc: 0.849\n",
      "Epoch 20/20, Train Loss: 0.445Train Acc: 0.865\n",
      "Finished 69 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.3822937625754527\n",
      "Epoch 1/50, Train Loss: 2.310Train Acc: 0.102\n",
      "Epoch 2/50, Train Loss: 2.318Train Acc: 0.087\n",
      "Epoch 3/50, Train Loss: 2.311Train Acc: 0.099\n",
      "Epoch 4/50, Train Loss: 2.319Train Acc: 0.091\n",
      "Epoch 5/50, Train Loss: 2.313Train Acc: 0.102\n",
      "Epoch 6/50, Train Loss: 2.315Train Acc: 0.090\n",
      "Epoch 7/50, Train Loss: 2.311Train Acc: 0.103\n",
      "Epoch 8/50, Train Loss: 2.311Train Acc: 0.086\n",
      "Epoch 9/50, Train Loss: 2.309Train Acc: 0.108\n",
      "Epoch 10/50, Train Loss: 2.311Train Acc: 0.095\n",
      "Epoch 11/50, Train Loss: 2.314Train Acc: 0.106\n",
      "Epoch 12/50, Train Loss: 2.313Train Acc: 0.087\n",
      "Epoch 13/50, Train Loss: 2.315Train Acc: 0.087\n",
      "Epoch 14/50, Train Loss: 2.308Train Acc: 0.100\n",
      "Epoch 15/50, Train Loss: 2.310Train Acc: 0.098\n",
      "Epoch 16/50, Train Loss: 2.310Train Acc: 0.093\n",
      "Epoch 17/50, Train Loss: 2.311Train Acc: 0.104\n",
      "Epoch 18/50, Train Loss: 2.312Train Acc: 0.100\n",
      "Epoch 19/50, Train Loss: 2.311Train Acc: 0.098\n",
      "Epoch 20/50, Train Loss: 2.306Train Acc: 0.096\n",
      "Epoch 21/50, Train Loss: 2.305Train Acc: 0.104\n",
      "Epoch 22/50, Train Loss: 2.308Train Acc: 0.096\n",
      "Epoch 23/50, Train Loss: 2.309Train Acc: 0.095\n",
      "Epoch 24/50, Train Loss: 2.314Train Acc: 0.086\n",
      "Epoch 25/50, Train Loss: 2.306Train Acc: 0.102\n",
      "Epoch 26/50, Train Loss: 2.309Train Acc: 0.100\n",
      "Epoch 27/50, Train Loss: 2.311Train Acc: 0.102\n",
      "Epoch 28/50, Train Loss: 2.304Train Acc: 0.106\n",
      "Epoch 29/50, Train Loss: 2.312Train Acc: 0.108\n",
      "Epoch 30/50, Train Loss: 2.310Train Acc: 0.087\n",
      "Epoch 31/50, Train Loss: 2.312Train Acc: 0.085\n",
      "Epoch 32/50, Train Loss: 2.307Train Acc: 0.101\n",
      "Epoch 33/50, Train Loss: 2.306Train Acc: 0.100\n",
      "Epoch 34/50, Train Loss: 2.309Train Acc: 0.100\n",
      "Epoch 35/50, Train Loss: 2.308Train Acc: 0.095\n",
      "Epoch 36/50, Train Loss: 2.310Train Acc: 0.097\n",
      "Epoch 37/50, Train Loss: 2.303Train Acc: 0.117\n",
      "Epoch 38/50, Train Loss: 2.306Train Acc: 0.099\n",
      "Epoch 39/50, Train Loss: 2.308Train Acc: 0.117\n",
      "Epoch 40/50, Train Loss: 2.305Train Acc: 0.105\n",
      "Epoch 41/50, Train Loss: 2.308Train Acc: 0.099\n",
      "Epoch 42/50, Train Loss: 2.310Train Acc: 0.105\n",
      "Epoch 43/50, Train Loss: 2.310Train Acc: 0.092\n",
      "Epoch 44/50, Train Loss: 2.308Train Acc: 0.101\n",
      "Epoch 45/50, Train Loss: 2.309Train Acc: 0.095\n",
      "Epoch 46/50, Train Loss: 2.308Train Acc: 0.100\n",
      "Epoch 47/50, Train Loss: 2.304Train Acc: 0.094\n",
      "Epoch 48/50, Train Loss: 2.310Train Acc: 0.078\n",
      "Epoch 49/50, Train Loss: 2.308Train Acc: 0.099\n",
      "Epoch 50/50, Train Loss: 2.305Train Acc: 0.112\n",
      "Finished 70 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.08853118712273642\n",
      "Epoch 1/50, Train Loss: 2.058Train Acc: 0.232\n",
      "Epoch 2/50, Train Loss: 1.681Train Acc: 0.436\n",
      "Epoch 3/50, Train Loss: 1.367Train Acc: 0.593\n",
      "Epoch 4/50, Train Loss: 1.196Train Acc: 0.637\n",
      "Epoch 5/50, Train Loss: 1.057Train Acc: 0.670\n",
      "Epoch 6/50, Train Loss: 0.986Train Acc: 0.686\n",
      "Epoch 7/50, Train Loss: 0.904Train Acc: 0.717\n",
      "Epoch 8/50, Train Loss: 0.859Train Acc: 0.733\n",
      "Epoch 9/50, Train Loss: 0.792Train Acc: 0.753\n",
      "Epoch 10/50, Train Loss: 0.768Train Acc: 0.759\n",
      "Epoch 11/50, Train Loss: 0.728Train Acc: 0.762\n",
      "Epoch 12/50, Train Loss: 0.702Train Acc: 0.776\n",
      "Epoch 13/50, Train Loss: 0.655Train Acc: 0.794\n",
      "Epoch 14/50, Train Loss: 0.603Train Acc: 0.816\n",
      "Epoch 15/50, Train Loss: 0.555Train Acc: 0.833\n",
      "Epoch 16/50, Train Loss: 0.599Train Acc: 0.809\n",
      "Epoch 17/50, Train Loss: 0.549Train Acc: 0.828\n",
      "Epoch 18/50, Train Loss: 0.484Train Acc: 0.846\n",
      "Epoch 19/50, Train Loss: 0.483Train Acc: 0.850\n",
      "Epoch 20/50, Train Loss: 0.457Train Acc: 0.855\n",
      "Epoch 21/50, Train Loss: 0.480Train Acc: 0.848\n",
      "Epoch 22/50, Train Loss: 0.459Train Acc: 0.859\n",
      "Epoch 23/50, Train Loss: 0.439Train Acc: 0.866\n",
      "Epoch 24/50, Train Loss: 0.385Train Acc: 0.886\n",
      "Epoch 25/50, Train Loss: 0.389Train Acc: 0.880\n",
      "Epoch 26/50, Train Loss: 0.388Train Acc: 0.882\n",
      "Epoch 27/50, Train Loss: 0.383Train Acc: 0.881\n",
      "Epoch 28/50, Train Loss: 0.355Train Acc: 0.893\n",
      "Epoch 29/50, Train Loss: 0.343Train Acc: 0.895\n",
      "Epoch 30/50, Train Loss: 0.310Train Acc: 0.904\n",
      "Epoch 31/50, Train Loss: 0.293Train Acc: 0.906\n",
      "Epoch 32/50, Train Loss: 0.279Train Acc: 0.914\n",
      "Epoch 33/50, Train Loss: 0.299Train Acc: 0.906\n",
      "Epoch 34/50, Train Loss: 0.266Train Acc: 0.916\n",
      "Epoch 35/50, Train Loss: 0.328Train Acc: 0.898\n",
      "Epoch 36/50, Train Loss: 0.301Train Acc: 0.905\n",
      "Epoch 37/50, Train Loss: 0.256Train Acc: 0.922\n",
      "Epoch 38/50, Train Loss: 0.251Train Acc: 0.927\n",
      "Epoch 39/50, Train Loss: 0.246Train Acc: 0.928\n",
      "Epoch 40/50, Train Loss: 0.259Train Acc: 0.917\n",
      "Epoch 41/50, Train Loss: 0.260Train Acc: 0.914\n",
      "Epoch 42/50, Train Loss: 0.239Train Acc: 0.928\n",
      "Epoch 43/50, Train Loss: 0.212Train Acc: 0.931\n",
      "Epoch 44/50, Train Loss: 0.202Train Acc: 0.943\n",
      "Epoch 45/50, Train Loss: 0.196Train Acc: 0.945\n",
      "Epoch 46/50, Train Loss: 0.192Train Acc: 0.939\n",
      "Epoch 47/50, Train Loss: 0.212Train Acc: 0.930\n",
      "Epoch 48/50, Train Loss: 0.199Train Acc: 0.937\n",
      "Epoch 49/50, Train Loss: 0.224Train Acc: 0.929\n",
      "Epoch 50/50, Train Loss: 0.221Train Acc: 0.931\n",
      "Finished 71 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.3843058350100604\n",
      "Epoch 1/20, Train Loss: 2.347Train Acc: 0.127\n",
      "Epoch 2/20, Train Loss: 2.325Train Acc: 0.131\n",
      "Epoch 3/20, Train Loss: 2.323Train Acc: 0.146\n",
      "Epoch 4/20, Train Loss: 2.301Train Acc: 0.133\n",
      "Epoch 5/20, Train Loss: 2.332Train Acc: 0.117\n",
      "Epoch 6/20, Train Loss: 2.353Train Acc: 0.116\n",
      "Epoch 7/20, Train Loss: 2.311Train Acc: 0.133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Train Loss: 2.304Train Acc: 0.124\n",
      "Epoch 9/20, Train Loss: 2.303Train Acc: 0.113\n",
      "Epoch 10/20, Train Loss: 2.324Train Acc: 0.119\n",
      "Epoch 11/20, Train Loss: 2.315Train Acc: 0.130\n",
      "Epoch 12/20, Train Loss: 2.310Train Acc: 0.118\n",
      "Epoch 13/20, Train Loss: 2.404Train Acc: 0.112\n",
      "Epoch 14/20, Train Loss: 2.371Train Acc: 0.106\n",
      "Epoch 15/20, Train Loss: 2.318Train Acc: 0.137\n",
      "Epoch 16/20, Train Loss: 2.293Train Acc: 0.135\n",
      "Epoch 17/20, Train Loss: 2.334Train Acc: 0.148\n",
      "Epoch 18/20, Train Loss: 2.310Train Acc: 0.134\n",
      "Epoch 19/20, Train Loss: 2.304Train Acc: 0.145\n",
      "Epoch 20/20, Train Loss: 2.279Train Acc: 0.152\n",
      "Finished 72 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.11066398390342053\n",
      "Epoch 1/50, Train Loss: 2.184Train Acc: 0.208\n",
      "Epoch 2/50, Train Loss: 2.327Train Acc: 0.132\n",
      "Epoch 3/50, Train Loss: 2.240Train Acc: 0.184\n",
      "Epoch 4/50, Train Loss: 1.973Train Acc: 0.294\n",
      "Epoch 5/50, Train Loss: 2.094Train Acc: 0.253\n",
      "Epoch 6/50, Train Loss: 2.151Train Acc: 0.209\n",
      "Epoch 7/50, Train Loss: 2.105Train Acc: 0.224\n",
      "Epoch 8/50, Train Loss: 2.241Train Acc: 0.175\n",
      "Epoch 9/50, Train Loss: 2.393Train Acc: 0.105\n",
      "Epoch 10/50, Train Loss: 2.388Train Acc: 0.100\n",
      "Epoch 11/50, Train Loss: 2.334Train Acc: 0.121\n",
      "Epoch 12/50, Train Loss: 2.329Train Acc: 0.110\n",
      "Epoch 13/50, Train Loss: 2.330Train Acc: 0.113\n",
      "Epoch 14/50, Train Loss: 2.315Train Acc: 0.130\n",
      "Epoch 15/50, Train Loss: 2.328Train Acc: 0.123\n",
      "Epoch 16/50, Train Loss: 2.322Train Acc: 0.136\n",
      "Epoch 17/50, Train Loss: 2.350Train Acc: 0.113\n",
      "Epoch 18/50, Train Loss: 2.308Train Acc: 0.121\n",
      "Epoch 19/50, Train Loss: 2.322Train Acc: 0.128\n",
      "Epoch 20/50, Train Loss: 2.345Train Acc: 0.105\n",
      "Epoch 21/50, Train Loss: 2.310Train Acc: 0.119\n",
      "Epoch 22/50, Train Loss: 2.283Train Acc: 0.151\n",
      "Epoch 23/50, Train Loss: 2.204Train Acc: 0.183\n",
      "Epoch 24/50, Train Loss: 2.109Train Acc: 0.226\n",
      "Epoch 25/50, Train Loss: 2.034Train Acc: 0.242\n",
      "Epoch 26/50, Train Loss: 2.011Train Acc: 0.256\n",
      "Epoch 27/50, Train Loss: 2.046Train Acc: 0.222\n",
      "Epoch 28/50, Train Loss: 2.111Train Acc: 0.215\n",
      "Epoch 29/50, Train Loss: 2.102Train Acc: 0.232\n",
      "Epoch 30/50, Train Loss: 2.065Train Acc: 0.205\n",
      "Epoch 31/50, Train Loss: 2.028Train Acc: 0.220\n",
      "Epoch 32/50, Train Loss: 2.363Train Acc: 0.172\n",
      "Epoch 33/50, Train Loss: 2.172Train Acc: 0.198\n",
      "Epoch 34/50, Train Loss: 2.087Train Acc: 0.221\n",
      "Epoch 35/50, Train Loss: 2.146Train Acc: 0.208\n",
      "Epoch 36/50, Train Loss: 2.011Train Acc: 0.219\n",
      "Epoch 37/50, Train Loss: 2.067Train Acc: 0.223\n",
      "Epoch 38/50, Train Loss: 1.952Train Acc: 0.268\n",
      "Epoch 39/50, Train Loss: 2.027Train Acc: 0.246\n",
      "Epoch 40/50, Train Loss: 2.112Train Acc: 0.225\n",
      "Epoch 41/50, Train Loss: 2.169Train Acc: 0.188\n",
      "Epoch 42/50, Train Loss: 2.104Train Acc: 0.222\n",
      "Epoch 43/50, Train Loss: 2.301Train Acc: 0.187\n",
      "Epoch 44/50, Train Loss: 2.251Train Acc: 0.190\n",
      "Epoch 45/50, Train Loss: 2.149Train Acc: 0.224\n",
      "Epoch 46/50, Train Loss: 2.253Train Acc: 0.171\n",
      "Epoch 47/50, Train Loss: 2.320Train Acc: 0.160\n",
      "Epoch 48/50, Train Loss: 2.122Train Acc: 0.231\n",
      "Epoch 49/50, Train Loss: 2.117Train Acc: 0.222\n",
      "Epoch 50/50, Train Loss: 2.172Train Acc: 0.222\n",
      "Finished 73 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.10261569416498995\n",
      "Epoch 1/10, Train Loss: 2.312Train Acc: 0.091\n",
      "Epoch 2/10, Train Loss: 2.308Train Acc: 0.106\n",
      "Epoch 3/10, Train Loss: 2.296Train Acc: 0.110\n",
      "Epoch 4/10, Train Loss: 2.050Train Acc: 0.229\n",
      "Epoch 5/10, Train Loss: 1.865Train Acc: 0.290\n",
      "Epoch 6/10, Train Loss: 1.747Train Acc: 0.352\n",
      "Epoch 7/10, Train Loss: 1.680Train Acc: 0.390\n",
      "Epoch 8/10, Train Loss: 1.603Train Acc: 0.447\n",
      "Epoch 9/10, Train Loss: 1.490Train Acc: 0.510\n",
      "Epoch 10/10, Train Loss: 1.404Train Acc: 0.546\n",
      "Finished 74 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.2575452716297787\n",
      "Epoch 1/20, Train Loss: 2.314Train Acc: 0.100\n",
      "Epoch 2/20, Train Loss: 2.309Train Acc: 0.091\n",
      "Epoch 3/20, Train Loss: 2.308Train Acc: 0.097\n",
      "Epoch 4/20, Train Loss: 2.306Train Acc: 0.105\n",
      "Epoch 5/20, Train Loss: 2.304Train Acc: 0.111\n",
      "Epoch 6/20, Train Loss: 2.305Train Acc: 0.088\n",
      "Epoch 7/20, Train Loss: 2.306Train Acc: 0.095\n",
      "Epoch 8/20, Train Loss: 2.304Train Acc: 0.107\n",
      "Epoch 9/20, Train Loss: 2.305Train Acc: 0.094\n",
      "Epoch 10/20, Train Loss: 2.306Train Acc: 0.096\n",
      "Epoch 11/20, Train Loss: 2.306Train Acc: 0.098\n",
      "Epoch 12/20, Train Loss: 2.306Train Acc: 0.101\n",
      "Epoch 13/20, Train Loss: 2.306Train Acc: 0.101\n",
      "Epoch 14/20, Train Loss: 2.305Train Acc: 0.090\n",
      "Epoch 15/20, Train Loss: 2.305Train Acc: 0.093\n",
      "Epoch 16/20, Train Loss: 2.260Train Acc: 0.142\n",
      "Epoch 17/20, Train Loss: 2.196Train Acc: 0.171\n",
      "Epoch 18/20, Train Loss: 2.158Train Acc: 0.165\n",
      "Epoch 19/20, Train Loss: 2.144Train Acc: 0.172\n",
      "Epoch 20/20, Train Loss: 2.140Train Acc: 0.167\n",
      "Finished 75 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.1227364185110664\n",
      "Epoch 1/10, Train Loss: 2.103Train Acc: 0.230\n",
      "Epoch 2/10, Train Loss: 1.579Train Acc: 0.490\n",
      "Epoch 3/10, Train Loss: 1.310Train Acc: 0.586\n",
      "Epoch 4/10, Train Loss: 1.073Train Acc: 0.673\n",
      "Epoch 5/10, Train Loss: 0.981Train Acc: 0.698\n",
      "Epoch 6/10, Train Loss: 0.883Train Acc: 0.728\n",
      "Epoch 7/10, Train Loss: 0.788Train Acc: 0.751\n",
      "Epoch 8/10, Train Loss: 0.739Train Acc: 0.771\n",
      "Epoch 9/10, Train Loss: 0.658Train Acc: 0.792\n",
      "Epoch 10/10, Train Loss: 0.606Train Acc: 0.815\n",
      "Finished 76 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.38832997987927564\n",
      "Epoch 1/50, Train Loss: 2.320Train Acc: 0.099\n",
      "Epoch 2/50, Train Loss: 2.313Train Acc: 0.096\n",
      "Epoch 3/50, Train Loss: 2.311Train Acc: 0.101\n",
      "Epoch 4/50, Train Loss: 2.307Train Acc: 0.102\n",
      "Epoch 5/50, Train Loss: 2.309Train Acc: 0.097\n",
      "Epoch 6/50, Train Loss: 2.310Train Acc: 0.091\n",
      "Epoch 7/50, Train Loss: 2.308Train Acc: 0.108\n",
      "Epoch 8/50, Train Loss: 2.311Train Acc: 0.088\n",
      "Epoch 9/50, Train Loss: 2.306Train Acc: 0.103\n",
      "Epoch 10/50, Train Loss: 2.305Train Acc: 0.101\n",
      "Epoch 11/50, Train Loss: 2.308Train Acc: 0.095\n",
      "Epoch 12/50, Train Loss: 2.308Train Acc: 0.101\n",
      "Epoch 13/50, Train Loss: 2.307Train Acc: 0.099\n",
      "Epoch 14/50, Train Loss: 2.306Train Acc: 0.103\n",
      "Epoch 15/50, Train Loss: 2.305Train Acc: 0.101\n",
      "Epoch 16/50, Train Loss: 2.307Train Acc: 0.103\n",
      "Epoch 17/50, Train Loss: 2.307Train Acc: 0.083\n",
      "Epoch 18/50, Train Loss: 2.305Train Acc: 0.104\n",
      "Epoch 19/50, Train Loss: 2.305Train Acc: 0.099\n",
      "Epoch 20/50, Train Loss: 2.306Train Acc: 0.107\n",
      "Epoch 21/50, Train Loss: 2.305Train Acc: 0.093\n",
      "Epoch 22/50, Train Loss: 2.304Train Acc: 0.093\n",
      "Epoch 23/50, Train Loss: 2.305Train Acc: 0.090\n",
      "Epoch 24/50, Train Loss: 2.306Train Acc: 0.099\n",
      "Epoch 25/50, Train Loss: 2.305Train Acc: 0.102\n",
      "Epoch 26/50, Train Loss: 2.305Train Acc: 0.091\n",
      "Epoch 27/50, Train Loss: 2.304Train Acc: 0.102\n",
      "Epoch 28/50, Train Loss: 2.306Train Acc: 0.097\n",
      "Epoch 29/50, Train Loss: 2.305Train Acc: 0.096\n",
      "Epoch 30/50, Train Loss: 2.305Train Acc: 0.091\n",
      "Epoch 31/50, Train Loss: 2.303Train Acc: 0.097\n",
      "Epoch 32/50, Train Loss: 2.306Train Acc: 0.087\n",
      "Epoch 33/50, Train Loss: 2.305Train Acc: 0.096\n",
      "Epoch 34/50, Train Loss: 2.305Train Acc: 0.093\n",
      "Epoch 35/50, Train Loss: 2.305Train Acc: 0.097\n",
      "Epoch 36/50, Train Loss: 2.305Train Acc: 0.086\n",
      "Epoch 37/50, Train Loss: 2.305Train Acc: 0.092\n",
      "Epoch 38/50, Train Loss: 2.304Train Acc: 0.099\n",
      "Epoch 39/50, Train Loss: 2.304Train Acc: 0.101\n",
      "Epoch 40/50, Train Loss: 2.306Train Acc: 0.086\n",
      "Epoch 41/50, Train Loss: 2.305Train Acc: 0.092\n",
      "Epoch 42/50, Train Loss: 2.306Train Acc: 0.089\n",
      "Epoch 43/50, Train Loss: 2.306Train Acc: 0.088\n",
      "Epoch 44/50, Train Loss: 2.305Train Acc: 0.096\n",
      "Epoch 45/50, Train Loss: 2.302Train Acc: 0.104\n",
      "Epoch 46/50, Train Loss: 2.304Train Acc: 0.110\n",
      "Epoch 47/50, Train Loss: 2.305Train Acc: 0.099\n",
      "Epoch 48/50, Train Loss: 2.305Train Acc: 0.093\n",
      "Epoch 49/50, Train Loss: 2.305Train Acc: 0.082\n",
      "Epoch 50/50, Train Loss: 2.304Train Acc: 0.088\n",
      "Finished 77 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.10663983903420524\n",
      "Epoch 1/50, Train Loss: 2.317Train Acc: 0.097\n",
      "Epoch 2/50, Train Loss: 2.311Train Acc: 0.110\n",
      "Epoch 3/50, Train Loss: 2.312Train Acc: 0.099\n",
      "Epoch 4/50, Train Loss: 2.308Train Acc: 0.104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Train Loss: 2.276Train Acc: 0.126\n",
      "Epoch 6/50, Train Loss: 2.118Train Acc: 0.193\n",
      "Epoch 7/50, Train Loss: 2.069Train Acc: 0.210\n",
      "Epoch 8/50, Train Loss: 1.980Train Acc: 0.275\n",
      "Epoch 9/50, Train Loss: 1.902Train Acc: 0.312\n",
      "Epoch 10/50, Train Loss: 1.842Train Acc: 0.327\n",
      "Epoch 11/50, Train Loss: 1.784Train Acc: 0.350\n",
      "Epoch 12/50, Train Loss: 1.752Train Acc: 0.376\n",
      "Epoch 13/50, Train Loss: 1.719Train Acc: 0.382\n",
      "Epoch 14/50, Train Loss: 1.682Train Acc: 0.401\n",
      "Epoch 15/50, Train Loss: 1.660Train Acc: 0.423\n",
      "Epoch 16/50, Train Loss: 1.615Train Acc: 0.436\n",
      "Epoch 17/50, Train Loss: 1.583Train Acc: 0.451\n",
      "Epoch 18/50, Train Loss: 1.548Train Acc: 0.469\n",
      "Epoch 19/50, Train Loss: 1.535Train Acc: 0.458\n",
      "Epoch 20/50, Train Loss: 1.538Train Acc: 0.447\n",
      "Epoch 21/50, Train Loss: 1.496Train Acc: 0.476\n",
      "Epoch 22/50, Train Loss: 1.487Train Acc: 0.487\n",
      "Epoch 23/50, Train Loss: 1.449Train Acc: 0.495\n",
      "Epoch 24/50, Train Loss: 1.422Train Acc: 0.515\n",
      "Epoch 25/50, Train Loss: 1.415Train Acc: 0.531\n",
      "Epoch 26/50, Train Loss: 1.396Train Acc: 0.522\n",
      "Epoch 27/50, Train Loss: 1.373Train Acc: 0.543\n",
      "Epoch 28/50, Train Loss: 1.365Train Acc: 0.547\n",
      "Epoch 29/50, Train Loss: 1.352Train Acc: 0.540\n",
      "Epoch 30/50, Train Loss: 1.285Train Acc: 0.572\n",
      "Epoch 31/50, Train Loss: 1.340Train Acc: 0.554\n",
      "Epoch 32/50, Train Loss: 1.298Train Acc: 0.575\n",
      "Epoch 33/50, Train Loss: 1.252Train Acc: 0.585\n",
      "Epoch 34/50, Train Loss: 1.257Train Acc: 0.581\n",
      "Epoch 35/50, Train Loss: 1.259Train Acc: 0.581\n",
      "Epoch 36/50, Train Loss: 1.225Train Acc: 0.597\n",
      "Epoch 37/50, Train Loss: 1.218Train Acc: 0.597\n",
      "Epoch 38/50, Train Loss: 1.208Train Acc: 0.601\n",
      "Epoch 39/50, Train Loss: 1.208Train Acc: 0.599\n",
      "Epoch 40/50, Train Loss: 1.193Train Acc: 0.609\n",
      "Epoch 41/50, Train Loss: 1.186Train Acc: 0.607\n",
      "Epoch 42/50, Train Loss: 1.202Train Acc: 0.595\n",
      "Epoch 43/50, Train Loss: 1.178Train Acc: 0.613\n",
      "Epoch 44/50, Train Loss: 1.169Train Acc: 0.628\n",
      "Epoch 45/50, Train Loss: 1.128Train Acc: 0.640\n",
      "Epoch 46/50, Train Loss: 1.120Train Acc: 0.640\n",
      "Epoch 47/50, Train Loss: 1.117Train Acc: 0.639\n",
      "Epoch 48/50, Train Loss: 1.134Train Acc: 0.634\n",
      "Epoch 49/50, Train Loss: 1.087Train Acc: 0.646\n",
      "Epoch 50/50, Train Loss: 1.068Train Acc: 0.654\n",
      "Finished 78 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.3158953722334004\n",
      "Epoch 1/10, Train Loss: 2.123Train Acc: 0.239\n",
      "Epoch 2/10, Train Loss: 1.824Train Acc: 0.384\n",
      "Epoch 3/10, Train Loss: 1.608Train Acc: 0.471\n",
      "Epoch 4/10, Train Loss: 1.451Train Acc: 0.541\n",
      "Epoch 5/10, Train Loss: 1.322Train Acc: 0.585\n",
      "Epoch 6/10, Train Loss: 1.218Train Acc: 0.621\n",
      "Epoch 7/10, Train Loss: 1.116Train Acc: 0.655\n",
      "Epoch 8/10, Train Loss: 1.005Train Acc: 0.706\n",
      "Epoch 9/10, Train Loss: 0.907Train Acc: 0.742\n",
      "Epoch 10/10, Train Loss: 0.814Train Acc: 0.768\n",
      "Finished 79 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.2977867203219316\n",
      "Epoch 1/50, Train Loss: 1.943Train Acc: 0.292\n",
      "Epoch 2/50, Train Loss: 1.653Train Acc: 0.434\n",
      "Epoch 3/50, Train Loss: 1.415Train Acc: 0.536\n",
      "Epoch 4/50, Train Loss: 1.262Train Acc: 0.587\n",
      "Epoch 5/50, Train Loss: 1.199Train Acc: 0.614\n",
      "Epoch 6/50, Train Loss: 1.036Train Acc: 0.675\n",
      "Epoch 7/50, Train Loss: 1.014Train Acc: 0.681\n",
      "Epoch 8/50, Train Loss: 1.022Train Acc: 0.674\n",
      "Epoch 9/50, Train Loss: 1.069Train Acc: 0.650\n",
      "Epoch 10/50, Train Loss: 0.994Train Acc: 0.691\n",
      "Epoch 11/50, Train Loss: 0.974Train Acc: 0.680\n",
      "Epoch 12/50, Train Loss: 0.845Train Acc: 0.731\n",
      "Epoch 13/50, Train Loss: 0.985Train Acc: 0.674\n",
      "Epoch 14/50, Train Loss: 0.983Train Acc: 0.680\n",
      "Epoch 15/50, Train Loss: 0.947Train Acc: 0.704\n",
      "Epoch 16/50, Train Loss: 0.942Train Acc: 0.700\n",
      "Epoch 17/50, Train Loss: 0.993Train Acc: 0.689\n",
      "Epoch 18/50, Train Loss: 0.881Train Acc: 0.718\n",
      "Epoch 19/50, Train Loss: 0.965Train Acc: 0.697\n",
      "Epoch 20/50, Train Loss: 1.048Train Acc: 0.661\n",
      "Epoch 21/50, Train Loss: 1.138Train Acc: 0.628\n",
      "Epoch 22/50, Train Loss: 1.019Train Acc: 0.675\n",
      "Epoch 23/50, Train Loss: 0.996Train Acc: 0.694\n",
      "Epoch 24/50, Train Loss: 0.966Train Acc: 0.684\n",
      "Epoch 25/50, Train Loss: 0.983Train Acc: 0.688\n",
      "Epoch 26/50, Train Loss: 0.999Train Acc: 0.676\n",
      "Epoch 27/50, Train Loss: 0.991Train Acc: 0.682\n",
      "Epoch 28/50, Train Loss: 0.952Train Acc: 0.690\n",
      "Epoch 29/50, Train Loss: 0.988Train Acc: 0.693\n",
      "Epoch 30/50, Train Loss: 1.087Train Acc: 0.650\n",
      "Epoch 31/50, Train Loss: 1.072Train Acc: 0.651\n",
      "Epoch 32/50, Train Loss: 1.013Train Acc: 0.671\n",
      "Epoch 33/50, Train Loss: 0.994Train Acc: 0.693\n",
      "Epoch 34/50, Train Loss: 1.143Train Acc: 0.638\n",
      "Epoch 35/50, Train Loss: 1.024Train Acc: 0.674\n",
      "Epoch 36/50, Train Loss: 1.061Train Acc: 0.660\n",
      "Epoch 37/50, Train Loss: 1.107Train Acc: 0.635\n",
      "Epoch 38/50, Train Loss: 1.052Train Acc: 0.655\n",
      "Epoch 39/50, Train Loss: 1.021Train Acc: 0.670\n",
      "Epoch 40/50, Train Loss: 1.081Train Acc: 0.642\n",
      "Epoch 41/50, Train Loss: 1.007Train Acc: 0.655\n",
      "Epoch 42/50, Train Loss: 1.110Train Acc: 0.643\n",
      "Epoch 43/50, Train Loss: 1.173Train Acc: 0.610\n",
      "Epoch 44/50, Train Loss: 1.201Train Acc: 0.613\n",
      "Epoch 45/50, Train Loss: 1.177Train Acc: 0.616\n",
      "Epoch 46/50, Train Loss: 1.206Train Acc: 0.619\n",
      "Epoch 47/50, Train Loss: 1.175Train Acc: 0.628\n",
      "Epoch 48/50, Train Loss: 1.297Train Acc: 0.586\n",
      "Epoch 49/50, Train Loss: 1.339Train Acc: 0.561\n",
      "Epoch 50/50, Train Loss: 1.363Train Acc: 0.556\n",
      "Finished 80 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.21327967806841047\n",
      "Epoch 1/10, Train Loss: 2.118Train Acc: 0.200\n",
      "Epoch 2/10, Train Loss: 1.772Train Acc: 0.379\n",
      "Epoch 3/10, Train Loss: 1.507Train Acc: 0.515\n",
      "Epoch 4/10, Train Loss: 1.341Train Acc: 0.572\n",
      "Epoch 5/10, Train Loss: 1.203Train Acc: 0.622\n",
      "Epoch 6/10, Train Loss: 1.064Train Acc: 0.669\n",
      "Epoch 7/10, Train Loss: 0.937Train Acc: 0.716\n",
      "Epoch 8/10, Train Loss: 0.875Train Acc: 0.731\n",
      "Epoch 9/10, Train Loss: 0.817Train Acc: 0.742\n",
      "Epoch 10/10, Train Loss: 0.765Train Acc: 0.769\n",
      "Finished 81 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.3440643863179074\n",
      "Epoch 1/20, Train Loss: 2.296Train Acc: 0.135\n",
      "Epoch 2/20, Train Loss: 1.982Train Acc: 0.308\n",
      "Epoch 3/20, Train Loss: 1.737Train Acc: 0.430\n",
      "Epoch 4/20, Train Loss: 1.579Train Acc: 0.470\n",
      "Epoch 5/20, Train Loss: 1.468Train Acc: 0.527\n",
      "Epoch 6/20, Train Loss: 1.351Train Acc: 0.574\n",
      "Epoch 7/20, Train Loss: 1.274Train Acc: 0.616\n",
      "Epoch 8/20, Train Loss: 1.183Train Acc: 0.628\n",
      "Epoch 9/20, Train Loss: 1.154Train Acc: 0.642\n",
      "Epoch 10/20, Train Loss: 1.092Train Acc: 0.666\n",
      "Epoch 11/20, Train Loss: 1.095Train Acc: 0.655\n",
      "Epoch 12/20, Train Loss: 1.032Train Acc: 0.683\n",
      "Epoch 13/20, Train Loss: 1.006Train Acc: 0.695\n",
      "Epoch 14/20, Train Loss: 0.980Train Acc: 0.696\n",
      "Epoch 15/20, Train Loss: 0.956Train Acc: 0.711\n",
      "Epoch 16/20, Train Loss: 0.906Train Acc: 0.717\n",
      "Epoch 17/20, Train Loss: 0.875Train Acc: 0.731\n",
      "Epoch 18/20, Train Loss: 0.846Train Acc: 0.734\n",
      "Epoch 19/20, Train Loss: 0.859Train Acc: 0.731\n",
      "Epoch 20/20, Train Loss: 0.821Train Acc: 0.737\n",
      "Finished 82 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.39235412474849096\n",
      "Epoch 1/20, Train Loss: 2.322Train Acc: 0.101\n",
      "Epoch 2/20, Train Loss: 2.321Train Acc: 0.107\n",
      "Epoch 3/20, Train Loss: 2.320Train Acc: 0.097\n",
      "Epoch 4/20, Train Loss: 2.259Train Acc: 0.141\n",
      "Epoch 5/20, Train Loss: 2.280Train Acc: 0.131\n",
      "Epoch 6/20, Train Loss: 2.268Train Acc: 0.138\n",
      "Epoch 7/20, Train Loss: 2.276Train Acc: 0.118\n",
      "Epoch 8/20, Train Loss: 2.328Train Acc: 0.089\n",
      "Epoch 9/20, Train Loss: 2.319Train Acc: 0.097\n",
      "Epoch 10/20, Train Loss: 2.315Train Acc: 0.102\n",
      "Epoch 11/20, Train Loss: 2.309Train Acc: 0.104\n",
      "Epoch 12/20, Train Loss: 2.263Train Acc: 0.128\n",
      "Epoch 13/20, Train Loss: 2.231Train Acc: 0.157\n",
      "Epoch 14/20, Train Loss: 2.231Train Acc: 0.140\n",
      "Epoch 15/20, Train Loss: 2.226Train Acc: 0.139\n",
      "Epoch 16/20, Train Loss: 2.243Train Acc: 0.150\n",
      "Epoch 17/20, Train Loss: 2.250Train Acc: 0.137\n",
      "Epoch 18/20, Train Loss: 2.254Train Acc: 0.138\n",
      "Epoch 19/20, Train Loss: 2.240Train Acc: 0.154\n",
      "Epoch 20/20, Train Loss: 2.240Train Acc: 0.147\n",
      "Finished 83 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.09859154929577464\n",
      "Epoch 1/10, Train Loss: 2.247Train Acc: 0.140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 1.999Train Acc: 0.269\n",
      "Epoch 3/10, Train Loss: 1.808Train Acc: 0.374\n",
      "Epoch 4/10, Train Loss: 1.644Train Acc: 0.434\n",
      "Epoch 5/10, Train Loss: 1.505Train Acc: 0.503\n",
      "Epoch 6/10, Train Loss: 1.401Train Acc: 0.542\n",
      "Epoch 7/10, Train Loss: 1.323Train Acc: 0.556\n",
      "Epoch 8/10, Train Loss: 1.301Train Acc: 0.559\n",
      "Epoch 9/10, Train Loss: 1.206Train Acc: 0.598\n",
      "Epoch 10/10, Train Loss: 1.158Train Acc: 0.610\n",
      "Finished 84 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.317907444668008\n",
      "Epoch 1/50, Train Loss: 2.310Train Acc: 0.103\n",
      "Epoch 2/50, Train Loss: 2.308Train Acc: 0.093\n",
      "Epoch 3/50, Train Loss: 2.308Train Acc: 0.100\n",
      "Epoch 4/50, Train Loss: 2.305Train Acc: 0.097\n",
      "Epoch 5/50, Train Loss: 2.286Train Acc: 0.129\n",
      "Epoch 6/50, Train Loss: 2.116Train Acc: 0.231\n",
      "Epoch 7/50, Train Loss: 2.002Train Acc: 0.272\n",
      "Epoch 8/50, Train Loss: 1.904Train Acc: 0.304\n",
      "Epoch 9/50, Train Loss: 1.837Train Acc: 0.336\n",
      "Epoch 10/50, Train Loss: 1.784Train Acc: 0.353\n",
      "Epoch 11/50, Train Loss: 1.739Train Acc: 0.347\n",
      "Epoch 12/50, Train Loss: 1.724Train Acc: 0.376\n",
      "Epoch 13/50, Train Loss: 1.650Train Acc: 0.404\n",
      "Epoch 14/50, Train Loss: 1.624Train Acc: 0.397\n",
      "Epoch 15/50, Train Loss: 1.605Train Acc: 0.406\n",
      "Epoch 16/50, Train Loss: 1.551Train Acc: 0.426\n",
      "Epoch 17/50, Train Loss: 1.524Train Acc: 0.452\n",
      "Epoch 18/50, Train Loss: 1.504Train Acc: 0.465\n",
      "Epoch 19/50, Train Loss: 1.493Train Acc: 0.462\n",
      "Epoch 20/50, Train Loss: 1.410Train Acc: 0.508\n",
      "Epoch 21/50, Train Loss: 1.417Train Acc: 0.514\n",
      "Epoch 22/50, Train Loss: 1.388Train Acc: 0.520\n",
      "Epoch 23/50, Train Loss: 1.347Train Acc: 0.519\n",
      "Epoch 24/50, Train Loss: 1.332Train Acc: 0.536\n",
      "Epoch 25/50, Train Loss: 1.291Train Acc: 0.557\n",
      "Epoch 26/50, Train Loss: 1.265Train Acc: 0.570\n",
      "Epoch 27/50, Train Loss: 1.234Train Acc: 0.580\n",
      "Epoch 28/50, Train Loss: 1.218Train Acc: 0.588\n",
      "Epoch 29/50, Train Loss: 1.228Train Acc: 0.579\n",
      "Epoch 30/50, Train Loss: 1.238Train Acc: 0.568\n",
      "Epoch 31/50, Train Loss: 1.201Train Acc: 0.585\n",
      "Epoch 32/50, Train Loss: 1.195Train Acc: 0.585\n",
      "Epoch 33/50, Train Loss: 1.197Train Acc: 0.596\n",
      "Epoch 34/50, Train Loss: 1.162Train Acc: 0.595\n",
      "Epoch 35/50, Train Loss: 1.145Train Acc: 0.618\n",
      "Epoch 36/50, Train Loss: 1.169Train Acc: 0.596\n",
      "Epoch 37/50, Train Loss: 1.172Train Acc: 0.602\n",
      "Epoch 38/50, Train Loss: 1.150Train Acc: 0.604\n",
      "Epoch 39/50, Train Loss: 1.130Train Acc: 0.610\n",
      "Epoch 40/50, Train Loss: 1.129Train Acc: 0.610\n",
      "Epoch 41/50, Train Loss: 1.138Train Acc: 0.594\n",
      "Epoch 42/50, Train Loss: 1.133Train Acc: 0.605\n",
      "Epoch 43/50, Train Loss: 1.144Train Acc: 0.599\n",
      "Epoch 44/50, Train Loss: 1.107Train Acc: 0.620\n",
      "Epoch 45/50, Train Loss: 1.064Train Acc: 0.626\n",
      "Epoch 46/50, Train Loss: 1.087Train Acc: 0.632\n",
      "Epoch 47/50, Train Loss: 1.069Train Acc: 0.628\n",
      "Epoch 48/50, Train Loss: 1.090Train Acc: 0.614\n",
      "Epoch 49/50, Train Loss: 1.086Train Acc: 0.625\n",
      "Epoch 50/50, Train Loss: 1.085Train Acc: 0.646\n",
      "Finished 85 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.2776659959758551\n",
      "Epoch 1/50, Train Loss: 2.318Train Acc: 0.110\n",
      "Epoch 2/50, Train Loss: 2.154Train Acc: 0.175\n",
      "Epoch 3/50, Train Loss: 1.980Train Acc: 0.273\n",
      "Epoch 4/50, Train Loss: 1.901Train Acc: 0.313\n",
      "Epoch 5/50, Train Loss: 1.767Train Acc: 0.383\n",
      "Epoch 6/50, Train Loss: 1.780Train Acc: 0.344\n",
      "Epoch 7/50, Train Loss: 1.852Train Acc: 0.312\n",
      "Epoch 8/50, Train Loss: 2.022Train Acc: 0.252\n",
      "Epoch 9/50, Train Loss: 1.854Train Acc: 0.322\n",
      "Epoch 10/50, Train Loss: 2.121Train Acc: 0.260\n",
      "Epoch 11/50, Train Loss: 2.107Train Acc: 0.245\n",
      "Epoch 12/50, Train Loss: 2.265Train Acc: 0.170\n",
      "Epoch 13/50, Train Loss: 2.233Train Acc: 0.181\n",
      "Epoch 14/50, Train Loss: 2.198Train Acc: 0.195\n",
      "Epoch 15/50, Train Loss: 2.243Train Acc: 0.167\n",
      "Epoch 16/50, Train Loss: 2.259Train Acc: 0.161\n",
      "Epoch 17/50, Train Loss: 2.248Train Acc: 0.175\n",
      "Epoch 18/50, Train Loss: 2.181Train Acc: 0.207\n",
      "Epoch 19/50, Train Loss: 2.228Train Acc: 0.174\n",
      "Epoch 20/50, Train Loss: 2.185Train Acc: 0.164\n",
      "Epoch 21/50, Train Loss: 2.158Train Acc: 0.175\n",
      "Epoch 22/50, Train Loss: 2.138Train Acc: 0.206\n",
      "Epoch 23/50, Train Loss: 2.168Train Acc: 0.177\n",
      "Epoch 24/50, Train Loss: 2.143Train Acc: 0.196\n",
      "Epoch 25/50, Train Loss: 2.170Train Acc: 0.204\n",
      "Epoch 26/50, Train Loss: 2.265Train Acc: 0.178\n",
      "Epoch 27/50, Train Loss: 2.216Train Acc: 0.195\n",
      "Epoch 28/50, Train Loss: 2.116Train Acc: 0.237\n",
      "Epoch 29/50, Train Loss: 2.102Train Acc: 0.244\n",
      "Epoch 30/50, Train Loss: 2.145Train Acc: 0.214\n",
      "Epoch 31/50, Train Loss: 2.157Train Acc: 0.208\n",
      "Epoch 32/50, Train Loss: 2.125Train Acc: 0.229\n",
      "Epoch 33/50, Train Loss: 2.100Train Acc: 0.246\n",
      "Epoch 34/50, Train Loss: 2.161Train Acc: 0.215\n",
      "Epoch 35/50, Train Loss: 2.114Train Acc: 0.245\n",
      "Epoch 36/50, Train Loss: 2.064Train Acc: 0.246\n",
      "Epoch 37/50, Train Loss: 2.081Train Acc: 0.237\n",
      "Epoch 38/50, Train Loss: 2.012Train Acc: 0.253\n",
      "Epoch 39/50, Train Loss: 1.943Train Acc: 0.263\n",
      "Epoch 40/50, Train Loss: 1.945Train Acc: 0.260\n",
      "Epoch 41/50, Train Loss: 1.989Train Acc: 0.245\n",
      "Epoch 42/50, Train Loss: 1.985Train Acc: 0.241\n",
      "Epoch 43/50, Train Loss: 1.900Train Acc: 0.290\n",
      "Epoch 44/50, Train Loss: 1.876Train Acc: 0.304\n",
      "Epoch 45/50, Train Loss: 1.944Train Acc: 0.265\n",
      "Epoch 46/50, Train Loss: 1.912Train Acc: 0.282\n",
      "Epoch 47/50, Train Loss: 1.847Train Acc: 0.346\n",
      "Epoch 48/50, Train Loss: 2.130Train Acc: 0.239\n",
      "Epoch 49/50, Train Loss: 2.102Train Acc: 0.225\n",
      "Epoch 50/50, Train Loss: 1.986Train Acc: 0.282\n",
      "Finished 86 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.17303822937625754\n",
      "Epoch 1/50, Train Loss: 2.349Train Acc: 0.098\n",
      "Epoch 2/50, Train Loss: 2.339Train Acc: 0.090\n",
      "Epoch 3/50, Train Loss: 2.330Train Acc: 0.099\n",
      "Epoch 4/50, Train Loss: 2.342Train Acc: 0.098\n",
      "Epoch 5/50, Train Loss: 2.332Train Acc: 0.104\n",
      "Epoch 6/50, Train Loss: 2.338Train Acc: 0.100\n",
      "Epoch 7/50, Train Loss: 2.349Train Acc: 0.096\n",
      "Epoch 8/50, Train Loss: 2.335Train Acc: 0.099\n",
      "Epoch 9/50, Train Loss: 2.343Train Acc: 0.093\n",
      "Epoch 10/50, Train Loss: 2.335Train Acc: 0.100\n",
      "Epoch 11/50, Train Loss: 2.336Train Acc: 0.107\n",
      "Epoch 12/50, Train Loss: 2.341Train Acc: 0.110\n",
      "Epoch 13/50, Train Loss: 2.363Train Acc: 0.083\n",
      "Epoch 14/50, Train Loss: 2.337Train Acc: 0.100\n",
      "Epoch 15/50, Train Loss: 2.357Train Acc: 0.096\n",
      "Epoch 16/50, Train Loss: 2.343Train Acc: 0.108\n",
      "Epoch 17/50, Train Loss: 2.339Train Acc: 0.096\n",
      "Epoch 18/50, Train Loss: 2.344Train Acc: 0.094\n",
      "Epoch 19/50, Train Loss: 2.343Train Acc: 0.092\n",
      "Epoch 20/50, Train Loss: 2.344Train Acc: 0.101\n",
      "Epoch 21/50, Train Loss: 2.344Train Acc: 0.099\n",
      "Epoch 22/50, Train Loss: 2.348Train Acc: 0.095\n",
      "Epoch 23/50, Train Loss: 2.335Train Acc: 0.112\n",
      "Epoch 24/50, Train Loss: 2.355Train Acc: 0.096\n",
      "Epoch 25/50, Train Loss: 2.352Train Acc: 0.082\n",
      "Epoch 26/50, Train Loss: 2.336Train Acc: 0.101\n",
      "Epoch 27/50, Train Loss: 2.345Train Acc: 0.086\n",
      "Epoch 28/50, Train Loss: 2.340Train Acc: 0.095\n",
      "Epoch 29/50, Train Loss: 2.343Train Acc: 0.092\n",
      "Epoch 30/50, Train Loss: 2.342Train Acc: 0.101\n",
      "Epoch 31/50, Train Loss: 2.351Train Acc: 0.095\n",
      "Epoch 32/50, Train Loss: 2.331Train Acc: 0.114\n",
      "Epoch 33/50, Train Loss: 2.342Train Acc: 0.094\n",
      "Epoch 34/50, Train Loss: 2.344Train Acc: 0.101\n",
      "Epoch 35/50, Train Loss: 2.345Train Acc: 0.087\n",
      "Epoch 36/50, Train Loss: 2.342Train Acc: 0.101\n",
      "Epoch 37/50, Train Loss: 2.335Train Acc: 0.106\n",
      "Epoch 38/50, Train Loss: 2.345Train Acc: 0.099\n",
      "Epoch 39/50, Train Loss: 2.348Train Acc: 0.095\n",
      "Epoch 40/50, Train Loss: 2.338Train Acc: 0.086\n",
      "Epoch 41/50, Train Loss: 2.334Train Acc: 0.102\n",
      "Epoch 42/50, Train Loss: 2.351Train Acc: 0.108\n",
      "Epoch 43/50, Train Loss: 2.332Train Acc: 0.106\n",
      "Epoch 44/50, Train Loss: 2.349Train Acc: 0.088\n",
      "Epoch 45/50, Train Loss: 2.351Train Acc: 0.094\n",
      "Epoch 46/50, Train Loss: 2.356Train Acc: 0.090\n",
      "Epoch 47/50, Train Loss: 2.342Train Acc: 0.096\n",
      "Epoch 48/50, Train Loss: 2.349Train Acc: 0.103\n",
      "Epoch 49/50, Train Loss: 2.348Train Acc: 0.096\n",
      "Epoch 50/50, Train Loss: 2.344Train Acc: 0.101\n",
      "Finished 87 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.10865191146881288\n",
      "Epoch 1/20, Train Loss: 2.325Train Acc: 0.104\n",
      "Epoch 2/20, Train Loss: 2.318Train Acc: 0.095\n",
      "Epoch 3/20, Train Loss: 2.308Train Acc: 0.088\n",
      "Epoch 4/20, Train Loss: 2.306Train Acc: 0.116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Train Loss: 2.306Train Acc: 0.108\n",
      "Epoch 6/20, Train Loss: 2.306Train Acc: 0.108\n",
      "Epoch 7/20, Train Loss: 2.260Train Acc: 0.150\n",
      "Epoch 8/20, Train Loss: 2.173Train Acc: 0.181\n",
      "Epoch 9/20, Train Loss: 2.081Train Acc: 0.217\n",
      "Epoch 10/20, Train Loss: 2.001Train Acc: 0.268\n",
      "Epoch 11/20, Train Loss: 1.878Train Acc: 0.347\n",
      "Epoch 12/20, Train Loss: 1.817Train Acc: 0.350\n",
      "Epoch 13/20, Train Loss: 1.765Train Acc: 0.370\n",
      "Epoch 14/20, Train Loss: 1.708Train Acc: 0.399\n",
      "Epoch 15/20, Train Loss: 1.646Train Acc: 0.421\n",
      "Epoch 16/20, Train Loss: 1.610Train Acc: 0.453\n",
      "Epoch 17/20, Train Loss: 1.574Train Acc: 0.455\n",
      "Epoch 18/20, Train Loss: 1.553Train Acc: 0.462\n",
      "Epoch 19/20, Train Loss: 1.502Train Acc: 0.479\n",
      "Epoch 20/20, Train Loss: 1.481Train Acc: 0.495\n",
      "Finished 88 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.24346076458752516\n",
      "Epoch 1/20, Train Loss: 2.241Train Acc: 0.153\n",
      "Epoch 2/20, Train Loss: 2.042Train Acc: 0.287\n",
      "Epoch 3/20, Train Loss: 1.898Train Acc: 0.332\n",
      "Epoch 4/20, Train Loss: 1.816Train Acc: 0.373\n",
      "Epoch 5/20, Train Loss: 1.744Train Acc: 0.417\n",
      "Epoch 6/20, Train Loss: 1.652Train Acc: 0.449\n",
      "Epoch 7/20, Train Loss: 1.585Train Acc: 0.474\n",
      "Epoch 8/20, Train Loss: 1.522Train Acc: 0.497\n",
      "Epoch 9/20, Train Loss: 1.468Train Acc: 0.510\n",
      "Epoch 10/20, Train Loss: 1.418Train Acc: 0.528\n",
      "Epoch 11/20, Train Loss: 1.374Train Acc: 0.534\n",
      "Epoch 12/20, Train Loss: 1.316Train Acc: 0.567\n",
      "Epoch 13/20, Train Loss: 1.283Train Acc: 0.595\n",
      "Epoch 14/20, Train Loss: 1.226Train Acc: 0.624\n",
      "Epoch 15/20, Train Loss: 1.180Train Acc: 0.627\n",
      "Epoch 16/20, Train Loss: 1.125Train Acc: 0.653\n",
      "Epoch 17/20, Train Loss: 1.097Train Acc: 0.666\n",
      "Epoch 18/20, Train Loss: 1.060Train Acc: 0.669\n",
      "Epoch 19/20, Train Loss: 1.018Train Acc: 0.685\n",
      "Epoch 20/20, Train Loss: 0.989Train Acc: 0.709\n",
      "Finished 89 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.2716297786720322\n",
      "Epoch 1/10, Train Loss: 2.064Train Acc: 0.259\n",
      "Epoch 2/10, Train Loss: 1.699Train Acc: 0.446\n",
      "Epoch 3/10, Train Loss: 1.365Train Acc: 0.599\n",
      "Epoch 4/10, Train Loss: 1.083Train Acc: 0.682\n",
      "Epoch 5/10, Train Loss: 0.887Train Acc: 0.737\n",
      "Epoch 6/10, Train Loss: 0.758Train Acc: 0.777\n",
      "Epoch 7/10, Train Loss: 0.657Train Acc: 0.814\n",
      "Epoch 8/10, Train Loss: 0.589Train Acc: 0.830\n",
      "Epoch 9/10, Train Loss: 0.516Train Acc: 0.851\n",
      "Epoch 10/10, Train Loss: 0.474Train Acc: 0.863\n",
      "Finished 90 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.3199195171026157\n",
      "Epoch 1/50, Train Loss: 2.239Train Acc: 0.158\n",
      "Epoch 2/50, Train Loss: 2.004Train Acc: 0.315\n",
      "Epoch 3/50, Train Loss: 1.840Train Acc: 0.374\n",
      "Epoch 4/50, Train Loss: 1.740Train Acc: 0.409\n",
      "Epoch 5/50, Train Loss: 1.622Train Acc: 0.466\n",
      "Epoch 6/50, Train Loss: 1.501Train Acc: 0.518\n",
      "Epoch 7/50, Train Loss: 1.398Train Acc: 0.551\n",
      "Epoch 8/50, Train Loss: 1.323Train Acc: 0.587\n",
      "Epoch 9/50, Train Loss: 1.255Train Acc: 0.609\n",
      "Epoch 10/50, Train Loss: 1.190Train Acc: 0.633\n",
      "Epoch 11/50, Train Loss: 1.130Train Acc: 0.664\n",
      "Epoch 12/50, Train Loss: 1.085Train Acc: 0.674\n",
      "Epoch 13/50, Train Loss: 1.034Train Acc: 0.697\n",
      "Epoch 14/50, Train Loss: 0.970Train Acc: 0.717\n",
      "Epoch 15/50, Train Loss: 0.924Train Acc: 0.741\n",
      "Epoch 16/50, Train Loss: 0.888Train Acc: 0.750\n",
      "Epoch 17/50, Train Loss: 0.857Train Acc: 0.747\n",
      "Epoch 18/50, Train Loss: 0.809Train Acc: 0.766\n",
      "Epoch 19/50, Train Loss: 0.777Train Acc: 0.779\n",
      "Epoch 20/50, Train Loss: 0.757Train Acc: 0.777\n",
      "Epoch 21/50, Train Loss: 0.726Train Acc: 0.793\n",
      "Epoch 22/50, Train Loss: 0.699Train Acc: 0.799\n",
      "Epoch 23/50, Train Loss: 0.698Train Acc: 0.783\n",
      "Epoch 24/50, Train Loss: 0.675Train Acc: 0.800\n",
      "Epoch 25/50, Train Loss: 0.655Train Acc: 0.818\n",
      "Epoch 26/50, Train Loss: 0.613Train Acc: 0.824\n",
      "Epoch 27/50, Train Loss: 0.606Train Acc: 0.818\n",
      "Epoch 28/50, Train Loss: 0.599Train Acc: 0.819\n",
      "Epoch 29/50, Train Loss: 0.572Train Acc: 0.831\n",
      "Epoch 30/50, Train Loss: 0.558Train Acc: 0.835\n",
      "Epoch 31/50, Train Loss: 0.544Train Acc: 0.834\n",
      "Epoch 32/50, Train Loss: 0.533Train Acc: 0.834\n",
      "Epoch 33/50, Train Loss: 0.521Train Acc: 0.845\n",
      "Epoch 34/50, Train Loss: 0.520Train Acc: 0.843\n",
      "Epoch 35/50, Train Loss: 0.489Train Acc: 0.851\n",
      "Epoch 36/50, Train Loss: 0.483Train Acc: 0.850\n",
      "Epoch 37/50, Train Loss: 0.474Train Acc: 0.862\n",
      "Epoch 38/50, Train Loss: 0.460Train Acc: 0.864\n",
      "Epoch 39/50, Train Loss: 0.452Train Acc: 0.865\n",
      "Epoch 40/50, Train Loss: 0.450Train Acc: 0.869\n",
      "Epoch 41/50, Train Loss: 0.437Train Acc: 0.865\n",
      "Epoch 42/50, Train Loss: 0.440Train Acc: 0.861\n",
      "Epoch 43/50, Train Loss: 0.432Train Acc: 0.870\n",
      "Epoch 44/50, Train Loss: 0.417Train Acc: 0.870\n",
      "Epoch 45/50, Train Loss: 0.405Train Acc: 0.876\n",
      "Epoch 46/50, Train Loss: 0.401Train Acc: 0.881\n",
      "Epoch 47/50, Train Loss: 0.387Train Acc: 0.891\n",
      "Epoch 48/50, Train Loss: 0.385Train Acc: 0.894\n",
      "Epoch 49/50, Train Loss: 0.375Train Acc: 0.885\n",
      "Epoch 50/50, Train Loss: 0.378Train Acc: 0.886\n",
      "Finished 91 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.317907444668008\n",
      "Epoch 1/20, Train Loss: 2.318Train Acc: 0.090\n",
      "Epoch 2/20, Train Loss: 2.316Train Acc: 0.095\n",
      "Epoch 3/20, Train Loss: 2.313Train Acc: 0.094\n",
      "Epoch 4/20, Train Loss: 2.314Train Acc: 0.095\n",
      "Epoch 5/20, Train Loss: 2.311Train Acc: 0.102\n",
      "Epoch 6/20, Train Loss: 2.305Train Acc: 0.102\n",
      "Epoch 7/20, Train Loss: 2.312Train Acc: 0.093\n",
      "Epoch 8/20, Train Loss: 2.308Train Acc: 0.099\n",
      "Epoch 9/20, Train Loss: 2.309Train Acc: 0.086\n",
      "Epoch 10/20, Train Loss: 2.311Train Acc: 0.095\n",
      "Epoch 11/20, Train Loss: 2.309Train Acc: 0.086\n",
      "Epoch 12/20, Train Loss: 2.306Train Acc: 0.099\n",
      "Epoch 13/20, Train Loss: 2.307Train Acc: 0.097\n",
      "Epoch 14/20, Train Loss: 2.308Train Acc: 0.092\n",
      "Epoch 15/20, Train Loss: 2.306Train Acc: 0.099\n",
      "Epoch 16/20, Train Loss: 2.307Train Acc: 0.092\n",
      "Epoch 17/20, Train Loss: 2.307Train Acc: 0.093\n",
      "Epoch 18/20, Train Loss: 2.306Train Acc: 0.095\n",
      "Epoch 19/20, Train Loss: 2.304Train Acc: 0.114\n",
      "Epoch 20/20, Train Loss: 2.306Train Acc: 0.100\n",
      "Finished 92 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.09456740442655935\n",
      "Epoch 1/20, Train Loss: 2.234Train Acc: 0.156\n",
      "Epoch 2/20, Train Loss: 2.011Train Acc: 0.261\n",
      "Epoch 3/20, Train Loss: 1.842Train Acc: 0.319\n",
      "Epoch 4/20, Train Loss: 1.734Train Acc: 0.371\n",
      "Epoch 5/20, Train Loss: 1.766Train Acc: 0.366\n",
      "Epoch 6/20, Train Loss: 1.835Train Acc: 0.343\n",
      "Epoch 7/20, Train Loss: 1.608Train Acc: 0.454\n",
      "Epoch 8/20, Train Loss: 1.720Train Acc: 0.376\n",
      "Epoch 9/20, Train Loss: 1.788Train Acc: 0.330\n",
      "Epoch 10/20, Train Loss: 1.672Train Acc: 0.405\n",
      "Epoch 11/20, Train Loss: 2.061Train Acc: 0.275\n",
      "Epoch 12/20, Train Loss: 2.142Train Acc: 0.218\n",
      "Epoch 13/20, Train Loss: 2.101Train Acc: 0.222\n",
      "Epoch 14/20, Train Loss: 2.036Train Acc: 0.227\n",
      "Epoch 15/20, Train Loss: 1.991Train Acc: 0.257\n",
      "Epoch 16/20, Train Loss: 1.936Train Acc: 0.286\n",
      "Epoch 17/20, Train Loss: 1.871Train Acc: 0.317\n",
      "Epoch 18/20, Train Loss: 1.870Train Acc: 0.314\n",
      "Epoch 19/20, Train Loss: 1.871Train Acc: 0.316\n",
      "Epoch 20/20, Train Loss: 1.852Train Acc: 0.309\n",
      "Finished 93 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.18108651911468812\n",
      "Epoch 1/10, Train Loss: 2.320Train Acc: 0.091\n",
      "Epoch 2/10, Train Loss: 2.107Train Acc: 0.223\n",
      "Epoch 3/10, Train Loss: 1.709Train Acc: 0.421\n",
      "Epoch 4/10, Train Loss: 1.396Train Acc: 0.542\n",
      "Epoch 5/10, Train Loss: 1.226Train Acc: 0.606\n",
      "Epoch 6/10, Train Loss: 1.122Train Acc: 0.646\n",
      "Epoch 7/10, Train Loss: 1.068Train Acc: 0.657\n",
      "Epoch 8/10, Train Loss: 1.014Train Acc: 0.676\n",
      "Epoch 9/10, Train Loss: 0.964Train Acc: 0.673\n",
      "Epoch 10/10, Train Loss: 0.966Train Acc: 0.691\n",
      "Finished 94 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.32796780684104626\n",
      "Epoch 1/50, Train Loss: 2.313Train Acc: 0.100\n",
      "Epoch 2/50, Train Loss: 2.162Train Acc: 0.180\n",
      "Epoch 3/50, Train Loss: 1.889Train Acc: 0.282\n",
      "Epoch 4/50, Train Loss: 1.731Train Acc: 0.360\n",
      "Epoch 5/50, Train Loss: 1.660Train Acc: 0.380\n",
      "Epoch 6/50, Train Loss: 1.614Train Acc: 0.405\n",
      "Epoch 7/50, Train Loss: 1.545Train Acc: 0.442\n",
      "Epoch 8/50, Train Loss: 1.456Train Acc: 0.488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Train Loss: 1.419Train Acc: 0.495\n",
      "Epoch 10/50, Train Loss: 1.395Train Acc: 0.500\n",
      "Epoch 11/50, Train Loss: 1.360Train Acc: 0.515\n",
      "Epoch 12/50, Train Loss: 1.312Train Acc: 0.545\n",
      "Epoch 13/50, Train Loss: 1.468Train Acc: 0.483\n",
      "Epoch 14/50, Train Loss: 1.445Train Acc: 0.507\n",
      "Epoch 15/50, Train Loss: 1.262Train Acc: 0.579\n",
      "Epoch 16/50, Train Loss: 1.305Train Acc: 0.554\n",
      "Epoch 17/50, Train Loss: 1.249Train Acc: 0.591\n",
      "Epoch 18/50, Train Loss: 1.361Train Acc: 0.540\n",
      "Epoch 19/50, Train Loss: 1.230Train Acc: 0.601\n",
      "Epoch 20/50, Train Loss: 1.150Train Acc: 0.620\n",
      "Epoch 21/50, Train Loss: 1.074Train Acc: 0.640\n",
      "Epoch 22/50, Train Loss: 1.247Train Acc: 0.584\n",
      "Epoch 23/50, Train Loss: 1.153Train Acc: 0.615\n",
      "Epoch 24/50, Train Loss: 1.237Train Acc: 0.584\n",
      "Epoch 25/50, Train Loss: 1.381Train Acc: 0.496\n",
      "Epoch 26/50, Train Loss: 1.411Train Acc: 0.472\n",
      "Epoch 27/50, Train Loss: 1.211Train Acc: 0.574\n",
      "Epoch 28/50, Train Loss: 1.169Train Acc: 0.602\n",
      "Epoch 29/50, Train Loss: 1.253Train Acc: 0.536\n",
      "Epoch 30/50, Train Loss: 1.212Train Acc: 0.569\n",
      "Epoch 31/50, Train Loss: 1.220Train Acc: 0.550\n",
      "Epoch 32/50, Train Loss: 1.299Train Acc: 0.537\n",
      "Epoch 33/50, Train Loss: 1.109Train Acc: 0.621\n",
      "Epoch 34/50, Train Loss: 1.064Train Acc: 0.642\n",
      "Epoch 35/50, Train Loss: 1.048Train Acc: 0.641\n",
      "Epoch 36/50, Train Loss: 1.009Train Acc: 0.661\n",
      "Epoch 37/50, Train Loss: 1.024Train Acc: 0.658\n",
      "Epoch 38/50, Train Loss: 1.021Train Acc: 0.651\n",
      "Epoch 39/50, Train Loss: 1.024Train Acc: 0.653\n",
      "Epoch 40/50, Train Loss: 1.082Train Acc: 0.645\n",
      "Epoch 41/50, Train Loss: 1.081Train Acc: 0.625\n",
      "Epoch 42/50, Train Loss: 1.035Train Acc: 0.644\n",
      "Epoch 43/50, Train Loss: 1.504Train Acc: 0.450\n",
      "Epoch 44/50, Train Loss: 1.479Train Acc: 0.455\n",
      "Epoch 45/50, Train Loss: 1.519Train Acc: 0.432\n",
      "Epoch 46/50, Train Loss: 1.388Train Acc: 0.493\n",
      "Epoch 47/50, Train Loss: 1.362Train Acc: 0.493\n",
      "Epoch 48/50, Train Loss: 1.358Train Acc: 0.510\n",
      "Epoch 49/50, Train Loss: 1.305Train Acc: 0.535\n",
      "Epoch 50/50, Train Loss: 1.361Train Acc: 0.505\n",
      "Finished 95 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.1790744466800805\n",
      "Epoch 1/20, Train Loss: 1.964Train Acc: 0.314\n",
      "Epoch 2/20, Train Loss: 1.446Train Acc: 0.569\n",
      "Epoch 3/20, Train Loss: 1.039Train Acc: 0.712\n",
      "Epoch 4/20, Train Loss: 0.780Train Acc: 0.798\n",
      "Epoch 5/20, Train Loss: 0.639Train Acc: 0.829\n",
      "Epoch 6/20, Train Loss: 0.543Train Acc: 0.858\n",
      "Epoch 7/20, Train Loss: 0.461Train Acc: 0.880\n",
      "Epoch 8/20, Train Loss: 0.388Train Acc: 0.900\n",
      "Epoch 9/20, Train Loss: 0.350Train Acc: 0.903\n",
      "Epoch 10/20, Train Loss: 0.315Train Acc: 0.915\n",
      "Epoch 11/20, Train Loss: 0.273Train Acc: 0.923\n",
      "Epoch 12/20, Train Loss: 0.242Train Acc: 0.936\n",
      "Epoch 13/20, Train Loss: 0.230Train Acc: 0.934\n",
      "Epoch 14/20, Train Loss: 0.218Train Acc: 0.939\n",
      "Epoch 15/20, Train Loss: 0.172Train Acc: 0.952\n",
      "Epoch 16/20, Train Loss: 0.146Train Acc: 0.964\n",
      "Epoch 17/20, Train Loss: 0.152Train Acc: 0.958\n",
      "Epoch 18/20, Train Loss: 0.119Train Acc: 0.967\n",
      "Epoch 19/20, Train Loss: 0.097Train Acc: 0.975\n",
      "Epoch 20/20, Train Loss: 0.093Train Acc: 0.976\n",
      "Finished 96 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.4104627766599598\n",
      "Epoch 1/10, Train Loss: 1.997Train Acc: 0.273\n",
      "Epoch 2/10, Train Loss: 1.719Train Acc: 0.387\n",
      "Epoch 3/10, Train Loss: 1.599Train Acc: 0.453\n",
      "Epoch 4/10, Train Loss: 1.642Train Acc: 0.449\n",
      "Epoch 5/10, Train Loss: 1.511Train Acc: 0.485\n",
      "Epoch 6/10, Train Loss: 1.473Train Acc: 0.517\n",
      "Epoch 7/10, Train Loss: 1.367Train Acc: 0.533\n",
      "Epoch 8/10, Train Loss: 1.281Train Acc: 0.562\n",
      "Epoch 9/10, Train Loss: 1.300Train Acc: 0.566\n",
      "Epoch 10/10, Train Loss: 1.320Train Acc: 0.553\n",
      "Finished 97 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.23340040241448692\n",
      "Epoch 1/10, Train Loss: 2.378Train Acc: 0.099\n",
      "Epoch 2/10, Train Loss: 2.366Train Acc: 0.104\n",
      "Epoch 3/10, Train Loss: 2.344Train Acc: 0.089\n",
      "Epoch 4/10, Train Loss: 2.363Train Acc: 0.100\n",
      "Epoch 5/10, Train Loss: 2.369Train Acc: 0.109\n",
      "Epoch 6/10, Train Loss: 2.357Train Acc: 0.111\n",
      "Epoch 7/10, Train Loss: 2.366Train Acc: 0.097\n",
      "Epoch 8/10, Train Loss: 2.369Train Acc: 0.090\n",
      "Epoch 9/10, Train Loss: 2.354Train Acc: 0.093\n",
      "Epoch 10/10, Train Loss: 2.324Train Acc: 0.117\n",
      "Finished 98 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.13078470824949698\n",
      "Epoch 1/50, Train Loss: 2.348Train Acc: 0.143\n",
      "Epoch 2/50, Train Loss: 2.375Train Acc: 0.108\n",
      "Epoch 3/50, Train Loss: 2.269Train Acc: 0.156\n",
      "Epoch 4/50, Train Loss: 2.315Train Acc: 0.126\n",
      "Epoch 5/50, Train Loss: 2.196Train Acc: 0.201\n",
      "Epoch 6/50, Train Loss: 2.239Train Acc: 0.183\n",
      "Epoch 7/50, Train Loss: 2.112Train Acc: 0.225\n",
      "Epoch 8/50, Train Loss: 1.999Train Acc: 0.266\n",
      "Epoch 9/50, Train Loss: 2.028Train Acc: 0.260\n",
      "Epoch 10/50, Train Loss: 2.232Train Acc: 0.192\n",
      "Epoch 11/50, Train Loss: 2.384Train Acc: 0.141\n",
      "Epoch 12/50, Train Loss: 2.349Train Acc: 0.127\n",
      "Epoch 13/50, Train Loss: 2.325Train Acc: 0.142\n",
      "Epoch 14/50, Train Loss: 2.347Train Acc: 0.124\n",
      "Epoch 15/50, Train Loss: 2.327Train Acc: 0.139\n",
      "Epoch 16/50, Train Loss: 2.299Train Acc: 0.164\n",
      "Epoch 17/50, Train Loss: 2.153Train Acc: 0.210\n",
      "Epoch 18/50, Train Loss: 2.168Train Acc: 0.206\n",
      "Epoch 19/50, Train Loss: 2.112Train Acc: 0.220\n",
      "Epoch 20/50, Train Loss: 2.209Train Acc: 0.201\n",
      "Epoch 21/50, Train Loss: 2.068Train Acc: 0.234\n",
      "Epoch 22/50, Train Loss: 2.054Train Acc: 0.240\n",
      "Epoch 23/50, Train Loss: 2.140Train Acc: 0.234\n",
      "Epoch 24/50, Train Loss: 2.066Train Acc: 0.241\n",
      "Epoch 25/50, Train Loss: 2.090Train Acc: 0.241\n",
      "Epoch 26/50, Train Loss: 2.160Train Acc: 0.222\n",
      "Epoch 27/50, Train Loss: 2.198Train Acc: 0.194\n",
      "Epoch 28/50, Train Loss: 2.156Train Acc: 0.197\n",
      "Epoch 29/50, Train Loss: 2.058Train Acc: 0.253\n",
      "Epoch 30/50, Train Loss: 2.037Train Acc: 0.248\n",
      "Epoch 31/50, Train Loss: 2.060Train Acc: 0.238\n",
      "Epoch 32/50, Train Loss: 2.072Train Acc: 0.246\n",
      "Epoch 33/50, Train Loss: 2.060Train Acc: 0.247\n",
      "Epoch 34/50, Train Loss: 2.006Train Acc: 0.250\n",
      "Epoch 35/50, Train Loss: 2.009Train Acc: 0.257\n",
      "Epoch 36/50, Train Loss: 1.996Train Acc: 0.271\n",
      "Epoch 37/50, Train Loss: 1.987Train Acc: 0.268\n",
      "Epoch 38/50, Train Loss: 2.018Train Acc: 0.271\n",
      "Epoch 39/50, Train Loss: 2.263Train Acc: 0.188\n",
      "Epoch 40/50, Train Loss: 2.252Train Acc: 0.169\n",
      "Epoch 41/50, Train Loss: 2.246Train Acc: 0.172\n",
      "Epoch 42/50, Train Loss: 2.144Train Acc: 0.217\n",
      "Epoch 43/50, Train Loss: 2.177Train Acc: 0.213\n",
      "Epoch 44/50, Train Loss: 2.126Train Acc: 0.225\n",
      "Epoch 45/50, Train Loss: 2.137Train Acc: 0.200\n",
      "Epoch 46/50, Train Loss: 2.072Train Acc: 0.240\n",
      "Epoch 47/50, Train Loss: 2.060Train Acc: 0.245\n",
      "Epoch 48/50, Train Loss: 2.104Train Acc: 0.228\n",
      "Epoch 49/50, Train Loss: 2.122Train Acc: 0.211\n",
      "Epoch 50/50, Train Loss: 2.111Train Acc: 0.213\n",
      "Finished 99 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.12877263581488935\n",
      "Epoch 1/20, Train Loss: 2.316Train Acc: 0.100\n",
      "Epoch 2/20, Train Loss: 2.317Train Acc: 0.105\n",
      "Epoch 3/20, Train Loss: 2.316Train Acc: 0.096\n",
      "Epoch 4/20, Train Loss: 2.314Train Acc: 0.106\n",
      "Epoch 5/20, Train Loss: 2.318Train Acc: 0.093\n",
      "Epoch 6/20, Train Loss: 2.314Train Acc: 0.095\n",
      "Epoch 7/20, Train Loss: 2.312Train Acc: 0.095\n",
      "Epoch 8/20, Train Loss: 2.309Train Acc: 0.110\n",
      "Epoch 9/20, Train Loss: 2.319Train Acc: 0.089\n",
      "Epoch 10/20, Train Loss: 2.313Train Acc: 0.098\n",
      "Epoch 11/20, Train Loss: 2.315Train Acc: 0.092\n",
      "Epoch 12/20, Train Loss: 2.310Train Acc: 0.092\n",
      "Epoch 13/20, Train Loss: 2.309Train Acc: 0.095\n",
      "Epoch 14/20, Train Loss: 2.311Train Acc: 0.100\n",
      "Epoch 15/20, Train Loss: 2.310Train Acc: 0.093\n",
      "Epoch 16/20, Train Loss: 2.311Train Acc: 0.092\n",
      "Epoch 17/20, Train Loss: 2.307Train Acc: 0.112\n",
      "Epoch 18/20, Train Loss: 2.311Train Acc: 0.091\n",
      "Epoch 19/20, Train Loss: 2.308Train Acc: 0.098\n",
      "Epoch 20/20, Train Loss: 2.312Train Acc: 0.096\n",
      "Finished 100 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.1006036217303823\n",
      "Epoch 1/50, Train Loss: 1.949Train Acc: 0.296\n",
      "Epoch 2/50, Train Loss: 1.439Train Acc: 0.520\n",
      "Epoch 3/50, Train Loss: 1.177Train Acc: 0.621\n",
      "Epoch 4/50, Train Loss: 1.139Train Acc: 0.622\n",
      "Epoch 5/50, Train Loss: 1.086Train Acc: 0.633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Train Loss: 1.035Train Acc: 0.659\n",
      "Epoch 7/50, Train Loss: 1.098Train Acc: 0.641\n",
      "Epoch 8/50, Train Loss: 1.161Train Acc: 0.623\n",
      "Epoch 9/50, Train Loss: 1.187Train Acc: 0.605\n",
      "Epoch 10/50, Train Loss: 1.211Train Acc: 0.590\n",
      "Epoch 11/50, Train Loss: 1.175Train Acc: 0.609\n",
      "Epoch 12/50, Train Loss: 1.219Train Acc: 0.599\n",
      "Epoch 13/50, Train Loss: 1.375Train Acc: 0.549\n",
      "Epoch 14/50, Train Loss: 1.303Train Acc: 0.567\n",
      "Epoch 15/50, Train Loss: 1.243Train Acc: 0.597\n",
      "Epoch 16/50, Train Loss: 1.336Train Acc: 0.556\n",
      "Epoch 17/50, Train Loss: 1.258Train Acc: 0.587\n",
      "Epoch 18/50, Train Loss: 1.232Train Acc: 0.583\n",
      "Epoch 19/50, Train Loss: 1.252Train Acc: 0.586\n",
      "Epoch 20/50, Train Loss: 1.241Train Acc: 0.586\n",
      "Epoch 21/50, Train Loss: 1.350Train Acc: 0.539\n",
      "Epoch 22/50, Train Loss: 1.537Train Acc: 0.469\n",
      "Epoch 23/50, Train Loss: 1.432Train Acc: 0.508\n",
      "Epoch 24/50, Train Loss: 1.386Train Acc: 0.524\n",
      "Epoch 25/50, Train Loss: 1.422Train Acc: 0.510\n",
      "Epoch 26/50, Train Loss: 1.560Train Acc: 0.472\n",
      "Epoch 27/50, Train Loss: 1.549Train Acc: 0.472\n",
      "Epoch 28/50, Train Loss: 1.680Train Acc: 0.421\n",
      "Epoch 29/50, Train Loss: 1.751Train Acc: 0.385\n",
      "Epoch 30/50, Train Loss: 1.780Train Acc: 0.375\n",
      "Epoch 31/50, Train Loss: 1.757Train Acc: 0.381\n",
      "Epoch 32/50, Train Loss: 1.627Train Acc: 0.439\n",
      "Epoch 33/50, Train Loss: 1.674Train Acc: 0.420\n",
      "Epoch 34/50, Train Loss: 1.703Train Acc: 0.407\n",
      "Epoch 35/50, Train Loss: 1.686Train Acc: 0.406\n",
      "Epoch 36/50, Train Loss: 1.663Train Acc: 0.410\n",
      "Epoch 37/50, Train Loss: 1.628Train Acc: 0.438\n",
      "Epoch 38/50, Train Loss: 1.655Train Acc: 0.437\n",
      "Epoch 39/50, Train Loss: 1.669Train Acc: 0.407\n",
      "Epoch 40/50, Train Loss: 1.648Train Acc: 0.415\n",
      "Epoch 41/50, Train Loss: 1.682Train Acc: 0.401\n",
      "Epoch 42/50, Train Loss: 1.691Train Acc: 0.401\n",
      "Epoch 43/50, Train Loss: 1.681Train Acc: 0.410\n",
      "Epoch 44/50, Train Loss: 1.672Train Acc: 0.416\n",
      "Epoch 45/50, Train Loss: 1.658Train Acc: 0.412\n",
      "Epoch 46/50, Train Loss: 1.649Train Acc: 0.430\n",
      "Epoch 47/50, Train Loss: 1.706Train Acc: 0.395\n",
      "Epoch 48/50, Train Loss: 1.707Train Acc: 0.408\n",
      "Epoch 49/50, Train Loss: 1.810Train Acc: 0.363\n",
      "Epoch 50/50, Train Loss: 1.794Train Acc: 0.368\n",
      "Finished 101 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.1710261569416499\n",
      "Epoch 1/20, Train Loss: 2.371Train Acc: 0.097\n",
      "Epoch 2/20, Train Loss: 2.360Train Acc: 0.105\n",
      "Epoch 3/20, Train Loss: 2.363Train Acc: 0.089\n",
      "Epoch 4/20, Train Loss: 2.368Train Acc: 0.094\n",
      "Epoch 5/20, Train Loss: 2.355Train Acc: 0.102\n",
      "Epoch 6/20, Train Loss: 2.358Train Acc: 0.104\n",
      "Epoch 7/20, Train Loss: 2.366Train Acc: 0.088\n",
      "Epoch 8/20, Train Loss: 2.346Train Acc: 0.097\n",
      "Epoch 9/20, Train Loss: 2.383Train Acc: 0.097\n",
      "Epoch 10/20, Train Loss: 2.380Train Acc: 0.108\n",
      "Epoch 11/20, Train Loss: 2.351Train Acc: 0.094\n",
      "Epoch 12/20, Train Loss: 2.374Train Acc: 0.100\n",
      "Epoch 13/20, Train Loss: 2.358Train Acc: 0.098\n",
      "Epoch 14/20, Train Loss: 2.377Train Acc: 0.095\n",
      "Epoch 15/20, Train Loss: 2.373Train Acc: 0.093\n",
      "Epoch 16/20, Train Loss: 2.364Train Acc: 0.102\n",
      "Epoch 17/20, Train Loss: 2.377Train Acc: 0.089\n",
      "Epoch 18/20, Train Loss: 2.361Train Acc: 0.094\n",
      "Epoch 19/20, Train Loss: 2.362Train Acc: 0.096\n",
      "Epoch 20/20, Train Loss: 2.376Train Acc: 0.100\n",
      "Finished 102 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.1006036217303823\n",
      "Epoch 1/50, Train Loss: 2.368Train Acc: 0.100\n",
      "Epoch 2/50, Train Loss: 2.378Train Acc: 0.086\n",
      "Epoch 3/50, Train Loss: 2.363Train Acc: 0.103\n",
      "Epoch 4/50, Train Loss: 2.385Train Acc: 0.096\n",
      "Epoch 5/50, Train Loss: 2.362Train Acc: 0.086\n",
      "Epoch 6/50, Train Loss: 2.361Train Acc: 0.097\n",
      "Epoch 7/50, Train Loss: 2.358Train Acc: 0.095\n",
      "Epoch 8/50, Train Loss: 2.373Train Acc: 0.087\n",
      "Epoch 9/50, Train Loss: 2.353Train Acc: 0.099\n",
      "Epoch 10/50, Train Loss: 2.360Train Acc: 0.101\n",
      "Epoch 11/50, Train Loss: 2.345Train Acc: 0.111\n",
      "Epoch 12/50, Train Loss: 2.356Train Acc: 0.105\n",
      "Epoch 13/50, Train Loss: 2.366Train Acc: 0.102\n",
      "Epoch 14/50, Train Loss: 2.367Train Acc: 0.097\n",
      "Epoch 15/50, Train Loss: 2.365Train Acc: 0.088\n",
      "Epoch 16/50, Train Loss: 2.349Train Acc: 0.100\n",
      "Epoch 17/50, Train Loss: 2.370Train Acc: 0.105\n",
      "Epoch 18/50, Train Loss: 2.375Train Acc: 0.102\n",
      "Epoch 19/50, Train Loss: 2.351Train Acc: 0.100\n",
      "Epoch 20/50, Train Loss: 2.346Train Acc: 0.099\n",
      "Epoch 21/50, Train Loss: 2.379Train Acc: 0.103\n",
      "Epoch 22/50, Train Loss: 2.380Train Acc: 0.092\n",
      "Epoch 23/50, Train Loss: 2.353Train Acc: 0.088\n",
      "Epoch 24/50, Train Loss: 2.360Train Acc: 0.088\n",
      "Epoch 25/50, Train Loss: 2.365Train Acc: 0.094\n",
      "Epoch 26/50, Train Loss: 2.370Train Acc: 0.090\n",
      "Epoch 27/50, Train Loss: 2.360Train Acc: 0.096\n",
      "Epoch 28/50, Train Loss: 2.374Train Acc: 0.096\n",
      "Epoch 29/50, Train Loss: 2.361Train Acc: 0.100\n",
      "Epoch 30/50, Train Loss: 2.372Train Acc: 0.090\n",
      "Epoch 31/50, Train Loss: 2.378Train Acc: 0.098\n",
      "Epoch 32/50, Train Loss: 2.355Train Acc: 0.108\n",
      "Epoch 33/50, Train Loss: 2.363Train Acc: 0.096\n",
      "Epoch 34/50, Train Loss: 2.352Train Acc: 0.096\n",
      "Epoch 35/50, Train Loss: 2.366Train Acc: 0.101\n",
      "Epoch 36/50, Train Loss: 2.367Train Acc: 0.098\n",
      "Epoch 37/50, Train Loss: 2.374Train Acc: 0.101\n",
      "Epoch 38/50, Train Loss: 2.362Train Acc: 0.100\n",
      "Epoch 39/50, Train Loss: 2.355Train Acc: 0.098\n",
      "Epoch 40/50, Train Loss: 2.377Train Acc: 0.089\n",
      "Epoch 41/50, Train Loss: 2.357Train Acc: 0.092\n",
      "Epoch 42/50, Train Loss: 2.378Train Acc: 0.088\n",
      "Epoch 43/50, Train Loss: 2.358Train Acc: 0.108\n",
      "Epoch 44/50, Train Loss: 2.360Train Acc: 0.099\n",
      "Epoch 45/50, Train Loss: 2.353Train Acc: 0.100\n",
      "Epoch 46/50, Train Loss: 2.359Train Acc: 0.097\n",
      "Epoch 47/50, Train Loss: 2.374Train Acc: 0.089\n",
      "Epoch 48/50, Train Loss: 2.363Train Acc: 0.097\n",
      "Epoch 49/50, Train Loss: 2.373Train Acc: 0.098\n",
      "Epoch 50/50, Train Loss: 2.359Train Acc: 0.089\n",
      "Finished 103 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.10663983903420524\n",
      "Epoch 1/50, Train Loss: 2.317Train Acc: 0.095\n",
      "Epoch 2/50, Train Loss: 2.317Train Acc: 0.095\n",
      "Epoch 3/50, Train Loss: 2.315Train Acc: 0.091\n",
      "Epoch 4/50, Train Loss: 2.316Train Acc: 0.117\n",
      "Epoch 5/50, Train Loss: 2.323Train Acc: 0.101\n",
      "Epoch 6/50, Train Loss: 2.315Train Acc: 0.099\n",
      "Epoch 7/50, Train Loss: 2.313Train Acc: 0.105\n",
      "Epoch 8/50, Train Loss: 2.313Train Acc: 0.102\n",
      "Epoch 9/50, Train Loss: 2.313Train Acc: 0.109\n",
      "Epoch 10/50, Train Loss: 2.309Train Acc: 0.110\n",
      "Epoch 11/50, Train Loss: 2.316Train Acc: 0.102\n",
      "Epoch 12/50, Train Loss: 2.311Train Acc: 0.105\n",
      "Epoch 13/50, Train Loss: 2.314Train Acc: 0.100\n",
      "Epoch 14/50, Train Loss: 2.314Train Acc: 0.102\n",
      "Epoch 15/50, Train Loss: 2.314Train Acc: 0.089\n",
      "Epoch 16/50, Train Loss: 2.310Train Acc: 0.097\n",
      "Epoch 17/50, Train Loss: 2.310Train Acc: 0.092\n",
      "Epoch 18/50, Train Loss: 2.311Train Acc: 0.111\n",
      "Epoch 19/50, Train Loss: 2.309Train Acc: 0.102\n",
      "Epoch 20/50, Train Loss: 2.311Train Acc: 0.102\n",
      "Epoch 21/50, Train Loss: 2.310Train Acc: 0.094\n",
      "Epoch 22/50, Train Loss: 2.312Train Acc: 0.091\n",
      "Epoch 23/50, Train Loss: 2.311Train Acc: 0.088\n",
      "Epoch 24/50, Train Loss: 2.314Train Acc: 0.094\n",
      "Epoch 25/50, Train Loss: 2.307Train Acc: 0.095\n",
      "Epoch 26/50, Train Loss: 2.314Train Acc: 0.103\n",
      "Epoch 27/50, Train Loss: 2.308Train Acc: 0.102\n",
      "Epoch 28/50, Train Loss: 2.311Train Acc: 0.105\n",
      "Epoch 29/50, Train Loss: 2.313Train Acc: 0.091\n",
      "Epoch 30/50, Train Loss: 2.307Train Acc: 0.100\n",
      "Epoch 31/50, Train Loss: 2.306Train Acc: 0.099\n",
      "Epoch 32/50, Train Loss: 2.313Train Acc: 0.099\n",
      "Epoch 33/50, Train Loss: 2.308Train Acc: 0.100\n",
      "Epoch 34/50, Train Loss: 2.308Train Acc: 0.091\n",
      "Epoch 35/50, Train Loss: 2.307Train Acc: 0.099\n",
      "Epoch 36/50, Train Loss: 2.306Train Acc: 0.104\n",
      "Epoch 37/50, Train Loss: 2.305Train Acc: 0.105\n",
      "Epoch 38/50, Train Loss: 2.309Train Acc: 0.097\n",
      "Epoch 39/50, Train Loss: 2.308Train Acc: 0.103\n",
      "Epoch 40/50, Train Loss: 2.308Train Acc: 0.104\n",
      "Epoch 41/50, Train Loss: 2.309Train Acc: 0.102\n",
      "Epoch 42/50, Train Loss: 2.313Train Acc: 0.089\n",
      "Epoch 43/50, Train Loss: 2.309Train Acc: 0.092\n",
      "Epoch 44/50, Train Loss: 2.310Train Acc: 0.088\n",
      "Epoch 45/50, Train Loss: 2.307Train Acc: 0.093\n",
      "Epoch 46/50, Train Loss: 2.307Train Acc: 0.107\n",
      "Epoch 47/50, Train Loss: 2.310Train Acc: 0.096\n",
      "Epoch 48/50, Train Loss: 2.309Train Acc: 0.095\n",
      "Epoch 49/50, Train Loss: 2.310Train Acc: 0.091\n",
      "Epoch 50/50, Train Loss: 2.305Train Acc: 0.102\n",
      "Finished 104 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.10865191146881288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 2.331Train Acc: 0.104\n",
      "Epoch 2/50, Train Loss: 2.331Train Acc: 0.093\n",
      "Epoch 3/50, Train Loss: 2.320Train Acc: 0.093\n",
      "Epoch 4/50, Train Loss: 2.320Train Acc: 0.100\n",
      "Epoch 5/50, Train Loss: 2.318Train Acc: 0.097\n",
      "Epoch 6/50, Train Loss: 2.320Train Acc: 0.099\n",
      "Epoch 7/50, Train Loss: 2.322Train Acc: 0.099\n",
      "Epoch 8/50, Train Loss: 2.322Train Acc: 0.098\n",
      "Epoch 9/50, Train Loss: 2.326Train Acc: 0.086\n",
      "Epoch 10/50, Train Loss: 2.320Train Acc: 0.093\n",
      "Epoch 11/50, Train Loss: 2.324Train Acc: 0.104\n",
      "Epoch 12/50, Train Loss: 2.327Train Acc: 0.103\n",
      "Epoch 13/50, Train Loss: 2.327Train Acc: 0.100\n",
      "Epoch 14/50, Train Loss: 2.324Train Acc: 0.111\n",
      "Epoch 15/50, Train Loss: 2.332Train Acc: 0.090\n",
      "Epoch 16/50, Train Loss: 2.327Train Acc: 0.096\n",
      "Epoch 17/50, Train Loss: 2.323Train Acc: 0.093\n",
      "Epoch 18/50, Train Loss: 2.332Train Acc: 0.091\n",
      "Epoch 19/50, Train Loss: 2.327Train Acc: 0.102\n",
      "Epoch 20/50, Train Loss: 2.321Train Acc: 0.108\n",
      "Epoch 21/50, Train Loss: 2.326Train Acc: 0.099\n",
      "Epoch 22/50, Train Loss: 2.332Train Acc: 0.100\n",
      "Epoch 23/50, Train Loss: 2.331Train Acc: 0.099\n",
      "Epoch 24/50, Train Loss: 2.332Train Acc: 0.100\n",
      "Epoch 25/50, Train Loss: 2.334Train Acc: 0.095\n",
      "Epoch 26/50, Train Loss: 2.334Train Acc: 0.092\n",
      "Epoch 27/50, Train Loss: 2.333Train Acc: 0.088\n",
      "Epoch 28/50, Train Loss: 2.326Train Acc: 0.105\n",
      "Epoch 29/50, Train Loss: 2.330Train Acc: 0.101\n",
      "Epoch 30/50, Train Loss: 2.328Train Acc: 0.095\n",
      "Epoch 31/50, Train Loss: 2.326Train Acc: 0.095\n",
      "Epoch 32/50, Train Loss: 2.327Train Acc: 0.089\n",
      "Epoch 33/50, Train Loss: 2.327Train Acc: 0.100\n",
      "Epoch 34/50, Train Loss: 2.322Train Acc: 0.111\n",
      "Epoch 35/50, Train Loss: 2.338Train Acc: 0.094\n",
      "Epoch 36/50, Train Loss: 2.334Train Acc: 0.088\n",
      "Epoch 37/50, Train Loss: 2.331Train Acc: 0.099\n",
      "Epoch 38/50, Train Loss: 2.332Train Acc: 0.095\n",
      "Epoch 39/50, Train Loss: 2.318Train Acc: 0.104\n",
      "Epoch 40/50, Train Loss: 2.328Train Acc: 0.106\n",
      "Epoch 41/50, Train Loss: 2.332Train Acc: 0.103\n",
      "Epoch 42/50, Train Loss: 2.332Train Acc: 0.097\n",
      "Epoch 43/50, Train Loss: 2.327Train Acc: 0.101\n",
      "Epoch 44/50, Train Loss: 2.330Train Acc: 0.092\n",
      "Epoch 45/50, Train Loss: 2.327Train Acc: 0.095\n",
      "Epoch 46/50, Train Loss: 2.333Train Acc: 0.097\n",
      "Epoch 47/50, Train Loss: 2.334Train Acc: 0.083\n",
      "Epoch 48/50, Train Loss: 2.332Train Acc: 0.091\n",
      "Epoch 49/50, Train Loss: 2.331Train Acc: 0.094\n",
      "Epoch 50/50, Train Loss: 2.335Train Acc: 0.084\n",
      "Finished 105 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.0925553319919517\n",
      "Epoch 1/50, Train Loss: 2.290Train Acc: 0.146\n",
      "Epoch 2/50, Train Loss: 2.267Train Acc: 0.160\n",
      "Epoch 3/50, Train Loss: 2.296Train Acc: 0.151\n",
      "Epoch 4/50, Train Loss: 2.286Train Acc: 0.162\n",
      "Epoch 5/50, Train Loss: 2.168Train Acc: 0.228\n",
      "Epoch 6/50, Train Loss: 2.261Train Acc: 0.202\n",
      "Epoch 7/50, Train Loss: 2.215Train Acc: 0.187\n",
      "Epoch 8/50, Train Loss: 2.146Train Acc: 0.216\n",
      "Epoch 9/50, Train Loss: 2.189Train Acc: 0.240\n",
      "Epoch 10/50, Train Loss: 2.394Train Acc: 0.131\n",
      "Epoch 11/50, Train Loss: 2.309Train Acc: 0.134\n",
      "Epoch 12/50, Train Loss: 2.311Train Acc: 0.158\n",
      "Epoch 13/50, Train Loss: 2.295Train Acc: 0.157\n",
      "Epoch 14/50, Train Loss: 2.340Train Acc: 0.140\n",
      "Epoch 15/50, Train Loss: 2.207Train Acc: 0.174\n",
      "Epoch 16/50, Train Loss: 2.034Train Acc: 0.267\n",
      "Epoch 17/50, Train Loss: 1.967Train Acc: 0.271\n",
      "Epoch 18/50, Train Loss: 1.969Train Acc: 0.281\n",
      "Epoch 19/50, Train Loss: 2.152Train Acc: 0.215\n",
      "Epoch 20/50, Train Loss: 2.088Train Acc: 0.228\n",
      "Epoch 21/50, Train Loss: 2.072Train Acc: 0.226\n",
      "Epoch 22/50, Train Loss: 2.097Train Acc: 0.234\n",
      "Epoch 23/50, Train Loss: 2.099Train Acc: 0.233\n",
      "Epoch 24/50, Train Loss: 2.177Train Acc: 0.199\n",
      "Epoch 25/50, Train Loss: 2.132Train Acc: 0.209\n",
      "Epoch 26/50, Train Loss: 2.082Train Acc: 0.222\n",
      "Epoch 27/50, Train Loss: 2.095Train Acc: 0.218\n",
      "Epoch 28/50, Train Loss: 2.076Train Acc: 0.245\n",
      "Epoch 29/50, Train Loss: 2.331Train Acc: 0.145\n",
      "Epoch 30/50, Train Loss: 2.128Train Acc: 0.215\n",
      "Epoch 31/50, Train Loss: 2.244Train Acc: 0.174\n",
      "Epoch 32/50, Train Loss: 2.187Train Acc: 0.192\n",
      "Epoch 33/50, Train Loss: 2.195Train Acc: 0.190\n",
      "Epoch 34/50, Train Loss: 2.136Train Acc: 0.211\n",
      "Epoch 35/50, Train Loss: 2.120Train Acc: 0.226\n",
      "Epoch 36/50, Train Loss: 2.371Train Acc: 0.147\n",
      "Epoch 37/50, Train Loss: 2.372Train Acc: 0.120\n",
      "Epoch 38/50, Train Loss: 2.299Train Acc: 0.138\n",
      "Epoch 39/50, Train Loss: 2.307Train Acc: 0.143\n",
      "Epoch 40/50, Train Loss: 2.268Train Acc: 0.157\n",
      "Epoch 41/50, Train Loss: 2.287Train Acc: 0.145\n",
      "Epoch 42/50, Train Loss: 2.301Train Acc: 0.144\n",
      "Epoch 43/50, Train Loss: 2.306Train Acc: 0.141\n",
      "Epoch 44/50, Train Loss: 2.297Train Acc: 0.148\n",
      "Epoch 45/50, Train Loss: 2.237Train Acc: 0.159\n",
      "Epoch 46/50, Train Loss: 2.247Train Acc: 0.170\n",
      "Epoch 47/50, Train Loss: 2.249Train Acc: 0.169\n",
      "Epoch 48/50, Train Loss: 2.258Train Acc: 0.165\n",
      "Epoch 49/50, Train Loss: 2.246Train Acc: 0.172\n",
      "Epoch 50/50, Train Loss: 2.241Train Acc: 0.162\n",
      "Finished 106 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.08853118712273642\n",
      "Epoch 1/10, Train Loss: 2.173Train Acc: 0.208\n",
      "Epoch 2/10, Train Loss: 2.033Train Acc: 0.262\n",
      "Epoch 3/10, Train Loss: 1.996Train Acc: 0.280\n",
      "Epoch 4/10, Train Loss: 2.294Train Acc: 0.160\n",
      "Epoch 5/10, Train Loss: 2.037Train Acc: 0.238\n",
      "Epoch 6/10, Train Loss: 1.926Train Acc: 0.292\n",
      "Epoch 7/10, Train Loss: 2.235Train Acc: 0.205\n",
      "Epoch 8/10, Train Loss: 2.162Train Acc: 0.209\n",
      "Epoch 9/10, Train Loss: 2.123Train Acc: 0.208\n",
      "Epoch 10/10, Train Loss: 2.110Train Acc: 0.214\n",
      "Finished 107 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.13883299798792756\n",
      "Epoch 1/10, Train Loss: 1.763Train Acc: 0.392\n",
      "Epoch 2/10, Train Loss: 1.155Train Acc: 0.630\n",
      "Epoch 3/10, Train Loss: 0.948Train Acc: 0.711\n",
      "Epoch 4/10, Train Loss: 0.832Train Acc: 0.736\n",
      "Epoch 5/10, Train Loss: 0.781Train Acc: 0.755\n",
      "Epoch 6/10, Train Loss: 0.769Train Acc: 0.748\n",
      "Epoch 7/10, Train Loss: 0.848Train Acc: 0.730\n",
      "Epoch 8/10, Train Loss: 0.963Train Acc: 0.700\n",
      "Epoch 9/10, Train Loss: 0.847Train Acc: 0.726\n",
      "Epoch 10/10, Train Loss: 0.753Train Acc: 0.763\n",
      "Finished 108 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.323943661971831\n",
      "Epoch 1/50, Train Loss: 1.820Train Acc: 0.365\n",
      "Epoch 2/50, Train Loss: 1.344Train Acc: 0.566\n",
      "Epoch 3/50, Train Loss: 1.088Train Acc: 0.632\n",
      "Epoch 4/50, Train Loss: 1.088Train Acc: 0.650\n",
      "Epoch 5/50, Train Loss: 1.006Train Acc: 0.666\n",
      "Epoch 6/50, Train Loss: 0.994Train Acc: 0.677\n",
      "Epoch 7/50, Train Loss: 1.040Train Acc: 0.657\n",
      "Epoch 8/50, Train Loss: 1.180Train Acc: 0.634\n",
      "Epoch 9/50, Train Loss: 1.103Train Acc: 0.645\n",
      "Epoch 10/50, Train Loss: 1.165Train Acc: 0.633\n",
      "Epoch 11/50, Train Loss: 1.595Train Acc: 0.459\n",
      "Epoch 12/50, Train Loss: 1.456Train Acc: 0.505\n",
      "Epoch 13/50, Train Loss: 1.370Train Acc: 0.544\n",
      "Epoch 14/50, Train Loss: 1.313Train Acc: 0.553\n",
      "Epoch 15/50, Train Loss: 1.373Train Acc: 0.531\n",
      "Epoch 16/50, Train Loss: 1.592Train Acc: 0.465\n",
      "Epoch 17/50, Train Loss: 1.520Train Acc: 0.477\n",
      "Epoch 18/50, Train Loss: 1.510Train Acc: 0.473\n",
      "Epoch 19/50, Train Loss: 1.588Train Acc: 0.456\n",
      "Epoch 20/50, Train Loss: 1.624Train Acc: 0.421\n",
      "Epoch 21/50, Train Loss: 1.524Train Acc: 0.462\n",
      "Epoch 22/50, Train Loss: 1.552Train Acc: 0.455\n",
      "Epoch 23/50, Train Loss: 1.470Train Acc: 0.508\n",
      "Epoch 24/50, Train Loss: 1.519Train Acc: 0.476\n",
      "Epoch 25/50, Train Loss: 1.534Train Acc: 0.479\n",
      "Epoch 26/50, Train Loss: 1.577Train Acc: 0.451\n",
      "Epoch 27/50, Train Loss: 1.479Train Acc: 0.476\n",
      "Epoch 28/50, Train Loss: 1.569Train Acc: 0.456\n",
      "Epoch 29/50, Train Loss: 1.573Train Acc: 0.447\n",
      "Epoch 30/50, Train Loss: 1.495Train Acc: 0.477\n",
      "Epoch 31/50, Train Loss: 1.562Train Acc: 0.451\n",
      "Epoch 32/50, Train Loss: 1.644Train Acc: 0.415\n",
      "Epoch 33/50, Train Loss: 1.670Train Acc: 0.407\n",
      "Epoch 34/50, Train Loss: 1.801Train Acc: 0.384\n",
      "Epoch 35/50, Train Loss: 1.666Train Acc: 0.419\n",
      "Epoch 36/50, Train Loss: 1.759Train Acc: 0.387\n",
      "Epoch 37/50, Train Loss: 1.625Train Acc: 0.425\n",
      "Epoch 38/50, Train Loss: 1.580Train Acc: 0.442\n",
      "Epoch 39/50, Train Loss: 1.524Train Acc: 0.443\n",
      "Epoch 40/50, Train Loss: 1.722Train Acc: 0.412\n",
      "Epoch 41/50, Train Loss: 1.705Train Acc: 0.396\n",
      "Epoch 42/50, Train Loss: 1.689Train Acc: 0.396\n",
      "Epoch 43/50, Train Loss: 1.652Train Acc: 0.413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Train Loss: 1.581Train Acc: 0.445\n",
      "Epoch 45/50, Train Loss: 1.611Train Acc: 0.422\n",
      "Epoch 46/50, Train Loss: 1.712Train Acc: 0.398\n",
      "Epoch 47/50, Train Loss: 1.688Train Acc: 0.407\n",
      "Epoch 48/50, Train Loss: 1.619Train Acc: 0.440\n",
      "Epoch 49/50, Train Loss: 1.665Train Acc: 0.418\n",
      "Epoch 50/50, Train Loss: 1.619Train Acc: 0.429\n",
      "Finished 109 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.1790744466800805\n",
      "Epoch 1/20, Train Loss: 2.018Train Acc: 0.297\n",
      "Epoch 2/20, Train Loss: 1.537Train Acc: 0.533\n",
      "Epoch 3/20, Train Loss: 1.213Train Acc: 0.639\n",
      "Epoch 4/20, Train Loss: 0.965Train Acc: 0.732\n",
      "Epoch 5/20, Train Loss: 0.804Train Acc: 0.768\n",
      "Epoch 6/20, Train Loss: 0.689Train Acc: 0.807\n",
      "Epoch 7/20, Train Loss: 0.624Train Acc: 0.823\n",
      "Epoch 8/20, Train Loss: 0.548Train Acc: 0.850\n",
      "Epoch 9/20, Train Loss: 0.477Train Acc: 0.867\n",
      "Epoch 10/20, Train Loss: 0.424Train Acc: 0.883\n",
      "Epoch 11/20, Train Loss: 0.382Train Acc: 0.893\n",
      "Epoch 12/20, Train Loss: 0.374Train Acc: 0.897\n",
      "Epoch 13/20, Train Loss: 0.321Train Acc: 0.909\n",
      "Epoch 14/20, Train Loss: 0.276Train Acc: 0.931\n",
      "Epoch 15/20, Train Loss: 0.263Train Acc: 0.928\n",
      "Epoch 16/20, Train Loss: 0.243Train Acc: 0.928\n",
      "Epoch 17/20, Train Loss: 0.219Train Acc: 0.944\n",
      "Epoch 18/20, Train Loss: 0.194Train Acc: 0.946\n",
      "Epoch 19/20, Train Loss: 0.183Train Acc: 0.948\n",
      "Epoch 20/20, Train Loss: 0.175Train Acc: 0.950\n",
      "Finished 110 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.4305835010060362\n",
      "Epoch 1/20, Train Loss: 2.321Train Acc: 0.103\n",
      "Epoch 2/20, Train Loss: 2.319Train Acc: 0.095\n",
      "Epoch 3/20, Train Loss: 2.308Train Acc: 0.112\n",
      "Epoch 4/20, Train Loss: 2.316Train Acc: 0.092\n",
      "Epoch 5/20, Train Loss: 2.309Train Acc: 0.100\n",
      "Epoch 6/20, Train Loss: 2.316Train Acc: 0.092\n",
      "Epoch 7/20, Train Loss: 2.310Train Acc: 0.097\n",
      "Epoch 8/20, Train Loss: 2.311Train Acc: 0.087\n",
      "Epoch 9/20, Train Loss: 2.309Train Acc: 0.103\n",
      "Epoch 10/20, Train Loss: 2.312Train Acc: 0.093\n",
      "Epoch 11/20, Train Loss: 2.315Train Acc: 0.100\n",
      "Epoch 12/20, Train Loss: 2.307Train Acc: 0.099\n",
      "Epoch 13/20, Train Loss: 2.311Train Acc: 0.095\n",
      "Epoch 14/20, Train Loss: 2.311Train Acc: 0.093\n",
      "Epoch 15/20, Train Loss: 2.310Train Acc: 0.099\n",
      "Epoch 16/20, Train Loss: 2.309Train Acc: 0.108\n",
      "Epoch 17/20, Train Loss: 2.310Train Acc: 0.104\n",
      "Epoch 18/20, Train Loss: 2.312Train Acc: 0.093\n",
      "Epoch 19/20, Train Loss: 2.309Train Acc: 0.099\n",
      "Epoch 20/20, Train Loss: 2.308Train Acc: 0.115\n",
      "Finished 111 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.0925553319919517\n",
      "Epoch 1/50, Train Loss: 2.318Train Acc: 0.101\n",
      "Epoch 2/50, Train Loss: 2.126Train Acc: 0.207\n",
      "Epoch 3/50, Train Loss: 1.660Train Acc: 0.433\n",
      "Epoch 4/50, Train Loss: 1.494Train Acc: 0.507\n",
      "Epoch 5/50, Train Loss: 1.322Train Acc: 0.574\n",
      "Epoch 6/50, Train Loss: 1.193Train Acc: 0.604\n",
      "Epoch 7/50, Train Loss: 1.162Train Acc: 0.616\n",
      "Epoch 8/50, Train Loss: 1.083Train Acc: 0.645\n",
      "Epoch 9/50, Train Loss: 0.998Train Acc: 0.672\n",
      "Epoch 10/50, Train Loss: 0.981Train Acc: 0.672\n",
      "Epoch 11/50, Train Loss: 0.980Train Acc: 0.681\n",
      "Epoch 12/50, Train Loss: 0.890Train Acc: 0.701\n",
      "Epoch 13/50, Train Loss: 0.874Train Acc: 0.713\n",
      "Epoch 14/50, Train Loss: 0.846Train Acc: 0.723\n",
      "Epoch 15/50, Train Loss: 0.810Train Acc: 0.735\n",
      "Epoch 16/50, Train Loss: 0.775Train Acc: 0.746\n",
      "Epoch 17/50, Train Loss: 0.785Train Acc: 0.737\n",
      "Epoch 18/50, Train Loss: 0.696Train Acc: 0.770\n",
      "Epoch 19/50, Train Loss: 0.751Train Acc: 0.755\n",
      "Epoch 20/50, Train Loss: 0.758Train Acc: 0.743\n",
      "Epoch 21/50, Train Loss: 0.694Train Acc: 0.772\n",
      "Epoch 22/50, Train Loss: 0.639Train Acc: 0.796\n",
      "Epoch 23/50, Train Loss: 0.666Train Acc: 0.769\n",
      "Epoch 24/50, Train Loss: 0.620Train Acc: 0.797\n",
      "Epoch 25/50, Train Loss: 0.633Train Acc: 0.792\n",
      "Epoch 26/50, Train Loss: 0.609Train Acc: 0.798\n",
      "Epoch 27/50, Train Loss: 0.618Train Acc: 0.800\n",
      "Epoch 28/50, Train Loss: 0.599Train Acc: 0.819\n",
      "Epoch 29/50, Train Loss: 0.559Train Acc: 0.822\n",
      "Epoch 30/50, Train Loss: 0.577Train Acc: 0.815\n",
      "Epoch 31/50, Train Loss: 0.554Train Acc: 0.819\n",
      "Epoch 32/50, Train Loss: 0.548Train Acc: 0.830\n",
      "Epoch 33/50, Train Loss: 0.583Train Acc: 0.826\n",
      "Epoch 34/50, Train Loss: 0.546Train Acc: 0.820\n",
      "Epoch 35/50, Train Loss: 0.519Train Acc: 0.832\n",
      "Epoch 36/50, Train Loss: 0.537Train Acc: 0.827\n",
      "Epoch 37/50, Train Loss: 0.514Train Acc: 0.829\n",
      "Epoch 38/50, Train Loss: 0.516Train Acc: 0.831\n",
      "Epoch 39/50, Train Loss: 0.523Train Acc: 0.832\n",
      "Epoch 40/50, Train Loss: 0.500Train Acc: 0.838\n",
      "Epoch 41/50, Train Loss: 0.449Train Acc: 0.857\n",
      "Epoch 42/50, Train Loss: 0.478Train Acc: 0.850\n",
      "Epoch 43/50, Train Loss: 0.440Train Acc: 0.860\n",
      "Epoch 44/50, Train Loss: 0.432Train Acc: 0.862\n",
      "Epoch 45/50, Train Loss: 0.414Train Acc: 0.869\n",
      "Epoch 46/50, Train Loss: 0.554Train Acc: 0.829\n",
      "Epoch 47/50, Train Loss: 0.522Train Acc: 0.841\n",
      "Epoch 48/50, Train Loss: 0.506Train Acc: 0.843\n",
      "Epoch 49/50, Train Loss: 0.466Train Acc: 0.857\n",
      "Epoch 50/50, Train Loss: 0.417Train Acc: 0.870\n",
      "Finished 112 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.40040241448692154\n",
      "Epoch 1/20, Train Loss: 2.340Train Acc: 0.100\n",
      "Epoch 2/20, Train Loss: 2.341Train Acc: 0.089\n",
      "Epoch 3/20, Train Loss: 2.336Train Acc: 0.102\n",
      "Epoch 4/20, Train Loss: 2.329Train Acc: 0.095\n",
      "Epoch 5/20, Train Loss: 2.330Train Acc: 0.090\n",
      "Epoch 6/20, Train Loss: 2.328Train Acc: 0.100\n",
      "Epoch 7/20, Train Loss: 2.330Train Acc: 0.107\n",
      "Epoch 8/20, Train Loss: 2.338Train Acc: 0.097\n",
      "Epoch 9/20, Train Loss: 2.329Train Acc: 0.100\n",
      "Epoch 10/20, Train Loss: 2.346Train Acc: 0.100\n",
      "Epoch 11/20, Train Loss: 2.336Train Acc: 0.097\n",
      "Epoch 12/20, Train Loss: 2.356Train Acc: 0.101\n",
      "Epoch 13/20, Train Loss: 2.336Train Acc: 0.106\n",
      "Epoch 14/20, Train Loss: 2.341Train Acc: 0.095\n",
      "Epoch 15/20, Train Loss: 2.358Train Acc: 0.082\n",
      "Epoch 16/20, Train Loss: 2.345Train Acc: 0.106\n",
      "Epoch 17/20, Train Loss: 2.358Train Acc: 0.102\n",
      "Epoch 18/20, Train Loss: 2.343Train Acc: 0.099\n",
      "Epoch 19/20, Train Loss: 2.339Train Acc: 0.106\n",
      "Epoch 20/20, Train Loss: 2.346Train Acc: 0.100\n",
      "Finished 113 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.1006036217303823\n",
      "Epoch 1/10, Train Loss: 2.231Train Acc: 0.171\n",
      "Epoch 2/10, Train Loss: 1.941Train Acc: 0.308\n",
      "Epoch 3/10, Train Loss: 1.866Train Acc: 0.351\n",
      "Epoch 4/10, Train Loss: 2.199Train Acc: 0.220\n",
      "Epoch 5/10, Train Loss: 2.150Train Acc: 0.212\n",
      "Epoch 6/10, Train Loss: 2.036Train Acc: 0.277\n",
      "Epoch 7/10, Train Loss: 2.074Train Acc: 0.241\n",
      "Epoch 8/10, Train Loss: 1.914Train Acc: 0.318\n",
      "Epoch 9/10, Train Loss: 1.858Train Acc: 0.323\n",
      "Epoch 10/10, Train Loss: 1.899Train Acc: 0.324\n",
      "Finished 114 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.16297786720321933\n",
      "Epoch 1/20, Train Loss: 1.806Train Acc: 0.365\n",
      "Epoch 2/20, Train Loss: 1.360Train Acc: 0.562\n",
      "Epoch 3/20, Train Loss: 1.155Train Acc: 0.641\n",
      "Epoch 4/20, Train Loss: 1.110Train Acc: 0.650\n",
      "Epoch 5/20, Train Loss: 1.111Train Acc: 0.633\n",
      "Epoch 6/20, Train Loss: 1.132Train Acc: 0.631\n",
      "Epoch 7/20, Train Loss: 1.072Train Acc: 0.642\n",
      "Epoch 8/20, Train Loss: 1.077Train Acc: 0.646\n",
      "Epoch 9/20, Train Loss: 1.220Train Acc: 0.600\n",
      "Epoch 10/20, Train Loss: 1.389Train Acc: 0.547\n",
      "Epoch 11/20, Train Loss: 1.396Train Acc: 0.555\n",
      "Epoch 12/20, Train Loss: 1.216Train Acc: 0.612\n",
      "Epoch 13/20, Train Loss: 1.212Train Acc: 0.594\n",
      "Epoch 14/20, Train Loss: 1.180Train Acc: 0.622\n",
      "Epoch 15/20, Train Loss: 1.264Train Acc: 0.583\n",
      "Epoch 16/20, Train Loss: 1.428Train Acc: 0.539\n",
      "Epoch 17/20, Train Loss: 1.283Train Acc: 0.568\n",
      "Epoch 18/20, Train Loss: 1.279Train Acc: 0.569\n",
      "Epoch 19/20, Train Loss: 1.215Train Acc: 0.603\n",
      "Epoch 20/20, Train Loss: 1.227Train Acc: 0.585\n",
      "Finished 115 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.2676056338028169\n",
      "Epoch 1/20, Train Loss: 2.232Train Acc: 0.151\n",
      "Epoch 2/20, Train Loss: 1.860Train Acc: 0.351\n",
      "Epoch 3/20, Train Loss: 1.494Train Acc: 0.548\n",
      "Epoch 4/20, Train Loss: 1.333Train Acc: 0.592\n",
      "Epoch 5/20, Train Loss: 1.194Train Acc: 0.634\n",
      "Epoch 6/20, Train Loss: 1.072Train Acc: 0.670\n",
      "Epoch 7/20, Train Loss: 0.957Train Acc: 0.703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Train Loss: 0.939Train Acc: 0.705\n",
      "Epoch 9/20, Train Loss: 0.903Train Acc: 0.713\n",
      "Epoch 10/20, Train Loss: 0.837Train Acc: 0.728\n",
      "Epoch 11/20, Train Loss: 0.792Train Acc: 0.750\n",
      "Epoch 12/20, Train Loss: 0.788Train Acc: 0.742\n",
      "Epoch 13/20, Train Loss: 0.763Train Acc: 0.748\n",
      "Epoch 14/20, Train Loss: 0.703Train Acc: 0.772\n",
      "Epoch 15/20, Train Loss: 0.680Train Acc: 0.782\n",
      "Epoch 16/20, Train Loss: 0.618Train Acc: 0.804\n",
      "Epoch 17/20, Train Loss: 0.684Train Acc: 0.778\n",
      "Epoch 18/20, Train Loss: 0.620Train Acc: 0.791\n",
      "Epoch 19/20, Train Loss: 0.606Train Acc: 0.798\n",
      "Epoch 20/20, Train Loss: 0.611Train Acc: 0.801\n",
      "Finished 116 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.36619718309859156\n",
      "Epoch 1/20, Train Loss: 2.135Train Acc: 0.227\n",
      "Epoch 2/20, Train Loss: 1.834Train Acc: 0.379\n",
      "Epoch 3/20, Train Loss: 1.630Train Acc: 0.462\n",
      "Epoch 4/20, Train Loss: 1.420Train Acc: 0.552\n",
      "Epoch 5/20, Train Loss: 1.246Train Acc: 0.634\n",
      "Epoch 6/20, Train Loss: 1.100Train Acc: 0.694\n",
      "Epoch 7/20, Train Loss: 0.979Train Acc: 0.717\n",
      "Epoch 8/20, Train Loss: 0.876Train Acc: 0.755\n",
      "Epoch 9/20, Train Loss: 0.775Train Acc: 0.785\n",
      "Epoch 10/20, Train Loss: 0.707Train Acc: 0.802\n",
      "Epoch 11/20, Train Loss: 0.650Train Acc: 0.816\n",
      "Epoch 12/20, Train Loss: 0.587Train Acc: 0.841\n",
      "Epoch 13/20, Train Loss: 0.550Train Acc: 0.849\n",
      "Epoch 14/20, Train Loss: 0.525Train Acc: 0.848\n",
      "Epoch 15/20, Train Loss: 0.480Train Acc: 0.866\n",
      "Epoch 16/20, Train Loss: 0.464Train Acc: 0.869\n",
      "Epoch 17/20, Train Loss: 0.449Train Acc: 0.869\n",
      "Epoch 18/20, Train Loss: 0.428Train Acc: 0.872\n",
      "Epoch 19/20, Train Loss: 0.394Train Acc: 0.888\n",
      "Epoch 20/20, Train Loss: 0.377Train Acc: 0.890\n",
      "Finished 117 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.4104627766599598\n",
      "Epoch 1/20, Train Loss: 2.313Train Acc: 0.098\n",
      "Epoch 2/20, Train Loss: 2.313Train Acc: 0.092\n",
      "Epoch 3/20, Train Loss: 2.310Train Acc: 0.086\n",
      "Epoch 4/20, Train Loss: 2.279Train Acc: 0.133\n",
      "Epoch 5/20, Train Loss: 2.088Train Acc: 0.236\n",
      "Epoch 6/20, Train Loss: 2.048Train Acc: 0.252\n",
      "Epoch 7/20, Train Loss: 1.969Train Acc: 0.259\n",
      "Epoch 8/20, Train Loss: 1.921Train Acc: 0.285\n",
      "Epoch 9/20, Train Loss: 1.849Train Acc: 0.314\n",
      "Epoch 10/20, Train Loss: 1.771Train Acc: 0.386\n",
      "Epoch 11/20, Train Loss: 1.636Train Acc: 0.435\n",
      "Epoch 12/20, Train Loss: 1.719Train Acc: 0.379\n",
      "Epoch 13/20, Train Loss: 1.834Train Acc: 0.332\n",
      "Epoch 14/20, Train Loss: 1.730Train Acc: 0.395\n",
      "Epoch 15/20, Train Loss: 1.747Train Acc: 0.377\n",
      "Epoch 16/20, Train Loss: 1.725Train Acc: 0.384\n",
      "Epoch 17/20, Train Loss: 1.723Train Acc: 0.385\n",
      "Epoch 18/20, Train Loss: 1.690Train Acc: 0.392\n",
      "Epoch 19/20, Train Loss: 1.656Train Acc: 0.392\n",
      "Epoch 20/20, Train Loss: 1.697Train Acc: 0.377\n",
      "Finished 118 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.18108651911468812\n",
      "Epoch 1/20, Train Loss: 2.256Train Acc: 0.165\n",
      "Epoch 2/20, Train Loss: 2.077Train Acc: 0.272\n",
      "Epoch 3/20, Train Loss: 1.894Train Acc: 0.336\n",
      "Epoch 4/20, Train Loss: 1.756Train Acc: 0.415\n",
      "Epoch 5/20, Train Loss: 1.634Train Acc: 0.462\n",
      "Epoch 6/20, Train Loss: 1.532Train Acc: 0.500\n",
      "Epoch 7/20, Train Loss: 1.438Train Acc: 0.525\n",
      "Epoch 8/20, Train Loss: 1.354Train Acc: 0.545\n",
      "Epoch 9/20, Train Loss: 1.287Train Acc: 0.585\n",
      "Epoch 10/20, Train Loss: 1.214Train Acc: 0.621\n",
      "Epoch 11/20, Train Loss: 1.153Train Acc: 0.653\n",
      "Epoch 12/20, Train Loss: 1.068Train Acc: 0.692\n",
      "Epoch 13/20, Train Loss: 1.024Train Acc: 0.704\n",
      "Epoch 14/20, Train Loss: 0.964Train Acc: 0.721\n",
      "Epoch 15/20, Train Loss: 0.927Train Acc: 0.720\n",
      "Epoch 16/20, Train Loss: 0.891Train Acc: 0.751\n",
      "Epoch 17/20, Train Loss: 0.840Train Acc: 0.763\n",
      "Epoch 18/20, Train Loss: 0.802Train Acc: 0.778\n",
      "Epoch 19/20, Train Loss: 0.767Train Acc: 0.788\n",
      "Epoch 20/20, Train Loss: 0.753Train Acc: 0.784\n",
      "Finished 119 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.3319919517102616\n",
      "Epoch 1/50, Train Loss: 1.864Train Acc: 0.343\n",
      "Epoch 2/50, Train Loss: 1.438Train Acc: 0.509\n",
      "Epoch 3/50, Train Loss: 1.220Train Acc: 0.595\n",
      "Epoch 4/50, Train Loss: 1.121Train Acc: 0.624\n",
      "Epoch 5/50, Train Loss: 1.177Train Acc: 0.617\n",
      "Epoch 6/50, Train Loss: 1.088Train Acc: 0.648\n",
      "Epoch 7/50, Train Loss: 1.124Train Acc: 0.625\n",
      "Epoch 8/50, Train Loss: 1.294Train Acc: 0.584\n",
      "Epoch 9/50, Train Loss: 1.078Train Acc: 0.635\n",
      "Epoch 10/50, Train Loss: 1.069Train Acc: 0.653\n",
      "Epoch 11/50, Train Loss: 1.063Train Acc: 0.646\n",
      "Epoch 12/50, Train Loss: 1.166Train Acc: 0.610\n",
      "Epoch 13/50, Train Loss: 1.286Train Acc: 0.573\n",
      "Epoch 14/50, Train Loss: 1.223Train Acc: 0.595\n",
      "Epoch 15/50, Train Loss: 1.208Train Acc: 0.596\n",
      "Epoch 16/50, Train Loss: 1.244Train Acc: 0.595\n",
      "Epoch 17/50, Train Loss: 1.366Train Acc: 0.530\n",
      "Epoch 18/50, Train Loss: 1.428Train Acc: 0.514\n",
      "Epoch 19/50, Train Loss: 1.352Train Acc: 0.536\n",
      "Epoch 20/50, Train Loss: 1.336Train Acc: 0.532\n",
      "Epoch 21/50, Train Loss: 1.310Train Acc: 0.556\n",
      "Epoch 22/50, Train Loss: 1.331Train Acc: 0.560\n",
      "Epoch 23/50, Train Loss: 1.494Train Acc: 0.488\n",
      "Epoch 24/50, Train Loss: 1.389Train Acc: 0.526\n",
      "Epoch 25/50, Train Loss: 1.460Train Acc: 0.496\n",
      "Epoch 26/50, Train Loss: 1.356Train Acc: 0.542\n",
      "Epoch 27/50, Train Loss: 1.369Train Acc: 0.543\n",
      "Epoch 28/50, Train Loss: 1.277Train Acc: 0.573\n",
      "Epoch 29/50, Train Loss: 1.379Train Acc: 0.522\n",
      "Epoch 30/50, Train Loss: 1.504Train Acc: 0.503\n",
      "Epoch 31/50, Train Loss: 1.398Train Acc: 0.517\n",
      "Epoch 32/50, Train Loss: 1.378Train Acc: 0.524\n",
      "Epoch 33/50, Train Loss: 1.328Train Acc: 0.540\n",
      "Epoch 34/50, Train Loss: 1.428Train Acc: 0.534\n",
      "Epoch 35/50, Train Loss: 1.446Train Acc: 0.513\n",
      "Epoch 36/50, Train Loss: 1.351Train Acc: 0.548\n",
      "Epoch 37/50, Train Loss: 1.470Train Acc: 0.507\n",
      "Epoch 38/50, Train Loss: 1.597Train Acc: 0.458\n",
      "Epoch 39/50, Train Loss: 1.680Train Acc: 0.429\n",
      "Epoch 40/50, Train Loss: 1.496Train Acc: 0.487\n",
      "Epoch 41/50, Train Loss: 1.484Train Acc: 0.497\n",
      "Epoch 42/50, Train Loss: 1.437Train Acc: 0.507\n",
      "Epoch 43/50, Train Loss: 1.489Train Acc: 0.480\n",
      "Epoch 44/50, Train Loss: 1.476Train Acc: 0.493\n",
      "Epoch 45/50, Train Loss: 1.550Train Acc: 0.453\n",
      "Epoch 46/50, Train Loss: 1.522Train Acc: 0.476\n",
      "Epoch 47/50, Train Loss: 1.500Train Acc: 0.469\n",
      "Epoch 48/50, Train Loss: 1.564Train Acc: 0.453\n",
      "Epoch 49/50, Train Loss: 1.689Train Acc: 0.393\n",
      "Epoch 50/50, Train Loss: 1.618Train Acc: 0.439\n",
      "Finished 120 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.15492957746478872\n",
      "Epoch 1/50, Train Loss: 2.077Train Acc: 0.255\n",
      "Epoch 2/50, Train Loss: 1.700Train Acc: 0.452\n",
      "Epoch 3/50, Train Loss: 1.318Train Acc: 0.618\n",
      "Epoch 4/50, Train Loss: 1.076Train Acc: 0.690\n",
      "Epoch 5/50, Train Loss: 0.900Train Acc: 0.750\n",
      "Epoch 6/50, Train Loss: 0.808Train Acc: 0.769\n",
      "Epoch 7/50, Train Loss: 0.719Train Acc: 0.787\n",
      "Epoch 8/50, Train Loss: 0.667Train Acc: 0.797\n",
      "Epoch 9/50, Train Loss: 0.591Train Acc: 0.834\n",
      "Epoch 10/50, Train Loss: 0.552Train Acc: 0.841\n",
      "Epoch 11/50, Train Loss: 0.510Train Acc: 0.853\n",
      "Epoch 12/50, Train Loss: 0.471Train Acc: 0.866\n",
      "Epoch 13/50, Train Loss: 0.429Train Acc: 0.875\n",
      "Epoch 14/50, Train Loss: 0.422Train Acc: 0.877\n",
      "Epoch 15/50, Train Loss: 0.415Train Acc: 0.875\n",
      "Epoch 16/50, Train Loss: 0.382Train Acc: 0.887\n",
      "Epoch 17/50, Train Loss: 0.337Train Acc: 0.901\n",
      "Epoch 18/50, Train Loss: 0.316Train Acc: 0.901\n",
      "Epoch 19/50, Train Loss: 0.315Train Acc: 0.908\n",
      "Epoch 20/50, Train Loss: 0.284Train Acc: 0.911\n",
      "Epoch 21/50, Train Loss: 0.270Train Acc: 0.922\n",
      "Epoch 22/50, Train Loss: 0.277Train Acc: 0.920\n",
      "Epoch 23/50, Train Loss: 0.253Train Acc: 0.922\n",
      "Epoch 24/50, Train Loss: 0.240Train Acc: 0.926\n",
      "Epoch 25/50, Train Loss: 0.258Train Acc: 0.926\n",
      "Epoch 26/50, Train Loss: 0.221Train Acc: 0.937\n",
      "Epoch 27/50, Train Loss: 0.223Train Acc: 0.935\n",
      "Epoch 28/50, Train Loss: 0.220Train Acc: 0.935\n",
      "Epoch 29/50, Train Loss: 0.196Train Acc: 0.944\n",
      "Epoch 30/50, Train Loss: 0.183Train Acc: 0.949\n",
      "Epoch 31/50, Train Loss: 0.178Train Acc: 0.946\n",
      "Epoch 32/50, Train Loss: 0.148Train Acc: 0.962\n",
      "Epoch 33/50, Train Loss: 0.146Train Acc: 0.959\n",
      "Epoch 34/50, Train Loss: 0.167Train Acc: 0.953\n",
      "Epoch 35/50, Train Loss: 0.159Train Acc: 0.951\n",
      "Epoch 36/50, Train Loss: 0.157Train Acc: 0.960\n",
      "Epoch 37/50, Train Loss: 0.133Train Acc: 0.969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Train Loss: 0.132Train Acc: 0.966\n",
      "Epoch 39/50, Train Loss: 0.145Train Acc: 0.955\n",
      "Epoch 40/50, Train Loss: 0.128Train Acc: 0.964\n",
      "Epoch 41/50, Train Loss: 0.118Train Acc: 0.968\n",
      "Epoch 42/50, Train Loss: 0.105Train Acc: 0.975\n",
      "Epoch 43/50, Train Loss: 0.117Train Acc: 0.969\n",
      "Epoch 44/50, Train Loss: 0.121Train Acc: 0.968\n",
      "Epoch 45/50, Train Loss: 0.135Train Acc: 0.961\n",
      "Epoch 46/50, Train Loss: 0.114Train Acc: 0.966\n",
      "Epoch 47/50, Train Loss: 0.106Train Acc: 0.972\n",
      "Epoch 48/50, Train Loss: 0.109Train Acc: 0.969\n",
      "Epoch 49/50, Train Loss: 0.114Train Acc: 0.969\n",
      "Epoch 50/50, Train Loss: 0.114Train Acc: 0.966\n",
      "Finished 121 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.4164989939637827\n",
      "Epoch 1/10, Train Loss: 2.349Train Acc: 0.100\n",
      "Epoch 2/10, Train Loss: 2.342Train Acc: 0.093\n",
      "Epoch 3/10, Train Loss: 2.341Train Acc: 0.098\n",
      "Epoch 4/10, Train Loss: 2.336Train Acc: 0.107\n",
      "Epoch 5/10, Train Loss: 2.343Train Acc: 0.090\n",
      "Epoch 6/10, Train Loss: 2.338Train Acc: 0.101\n",
      "Epoch 7/10, Train Loss: 2.338Train Acc: 0.087\n",
      "Epoch 8/10, Train Loss: 2.344Train Acc: 0.086\n",
      "Epoch 9/10, Train Loss: 2.338Train Acc: 0.098\n",
      "Epoch 10/10, Train Loss: 2.344Train Acc: 0.097\n",
      "Finished 122 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.1006036217303823\n",
      "Epoch 1/10, Train Loss: 2.335Train Acc: 0.104\n",
      "Epoch 2/10, Train Loss: 2.327Train Acc: 0.101\n",
      "Epoch 3/10, Train Loss: 2.325Train Acc: 0.084\n",
      "Epoch 4/10, Train Loss: 2.323Train Acc: 0.093\n",
      "Epoch 5/10, Train Loss: 2.317Train Acc: 0.101\n",
      "Epoch 6/10, Train Loss: 2.318Train Acc: 0.102\n",
      "Epoch 7/10, Train Loss: 2.321Train Acc: 0.097\n",
      "Epoch 8/10, Train Loss: 2.317Train Acc: 0.093\n",
      "Epoch 9/10, Train Loss: 2.316Train Acc: 0.103\n",
      "Epoch 10/10, Train Loss: 2.318Train Acc: 0.107\n",
      "Finished 123 of 144 parameter combinations\n",
      "best parameters are (50, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.10865191146881288\n",
      "Epoch 1/50, Train Loss: 1.935Train Acc: 0.325\n",
      "Epoch 2/50, Train Loss: 1.399Train Acc: 0.594\n",
      "Epoch 3/50, Train Loss: 1.022Train Acc: 0.726\n",
      "Epoch 4/50, Train Loss: 0.789Train Acc: 0.772\n",
      "Epoch 5/50, Train Loss: 0.634Train Acc: 0.828\n",
      "Epoch 6/50, Train Loss: 0.537Train Acc: 0.846\n",
      "Epoch 7/50, Train Loss: 0.456Train Acc: 0.865\n",
      "Epoch 8/50, Train Loss: 0.415Train Acc: 0.885\n",
      "Epoch 9/50, Train Loss: 0.357Train Acc: 0.898\n",
      "Epoch 10/50, Train Loss: 0.319Train Acc: 0.910\n",
      "Epoch 11/50, Train Loss: 0.316Train Acc: 0.903\n",
      "Epoch 12/50, Train Loss: 0.267Train Acc: 0.921\n",
      "Epoch 13/50, Train Loss: 0.226Train Acc: 0.932\n",
      "Epoch 14/50, Train Loss: 0.214Train Acc: 0.941\n",
      "Epoch 15/50, Train Loss: 0.196Train Acc: 0.946\n",
      "Epoch 16/50, Train Loss: 0.190Train Acc: 0.944\n",
      "Epoch 17/50, Train Loss: 0.156Train Acc: 0.961\n",
      "Epoch 18/50, Train Loss: 0.138Train Acc: 0.965\n",
      "Epoch 19/50, Train Loss: 0.127Train Acc: 0.969\n",
      "Epoch 20/50, Train Loss: 0.107Train Acc: 0.972\n",
      "Epoch 21/50, Train Loss: 0.106Train Acc: 0.972\n",
      "Epoch 22/50, Train Loss: 0.108Train Acc: 0.970\n",
      "Epoch 23/50, Train Loss: 0.117Train Acc: 0.968\n",
      "Epoch 24/50, Train Loss: 0.082Train Acc: 0.977\n",
      "Epoch 25/50, Train Loss: 0.072Train Acc: 0.984\n",
      "Epoch 26/50, Train Loss: 0.070Train Acc: 0.981\n",
      "Epoch 27/50, Train Loss: 0.073Train Acc: 0.984\n",
      "Epoch 28/50, Train Loss: 0.052Train Acc: 0.989\n",
      "Epoch 29/50, Train Loss: 0.050Train Acc: 0.992\n",
      "Epoch 30/50, Train Loss: 0.045Train Acc: 0.991\n",
      "Epoch 31/50, Train Loss: 0.039Train Acc: 0.994\n",
      "Epoch 32/50, Train Loss: 0.061Train Acc: 0.983\n",
      "Epoch 33/50, Train Loss: 0.059Train Acc: 0.986\n",
      "Epoch 34/50, Train Loss: 0.077Train Acc: 0.975\n",
      "Epoch 35/50, Train Loss: 0.062Train Acc: 0.989\n",
      "Epoch 36/50, Train Loss: 0.100Train Acc: 0.966\n",
      "Epoch 37/50, Train Loss: 0.086Train Acc: 0.977\n",
      "Epoch 38/50, Train Loss: 0.049Train Acc: 0.989\n",
      "Epoch 39/50, Train Loss: 0.031Train Acc: 0.994\n",
      "Epoch 40/50, Train Loss: 0.025Train Acc: 0.996\n",
      "Epoch 41/50, Train Loss: 0.026Train Acc: 0.994\n",
      "Epoch 42/50, Train Loss: 0.020Train Acc: 0.997\n",
      "Epoch 43/50, Train Loss: 0.018Train Acc: 0.998\n",
      "Epoch 44/50, Train Loss: 0.018Train Acc: 0.997\n",
      "Epoch 45/50, Train Loss: 0.066Train Acc: 0.981\n",
      "Epoch 46/50, Train Loss: 0.074Train Acc: 0.976\n",
      "Epoch 47/50, Train Loss: 0.029Train Acc: 0.996\n",
      "Epoch 48/50, Train Loss: 0.023Train Acc: 0.997\n",
      "Epoch 49/50, Train Loss: 0.018Train Acc: 0.997\n",
      "Epoch 50/50, Train Loss: 0.021Train Acc: 0.995\n",
      "Finished 124 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.4567404426559356\n",
      "Epoch 1/20, Train Loss: 2.204Train Acc: 0.184\n",
      "Epoch 2/20, Train Loss: 2.071Train Acc: 0.263\n",
      "Epoch 3/20, Train Loss: 1.882Train Acc: 0.319\n",
      "Epoch 4/20, Train Loss: 1.757Train Acc: 0.365\n",
      "Epoch 5/20, Train Loss: 2.323Train Acc: 0.173\n",
      "Epoch 6/20, Train Loss: 2.274Train Acc: 0.165\n",
      "Epoch 7/20, Train Loss: 2.332Train Acc: 0.140\n",
      "Epoch 8/20, Train Loss: 2.252Train Acc: 0.142\n",
      "Epoch 9/20, Train Loss: 2.231Train Acc: 0.166\n",
      "Epoch 10/20, Train Loss: 2.209Train Acc: 0.179\n",
      "Epoch 11/20, Train Loss: 2.246Train Acc: 0.167\n",
      "Epoch 12/20, Train Loss: 2.255Train Acc: 0.153\n",
      "Epoch 13/20, Train Loss: 2.263Train Acc: 0.141\n",
      "Epoch 14/20, Train Loss: 2.253Train Acc: 0.142\n",
      "Epoch 15/20, Train Loss: 2.252Train Acc: 0.178\n",
      "Epoch 16/20, Train Loss: 2.250Train Acc: 0.175\n",
      "Epoch 17/20, Train Loss: 2.161Train Acc: 0.217\n",
      "Epoch 18/20, Train Loss: 2.139Train Acc: 0.220\n",
      "Epoch 19/20, Train Loss: 2.174Train Acc: 0.196\n",
      "Epoch 20/20, Train Loss: 2.170Train Acc: 0.212\n",
      "Finished 125 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.13078470824949698\n",
      "Epoch 1/20, Train Loss: 2.381Train Acc: 0.102\n",
      "Epoch 2/20, Train Loss: 2.368Train Acc: 0.100\n",
      "Epoch 3/20, Train Loss: 2.357Train Acc: 0.112\n",
      "Epoch 4/20, Train Loss: 2.351Train Acc: 0.114\n",
      "Epoch 5/20, Train Loss: 2.348Train Acc: 0.110\n",
      "Epoch 6/20, Train Loss: 2.341Train Acc: 0.133\n",
      "Epoch 7/20, Train Loss: 2.348Train Acc: 0.123\n",
      "Epoch 8/20, Train Loss: 2.342Train Acc: 0.120\n",
      "Epoch 9/20, Train Loss: 2.370Train Acc: 0.124\n",
      "Epoch 10/20, Train Loss: 2.329Train Acc: 0.112\n",
      "Epoch 11/20, Train Loss: 2.341Train Acc: 0.106\n",
      "Epoch 12/20, Train Loss: 2.319Train Acc: 0.122\n",
      "Epoch 13/20, Train Loss: 2.352Train Acc: 0.105\n",
      "Epoch 14/20, Train Loss: 2.364Train Acc: 0.111\n",
      "Epoch 15/20, Train Loss: 2.325Train Acc: 0.122\n",
      "Epoch 16/20, Train Loss: 2.332Train Acc: 0.111\n",
      "Epoch 17/20, Train Loss: 2.342Train Acc: 0.117\n",
      "Epoch 18/20, Train Loss: 2.334Train Acc: 0.126\n",
      "Epoch 19/20, Train Loss: 2.346Train Acc: 0.103\n",
      "Epoch 20/20, Train Loss: 2.354Train Acc: 0.111\n",
      "Finished 126 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.1488933601609658\n",
      "Epoch 1/20, Train Loss: 2.232Train Acc: 0.175\n",
      "Epoch 2/20, Train Loss: 2.067Train Acc: 0.237\n",
      "Epoch 3/20, Train Loss: 2.022Train Acc: 0.264\n",
      "Epoch 4/20, Train Loss: 2.196Train Acc: 0.212\n",
      "Epoch 5/20, Train Loss: 1.986Train Acc: 0.292\n",
      "Epoch 6/20, Train Loss: 2.095Train Acc: 0.274\n",
      "Epoch 7/20, Train Loss: 2.056Train Acc: 0.274\n",
      "Epoch 8/20, Train Loss: 2.192Train Acc: 0.193\n",
      "Epoch 9/20, Train Loss: 2.063Train Acc: 0.245\n",
      "Epoch 10/20, Train Loss: 2.310Train Acc: 0.142\n",
      "Epoch 11/20, Train Loss: 2.365Train Acc: 0.117\n",
      "Epoch 12/20, Train Loss: 2.277Train Acc: 0.148\n",
      "Epoch 13/20, Train Loss: 2.190Train Acc: 0.179\n",
      "Epoch 14/20, Train Loss: 2.225Train Acc: 0.149\n",
      "Epoch 15/20, Train Loss: 2.231Train Acc: 0.178\n",
      "Epoch 16/20, Train Loss: 2.156Train Acc: 0.207\n",
      "Epoch 17/20, Train Loss: 2.084Train Acc: 0.234\n",
      "Epoch 18/20, Train Loss: 2.038Train Acc: 0.247\n",
      "Epoch 19/20, Train Loss: 2.266Train Acc: 0.168\n",
      "Epoch 20/20, Train Loss: 2.187Train Acc: 0.193\n",
      "Finished 127 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.10663983903420524\n",
      "Epoch 1/50, Train Loss: 2.107Train Acc: 0.220\n",
      "Epoch 2/50, Train Loss: 1.858Train Acc: 0.346\n",
      "Epoch 3/50, Train Loss: 1.711Train Acc: 0.406\n",
      "Epoch 4/50, Train Loss: 1.580Train Acc: 0.460\n",
      "Epoch 5/50, Train Loss: 1.480Train Acc: 0.499\n",
      "Epoch 6/50, Train Loss: 1.378Train Acc: 0.550\n",
      "Epoch 7/50, Train Loss: 1.288Train Acc: 0.593\n",
      "Epoch 8/50, Train Loss: 1.186Train Acc: 0.629\n",
      "Epoch 9/50, Train Loss: 1.124Train Acc: 0.654\n",
      "Epoch 10/50, Train Loss: 1.027Train Acc: 0.689\n",
      "Epoch 11/50, Train Loss: 0.968Train Acc: 0.720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Train Loss: 0.919Train Acc: 0.726\n",
      "Epoch 13/50, Train Loss: 0.853Train Acc: 0.745\n",
      "Epoch 14/50, Train Loss: 0.809Train Acc: 0.767\n",
      "Epoch 15/50, Train Loss: 0.784Train Acc: 0.776\n",
      "Epoch 16/50, Train Loss: 0.724Train Acc: 0.781\n",
      "Epoch 17/50, Train Loss: 0.699Train Acc: 0.795\n",
      "Epoch 18/50, Train Loss: 0.671Train Acc: 0.799\n",
      "Epoch 19/50, Train Loss: 0.665Train Acc: 0.800\n",
      "Epoch 20/50, Train Loss: 0.622Train Acc: 0.816\n",
      "Epoch 21/50, Train Loss: 0.582Train Acc: 0.817\n",
      "Epoch 22/50, Train Loss: 0.577Train Acc: 0.828\n",
      "Epoch 23/50, Train Loss: 0.557Train Acc: 0.836\n",
      "Epoch 24/50, Train Loss: 0.541Train Acc: 0.835\n",
      "Epoch 25/50, Train Loss: 0.525Train Acc: 0.846\n",
      "Epoch 26/50, Train Loss: 0.539Train Acc: 0.841\n",
      "Epoch 27/50, Train Loss: 0.482Train Acc: 0.862\n",
      "Epoch 28/50, Train Loss: 0.469Train Acc: 0.861\n",
      "Epoch 29/50, Train Loss: 0.467Train Acc: 0.864\n",
      "Epoch 30/50, Train Loss: 0.450Train Acc: 0.872\n",
      "Epoch 31/50, Train Loss: 0.417Train Acc: 0.877\n",
      "Epoch 32/50, Train Loss: 0.420Train Acc: 0.878\n",
      "Epoch 33/50, Train Loss: 0.448Train Acc: 0.860\n",
      "Epoch 34/50, Train Loss: 0.411Train Acc: 0.875\n",
      "Epoch 35/50, Train Loss: 0.389Train Acc: 0.882\n",
      "Epoch 36/50, Train Loss: 0.398Train Acc: 0.883\n",
      "Epoch 37/50, Train Loss: 0.379Train Acc: 0.879\n",
      "Epoch 38/50, Train Loss: 0.373Train Acc: 0.888\n",
      "Epoch 39/50, Train Loss: 0.382Train Acc: 0.878\n",
      "Epoch 40/50, Train Loss: 0.348Train Acc: 0.897\n",
      "Epoch 41/50, Train Loss: 0.334Train Acc: 0.903\n",
      "Epoch 42/50, Train Loss: 0.369Train Acc: 0.878\n",
      "Epoch 43/50, Train Loss: 0.341Train Acc: 0.891\n",
      "Epoch 44/50, Train Loss: 0.341Train Acc: 0.899\n",
      "Epoch 45/50, Train Loss: 0.313Train Acc: 0.904\n",
      "Epoch 46/50, Train Loss: 0.299Train Acc: 0.915\n",
      "Epoch 47/50, Train Loss: 0.308Train Acc: 0.904\n",
      "Epoch 48/50, Train Loss: 0.307Train Acc: 0.910\n",
      "Epoch 49/50, Train Loss: 0.281Train Acc: 0.915\n",
      "Epoch 50/50, Train Loss: 0.276Train Acc: 0.913\n",
      "Finished 128 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.3782696177062374\n",
      "Epoch 1/20, Train Loss: 2.174Train Acc: 0.201\n",
      "Epoch 2/20, Train Loss: 1.937Train Acc: 0.292\n",
      "Epoch 3/20, Train Loss: 1.930Train Acc: 0.283\n",
      "Epoch 4/20, Train Loss: 1.917Train Acc: 0.302\n",
      "Epoch 5/20, Train Loss: 1.859Train Acc: 0.308\n",
      "Epoch 6/20, Train Loss: 1.848Train Acc: 0.307\n",
      "Epoch 7/20, Train Loss: 2.020Train Acc: 0.297\n",
      "Epoch 8/20, Train Loss: 1.975Train Acc: 0.290\n",
      "Epoch 9/20, Train Loss: 1.820Train Acc: 0.351\n",
      "Epoch 10/20, Train Loss: 1.683Train Acc: 0.390\n",
      "Epoch 11/20, Train Loss: 1.631Train Acc: 0.433\n",
      "Epoch 12/20, Train Loss: 1.946Train Acc: 0.309\n",
      "Epoch 13/20, Train Loss: 1.969Train Acc: 0.290\n",
      "Epoch 14/20, Train Loss: 1.765Train Acc: 0.364\n",
      "Epoch 15/20, Train Loss: 1.758Train Acc: 0.384\n",
      "Epoch 16/20, Train Loss: 1.727Train Acc: 0.394\n",
      "Epoch 17/20, Train Loss: 1.709Train Acc: 0.412\n",
      "Epoch 18/20, Train Loss: 1.641Train Acc: 0.402\n",
      "Epoch 19/20, Train Loss: 1.566Train Acc: 0.436\n",
      "Epoch 20/20, Train Loss: 1.612Train Acc: 0.424\n",
      "Finished 129 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.18712273641851107\n",
      "Epoch 1/10, Train Loss: 2.311Train Acc: 0.106\n",
      "Epoch 2/10, Train Loss: 2.168Train Acc: 0.170\n",
      "Epoch 3/10, Train Loss: 1.971Train Acc: 0.261\n",
      "Epoch 4/10, Train Loss: 1.799Train Acc: 0.368\n",
      "Epoch 5/10, Train Loss: 1.702Train Acc: 0.404\n",
      "Epoch 6/10, Train Loss: 1.583Train Acc: 0.454\n",
      "Epoch 7/10, Train Loss: 1.592Train Acc: 0.461\n",
      "Epoch 8/10, Train Loss: 1.646Train Acc: 0.436\n",
      "Epoch 9/10, Train Loss: 1.980Train Acc: 0.283\n",
      "Epoch 10/10, Train Loss: 1.758Train Acc: 0.374\n",
      "Finished 130 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.18309859154929578\n",
      "Epoch 1/10, Train Loss: 2.255Train Acc: 0.149\n",
      "Epoch 2/10, Train Loss: 1.923Train Acc: 0.307\n",
      "Epoch 3/10, Train Loss: 1.744Train Acc: 0.380\n",
      "Epoch 4/10, Train Loss: 1.586Train Acc: 0.440\n",
      "Epoch 5/10, Train Loss: 1.466Train Acc: 0.483\n",
      "Epoch 6/10, Train Loss: 1.384Train Acc: 0.526\n",
      "Epoch 7/10, Train Loss: 1.258Train Acc: 0.578\n",
      "Epoch 8/10, Train Loss: 1.243Train Acc: 0.584\n",
      "Epoch 9/10, Train Loss: 1.116Train Acc: 0.638\n",
      "Epoch 10/10, Train Loss: 1.074Train Acc: 0.641\n",
      "Finished 131 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.2716297786720322\n",
      "Epoch 1/10, Train Loss: 2.334Train Acc: 0.096\n",
      "Epoch 2/10, Train Loss: 2.328Train Acc: 0.092\n",
      "Epoch 3/10, Train Loss: 2.326Train Acc: 0.089\n",
      "Epoch 4/10, Train Loss: 2.323Train Acc: 0.086\n",
      "Epoch 5/10, Train Loss: 2.316Train Acc: 0.105\n",
      "Epoch 6/10, Train Loss: 2.328Train Acc: 0.095\n",
      "Epoch 7/10, Train Loss: 2.326Train Acc: 0.110\n",
      "Epoch 8/10, Train Loss: 2.325Train Acc: 0.091\n",
      "Epoch 9/10, Train Loss: 2.326Train Acc: 0.088\n",
      "Epoch 10/10, Train Loss: 2.314Train Acc: 0.104\n",
      "Finished 132 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.08853118712273642\n",
      "Epoch 1/20, Train Loss: 1.633Train Acc: 0.456\n",
      "Epoch 2/20, Train Loss: 1.162Train Acc: 0.638\n",
      "Epoch 3/20, Train Loss: 0.982Train Acc: 0.693\n",
      "Epoch 4/20, Train Loss: 0.895Train Acc: 0.720\n",
      "Epoch 5/20, Train Loss: 0.923Train Acc: 0.711\n",
      "Epoch 6/20, Train Loss: 0.828Train Acc: 0.743\n",
      "Epoch 7/20, Train Loss: 0.987Train Acc: 0.670\n",
      "Epoch 8/20, Train Loss: 0.997Train Acc: 0.680\n",
      "Epoch 9/20, Train Loss: 0.880Train Acc: 0.722\n",
      "Epoch 10/20, Train Loss: 1.030Train Acc: 0.670\n",
      "Epoch 11/20, Train Loss: 1.053Train Acc: 0.664\n",
      "Epoch 12/20, Train Loss: 1.065Train Acc: 0.656\n",
      "Epoch 13/20, Train Loss: 0.963Train Acc: 0.691\n",
      "Epoch 14/20, Train Loss: 1.042Train Acc: 0.660\n",
      "Epoch 15/20, Train Loss: 1.138Train Acc: 0.654\n",
      "Epoch 16/20, Train Loss: 1.360Train Acc: 0.562\n",
      "Epoch 17/20, Train Loss: 1.401Train Acc: 0.564\n",
      "Epoch 18/20, Train Loss: 1.482Train Acc: 0.539\n",
      "Epoch 19/20, Train Loss: 1.634Train Acc: 0.470\n",
      "Epoch 20/20, Train Loss: 1.434Train Acc: 0.509\n",
      "Finished 133 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.2193158953722334\n",
      "Epoch 1/10, Train Loss: 2.383Train Acc: 0.095\n",
      "Epoch 2/10, Train Loss: 2.377Train Acc: 0.099\n",
      "Epoch 3/10, Train Loss: 2.365Train Acc: 0.097\n",
      "Epoch 4/10, Train Loss: 2.389Train Acc: 0.092\n",
      "Epoch 5/10, Train Loss: 2.376Train Acc: 0.086\n",
      "Epoch 6/10, Train Loss: 2.404Train Acc: 0.100\n",
      "Epoch 7/10, Train Loss: 2.375Train Acc: 0.106\n",
      "Epoch 8/10, Train Loss: 2.371Train Acc: 0.094\n",
      "Epoch 9/10, Train Loss: 2.396Train Acc: 0.097\n",
      "Epoch 10/10, Train Loss: 2.398Train Acc: 0.091\n",
      "Finished 134 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.10865191146881288\n",
      "Epoch 1/10, Train Loss: 2.311Train Acc: 0.110\n",
      "Epoch 2/10, Train Loss: 2.129Train Acc: 0.209\n",
      "Epoch 3/10, Train Loss: 1.951Train Acc: 0.280\n",
      "Epoch 4/10, Train Loss: 1.854Train Acc: 0.320\n",
      "Epoch 5/10, Train Loss: 1.746Train Acc: 0.386\n",
      "Epoch 6/10, Train Loss: 1.661Train Acc: 0.420\n",
      "Epoch 7/10, Train Loss: 1.595Train Acc: 0.459\n",
      "Epoch 8/10, Train Loss: 1.535Train Acc: 0.483\n",
      "Epoch 9/10, Train Loss: 1.480Train Acc: 0.493\n",
      "Epoch 10/10, Train Loss: 1.435Train Acc: 0.515\n",
      "Finished 135 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.30784708249496984\n",
      "Epoch 1/20, Train Loss: 1.967Train Acc: 0.302\n",
      "Epoch 2/20, Train Loss: 1.471Train Acc: 0.530\n",
      "Epoch 3/20, Train Loss: 1.169Train Acc: 0.655\n",
      "Epoch 4/20, Train Loss: 1.045Train Acc: 0.676\n",
      "Epoch 5/20, Train Loss: 0.941Train Acc: 0.699\n",
      "Epoch 6/20, Train Loss: 0.851Train Acc: 0.725\n",
      "Epoch 7/20, Train Loss: 0.738Train Acc: 0.761\n",
      "Epoch 8/20, Train Loss: 0.725Train Acc: 0.771\n",
      "Epoch 9/20, Train Loss: 0.678Train Acc: 0.790\n",
      "Epoch 10/20, Train Loss: 0.631Train Acc: 0.803\n",
      "Epoch 11/20, Train Loss: 0.606Train Acc: 0.817\n",
      "Epoch 12/20, Train Loss: 0.507Train Acc: 0.842\n",
      "Epoch 13/20, Train Loss: 0.554Train Acc: 0.825\n",
      "Epoch 14/20, Train Loss: 0.569Train Acc: 0.820\n",
      "Epoch 15/20, Train Loss: 0.477Train Acc: 0.851\n",
      "Epoch 16/20, Train Loss: 0.407Train Acc: 0.873\n",
      "Epoch 17/20, Train Loss: 0.430Train Acc: 0.858\n",
      "Epoch 18/20, Train Loss: 0.346Train Acc: 0.892\n",
      "Epoch 19/20, Train Loss: 0.370Train Acc: 0.881\n",
      "Epoch 20/20, Train Loss: 0.354Train Acc: 0.880\n",
      "Finished 136 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.3822937625754527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 2.353Train Acc: 0.083\n",
      "Epoch 2/10, Train Loss: 2.336Train Acc: 0.106\n",
      "Epoch 3/10, Train Loss: 2.339Train Acc: 0.097\n",
      "Epoch 4/10, Train Loss: 2.333Train Acc: 0.109\n",
      "Epoch 5/10, Train Loss: 2.343Train Acc: 0.105\n",
      "Epoch 6/10, Train Loss: 2.345Train Acc: 0.098\n",
      "Epoch 7/10, Train Loss: 2.331Train Acc: 0.098\n",
      "Epoch 8/10, Train Loss: 2.338Train Acc: 0.095\n",
      "Epoch 9/10, Train Loss: 2.341Train Acc: 0.096\n",
      "Epoch 10/10, Train Loss: 2.345Train Acc: 0.090\n",
      "Finished 137 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.10865191146881288\n",
      "Epoch 1/10, Train Loss: 2.128Train Acc: 0.242\n",
      "Epoch 2/10, Train Loss: 1.683Train Acc: 0.462\n",
      "Epoch 3/10, Train Loss: 1.335Train Acc: 0.600\n",
      "Epoch 4/10, Train Loss: 1.097Train Acc: 0.688\n",
      "Epoch 5/10, Train Loss: 0.909Train Acc: 0.753\n",
      "Epoch 6/10, Train Loss: 0.795Train Acc: 0.777\n",
      "Epoch 7/10, Train Loss: 0.682Train Acc: 0.802\n",
      "Epoch 8/10, Train Loss: 0.624Train Acc: 0.818\n",
      "Epoch 9/10, Train Loss: 0.562Train Acc: 0.843\n",
      "Epoch 10/10, Train Loss: 0.510Train Acc: 0.852\n",
      "Finished 138 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.3299798792756539\n",
      "Epoch 1/50, Train Loss: 2.314Train Acc: 0.086\n",
      "Epoch 2/50, Train Loss: 2.277Train Acc: 0.131\n",
      "Epoch 3/50, Train Loss: 2.045Train Acc: 0.255\n",
      "Epoch 4/50, Train Loss: 1.850Train Acc: 0.310\n",
      "Epoch 5/50, Train Loss: 1.745Train Acc: 0.366\n",
      "Epoch 6/50, Train Loss: 1.656Train Acc: 0.418\n",
      "Epoch 7/50, Train Loss: 1.539Train Acc: 0.480\n",
      "Epoch 8/50, Train Loss: 1.482Train Acc: 0.490\n",
      "Epoch 9/50, Train Loss: 1.411Train Acc: 0.530\n",
      "Epoch 10/50, Train Loss: 1.445Train Acc: 0.512\n",
      "Epoch 11/50, Train Loss: 1.387Train Acc: 0.545\n",
      "Epoch 12/50, Train Loss: 1.316Train Acc: 0.578\n",
      "Epoch 13/50, Train Loss: 1.238Train Acc: 0.598\n",
      "Epoch 14/50, Train Loss: 1.224Train Acc: 0.604\n",
      "Epoch 15/50, Train Loss: 1.277Train Acc: 0.571\n",
      "Epoch 16/50, Train Loss: 1.240Train Acc: 0.582\n",
      "Epoch 17/50, Train Loss: 1.643Train Acc: 0.437\n",
      "Epoch 18/50, Train Loss: 1.450Train Acc: 0.500\n",
      "Epoch 19/50, Train Loss: 1.885Train Acc: 0.337\n",
      "Epoch 20/50, Train Loss: 1.601Train Acc: 0.437\n",
      "Epoch 21/50, Train Loss: 1.471Train Acc: 0.494\n",
      "Epoch 22/50, Train Loss: 1.354Train Acc: 0.515\n",
      "Epoch 23/50, Train Loss: 1.295Train Acc: 0.560\n",
      "Epoch 24/50, Train Loss: 1.252Train Acc: 0.584\n",
      "Epoch 25/50, Train Loss: 1.275Train Acc: 0.555\n",
      "Epoch 26/50, Train Loss: 1.269Train Acc: 0.566\n",
      "Epoch 27/50, Train Loss: 1.224Train Acc: 0.580\n",
      "Epoch 28/50, Train Loss: 1.323Train Acc: 0.540\n",
      "Epoch 29/50, Train Loss: 1.267Train Acc: 0.564\n",
      "Epoch 30/50, Train Loss: 1.199Train Acc: 0.590\n",
      "Epoch 31/50, Train Loss: 1.189Train Acc: 0.586\n",
      "Epoch 32/50, Train Loss: 1.165Train Acc: 0.602\n",
      "Epoch 33/50, Train Loss: 1.145Train Acc: 0.611\n",
      "Epoch 34/50, Train Loss: 1.099Train Acc: 0.634\n",
      "Epoch 35/50, Train Loss: 1.100Train Acc: 0.619\n",
      "Epoch 36/50, Train Loss: 1.082Train Acc: 0.638\n",
      "Epoch 37/50, Train Loss: 1.061Train Acc: 0.641\n",
      "Epoch 38/50, Train Loss: 1.063Train Acc: 0.643\n",
      "Epoch 39/50, Train Loss: 1.017Train Acc: 0.658\n",
      "Epoch 40/50, Train Loss: 1.047Train Acc: 0.658\n",
      "Epoch 41/50, Train Loss: 1.116Train Acc: 0.608\n",
      "Epoch 42/50, Train Loss: 1.014Train Acc: 0.662\n",
      "Epoch 43/50, Train Loss: 1.018Train Acc: 0.645\n",
      "Epoch 44/50, Train Loss: 1.000Train Acc: 0.662\n",
      "Epoch 45/50, Train Loss: 1.000Train Acc: 0.660\n",
      "Epoch 46/50, Train Loss: 0.990Train Acc: 0.669\n",
      "Epoch 47/50, Train Loss: 0.943Train Acc: 0.672\n",
      "Epoch 48/50, Train Loss: 0.959Train Acc: 0.667\n",
      "Epoch 49/50, Train Loss: 0.935Train Acc: 0.690\n",
      "Epoch 50/50, Train Loss: 0.936Train Acc: 0.689\n",
      "Finished 139 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.29577464788732394\n",
      "Epoch 1/10, Train Loss: 2.314Train Acc: 0.104\n",
      "Epoch 2/10, Train Loss: 2.314Train Acc: 0.094\n",
      "Epoch 3/10, Train Loss: 2.312Train Acc: 0.098\n",
      "Epoch 4/10, Train Loss: 2.306Train Acc: 0.100\n",
      "Epoch 5/10, Train Loss: 2.312Train Acc: 0.106\n",
      "Epoch 6/10, Train Loss: 2.309Train Acc: 0.096\n",
      "Epoch 7/10, Train Loss: 2.312Train Acc: 0.096\n",
      "Epoch 8/10, Train Loss: 2.305Train Acc: 0.099\n",
      "Epoch 9/10, Train Loss: 2.306Train Acc: 0.098\n",
      "Epoch 10/10, Train Loss: 2.313Train Acc: 0.089\n",
      "Finished 140 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.09054325955734406\n",
      "Epoch 1/50, Train Loss: 2.269Train Acc: 0.145\n",
      "Epoch 2/50, Train Loss: 2.038Train Acc: 0.270\n",
      "Epoch 3/50, Train Loss: 1.875Train Acc: 0.316\n",
      "Epoch 4/50, Train Loss: 1.801Train Acc: 0.340\n",
      "Epoch 5/50, Train Loss: 1.729Train Acc: 0.383\n",
      "Epoch 6/50, Train Loss: 1.822Train Acc: 0.337\n",
      "Epoch 7/50, Train Loss: 1.787Train Acc: 0.336\n",
      "Epoch 8/50, Train Loss: 1.781Train Acc: 0.394\n",
      "Epoch 9/50, Train Loss: 1.767Train Acc: 0.390\n",
      "Epoch 10/50, Train Loss: 1.728Train Acc: 0.407\n",
      "Epoch 11/50, Train Loss: 1.807Train Acc: 0.348\n",
      "Epoch 12/50, Train Loss: 1.979Train Acc: 0.260\n",
      "Epoch 13/50, Train Loss: 2.055Train Acc: 0.230\n",
      "Epoch 14/50, Train Loss: 2.178Train Acc: 0.172\n",
      "Epoch 15/50, Train Loss: 2.100Train Acc: 0.196\n",
      "Epoch 16/50, Train Loss: 2.084Train Acc: 0.209\n",
      "Epoch 17/50, Train Loss: 2.068Train Acc: 0.215\n",
      "Epoch 18/50, Train Loss: 1.999Train Acc: 0.253\n",
      "Epoch 19/50, Train Loss: 1.943Train Acc: 0.287\n",
      "Epoch 20/50, Train Loss: 2.056Train Acc: 0.216\n",
      "Epoch 21/50, Train Loss: 1.964Train Acc: 0.268\n",
      "Epoch 22/50, Train Loss: 1.926Train Acc: 0.290\n",
      "Epoch 23/50, Train Loss: 2.023Train Acc: 0.283\n",
      "Epoch 24/50, Train Loss: 2.300Train Acc: 0.181\n",
      "Epoch 25/50, Train Loss: 2.306Train Acc: 0.142\n",
      "Epoch 26/50, Train Loss: 2.247Train Acc: 0.175\n",
      "Epoch 27/50, Train Loss: 2.273Train Acc: 0.147\n",
      "Epoch 28/50, Train Loss: 2.290Train Acc: 0.134\n",
      "Epoch 29/50, Train Loss: 2.152Train Acc: 0.194\n",
      "Epoch 30/50, Train Loss: 2.116Train Acc: 0.225\n",
      "Epoch 31/50, Train Loss: 2.103Train Acc: 0.231\n",
      "Epoch 32/50, Train Loss: 2.109Train Acc: 0.217\n",
      "Epoch 33/50, Train Loss: 2.110Train Acc: 0.220\n",
      "Epoch 34/50, Train Loss: 2.121Train Acc: 0.216\n",
      "Epoch 35/50, Train Loss: 2.131Train Acc: 0.211\n",
      "Epoch 36/50, Train Loss: 2.112Train Acc: 0.218\n",
      "Epoch 37/50, Train Loss: 2.133Train Acc: 0.216\n",
      "Epoch 38/50, Train Loss: 2.138Train Acc: 0.213\n",
      "Epoch 39/50, Train Loss: 2.173Train Acc: 0.193\n",
      "Epoch 40/50, Train Loss: 2.179Train Acc: 0.202\n",
      "Epoch 41/50, Train Loss: 2.131Train Acc: 0.234\n",
      "Epoch 42/50, Train Loss: 2.165Train Acc: 0.201\n",
      "Epoch 43/50, Train Loss: 2.190Train Acc: 0.202\n",
      "Epoch 44/50, Train Loss: 2.205Train Acc: 0.183\n",
      "Epoch 45/50, Train Loss: 2.231Train Acc: 0.197\n",
      "Epoch 46/50, Train Loss: 2.222Train Acc: 0.185\n",
      "Epoch 47/50, Train Loss: 2.222Train Acc: 0.181\n",
      "Epoch 48/50, Train Loss: 2.229Train Acc: 0.171\n",
      "Epoch 49/50, Train Loss: 2.240Train Acc: 0.180\n",
      "Epoch 50/50, Train Loss: 2.206Train Acc: 0.167\n",
      "Finished 141 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.10865191146881288\n",
      "Epoch 1/20, Train Loss: 2.337Train Acc: 0.088\n",
      "Epoch 2/20, Train Loss: 2.324Train Acc: 0.101\n",
      "Epoch 3/20, Train Loss: 2.324Train Acc: 0.102\n",
      "Epoch 4/20, Train Loss: 2.316Train Acc: 0.101\n",
      "Epoch 5/20, Train Loss: 2.319Train Acc: 0.104\n",
      "Epoch 6/20, Train Loss: 2.325Train Acc: 0.095\n",
      "Epoch 7/20, Train Loss: 2.319Train Acc: 0.104\n",
      "Epoch 8/20, Train Loss: 2.318Train Acc: 0.107\n",
      "Epoch 9/20, Train Loss: 2.327Train Acc: 0.090\n",
      "Epoch 10/20, Train Loss: 2.324Train Acc: 0.100\n",
      "Epoch 11/20, Train Loss: 2.327Train Acc: 0.103\n",
      "Epoch 12/20, Train Loss: 2.330Train Acc: 0.088\n",
      "Epoch 13/20, Train Loss: 2.322Train Acc: 0.103\n",
      "Epoch 14/20, Train Loss: 2.326Train Acc: 0.091\n",
      "Epoch 15/20, Train Loss: 2.325Train Acc: 0.102\n",
      "Epoch 16/20, Train Loss: 2.331Train Acc: 0.094\n",
      "Epoch 17/20, Train Loss: 2.332Train Acc: 0.092\n",
      "Epoch 18/20, Train Loss: 2.327Train Acc: 0.094\n",
      "Epoch 19/20, Train Loss: 2.323Train Acc: 0.108\n",
      "Epoch 20/20, Train Loss: 2.330Train Acc: 0.093\n",
      "Finished 142 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.10261569416498995\n",
      "Epoch 1/50, Train Loss: 2.243Train Acc: 0.170\n",
      "Epoch 2/50, Train Loss: 2.055Train Acc: 0.270\n",
      "Epoch 3/50, Train Loss: 1.920Train Acc: 0.320\n",
      "Epoch 4/50, Train Loss: 1.837Train Acc: 0.339\n",
      "Epoch 5/50, Train Loss: 1.747Train Acc: 0.407\n",
      "Epoch 6/50, Train Loss: 1.649Train Acc: 0.459\n",
      "Epoch 7/50, Train Loss: 1.566Train Acc: 0.489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Train Loss: 1.478Train Acc: 0.550\n",
      "Epoch 9/50, Train Loss: 1.393Train Acc: 0.571\n",
      "Epoch 10/50, Train Loss: 1.309Train Acc: 0.619\n",
      "Epoch 11/50, Train Loss: 1.238Train Acc: 0.637\n",
      "Epoch 12/50, Train Loss: 1.188Train Acc: 0.646\n",
      "Epoch 13/50, Train Loss: 1.115Train Acc: 0.671\n",
      "Epoch 14/50, Train Loss: 1.080Train Acc: 0.688\n",
      "Epoch 15/50, Train Loss: 1.034Train Acc: 0.683\n",
      "Epoch 16/50, Train Loss: 0.994Train Acc: 0.703\n",
      "Epoch 17/50, Train Loss: 0.954Train Acc: 0.720\n",
      "Epoch 18/50, Train Loss: 0.923Train Acc: 0.724\n",
      "Epoch 19/50, Train Loss: 0.891Train Acc: 0.738\n",
      "Epoch 20/50, Train Loss: 0.870Train Acc: 0.744\n",
      "Epoch 21/50, Train Loss: 0.849Train Acc: 0.746\n",
      "Epoch 22/50, Train Loss: 0.837Train Acc: 0.750\n",
      "Epoch 23/50, Train Loss: 0.809Train Acc: 0.762\n",
      "Epoch 24/50, Train Loss: 0.801Train Acc: 0.768\n",
      "Epoch 25/50, Train Loss: 0.784Train Acc: 0.757\n",
      "Epoch 26/50, Train Loss: 0.768Train Acc: 0.760\n",
      "Epoch 27/50, Train Loss: 0.747Train Acc: 0.782\n",
      "Epoch 28/50, Train Loss: 0.728Train Acc: 0.787\n",
      "Epoch 29/50, Train Loss: 0.721Train Acc: 0.784\n",
      "Epoch 30/50, Train Loss: 0.724Train Acc: 0.789\n",
      "Epoch 31/50, Train Loss: 0.699Train Acc: 0.794\n",
      "Epoch 32/50, Train Loss: 0.688Train Acc: 0.797\n",
      "Epoch 33/50, Train Loss: 0.687Train Acc: 0.802\n",
      "Epoch 34/50, Train Loss: 0.695Train Acc: 0.784\n",
      "Epoch 35/50, Train Loss: 0.669Train Acc: 0.808\n",
      "Epoch 36/50, Train Loss: 0.645Train Acc: 0.803\n",
      "Epoch 37/50, Train Loss: 0.652Train Acc: 0.803\n",
      "Epoch 38/50, Train Loss: 0.633Train Acc: 0.822\n",
      "Epoch 39/50, Train Loss: 0.619Train Acc: 0.817\n",
      "Epoch 40/50, Train Loss: 0.611Train Acc: 0.825\n",
      "Epoch 41/50, Train Loss: 0.614Train Acc: 0.810\n",
      "Epoch 42/50, Train Loss: 0.585Train Acc: 0.825\n",
      "Epoch 43/50, Train Loss: 0.592Train Acc: 0.824\n",
      "Epoch 44/50, Train Loss: 0.599Train Acc: 0.822\n",
      "Epoch 45/50, Train Loss: 0.580Train Acc: 0.830\n",
      "Epoch 46/50, Train Loss: 0.556Train Acc: 0.833\n",
      "Epoch 47/50, Train Loss: 0.562Train Acc: 0.836\n",
      "Epoch 48/50, Train Loss: 0.536Train Acc: 0.837\n",
      "Epoch 49/50, Train Loss: 0.526Train Acc: 0.854\n",
      "Epoch 50/50, Train Loss: 0.541Train Acc: 0.840\n",
      "Finished 143 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.29979879275653926\n",
      "Epoch 1/20, Train Loss: 1.821Train Acc: 0.363\n",
      "Epoch 2/20, Train Loss: 1.293Train Acc: 0.587\n",
      "Epoch 3/20, Train Loss: 1.033Train Acc: 0.666\n",
      "Epoch 4/20, Train Loss: 0.928Train Acc: 0.710\n",
      "Epoch 5/20, Train Loss: 0.940Train Acc: 0.694\n",
      "Epoch 6/20, Train Loss: 0.910Train Acc: 0.714\n",
      "Epoch 7/20, Train Loss: 0.906Train Acc: 0.711\n",
      "Epoch 8/20, Train Loss: 0.844Train Acc: 0.736\n",
      "Epoch 9/20, Train Loss: 0.778Train Acc: 0.753\n",
      "Epoch 10/20, Train Loss: 0.932Train Acc: 0.710\n",
      "Epoch 11/20, Train Loss: 0.900Train Acc: 0.711\n",
      "Epoch 12/20, Train Loss: 0.838Train Acc: 0.727\n",
      "Epoch 13/20, Train Loss: 0.946Train Acc: 0.695\n",
      "Epoch 14/20, Train Loss: 0.887Train Acc: 0.722\n",
      "Epoch 15/20, Train Loss: 0.967Train Acc: 0.677\n",
      "Epoch 16/20, Train Loss: 1.114Train Acc: 0.638\n",
      "Epoch 17/20, Train Loss: 1.057Train Acc: 0.664\n",
      "Epoch 18/20, Train Loss: 1.052Train Acc: 0.658\n",
      "Epoch 19/20, Train Loss: 1.056Train Acc: 0.648\n",
      "Epoch 20/20, Train Loss: 1.031Train Acc: 0.671\n",
      "Finished 144 of 144 parameter combinations\n",
      "best parameters are (64, 0.001, 50, 2, 0.2)\n",
      "dev accuracy for the given set of parameters 0.28772635814889336\n",
      "best dev accuracy 0.4567404426559356\n",
      "Epoch 1/50, Train Loss: 1.996Train Acc: 0.304\n",
      "Epoch 2/50, Train Loss: 1.484Train Acc: 0.557\n",
      "Epoch 3/50, Train Loss: 1.050Train Acc: 0.721\n",
      "Epoch 4/50, Train Loss: 0.805Train Acc: 0.778\n",
      "Epoch 5/50, Train Loss: 0.660Train Acc: 0.815\n",
      "Epoch 6/50, Train Loss: 0.548Train Acc: 0.852\n",
      "Epoch 7/50, Train Loss: 0.461Train Acc: 0.877\n",
      "Epoch 8/50, Train Loss: 0.406Train Acc: 0.888\n",
      "Epoch 9/50, Train Loss: 0.348Train Acc: 0.908\n",
      "Epoch 10/50, Train Loss: 0.302Train Acc: 0.915\n",
      "Epoch 11/50, Train Loss: 0.279Train Acc: 0.920\n",
      "Epoch 12/50, Train Loss: 0.262Train Acc: 0.928\n",
      "Epoch 13/50, Train Loss: 0.225Train Acc: 0.938\n",
      "Epoch 14/50, Train Loss: 0.213Train Acc: 0.944\n",
      "Epoch 15/50, Train Loss: 0.164Train Acc: 0.962\n",
      "Epoch 16/50, Train Loss: 0.161Train Acc: 0.961\n",
      "Epoch 17/50, Train Loss: 0.147Train Acc: 0.963\n",
      "Epoch 18/50, Train Loss: 0.127Train Acc: 0.973\n",
      "Epoch 19/50, Train Loss: 0.124Train Acc: 0.967\n",
      "Epoch 20/50, Train Loss: 0.115Train Acc: 0.970\n",
      "Epoch 21/50, Train Loss: 0.098Train Acc: 0.977\n",
      "Epoch 22/50, Train Loss: 0.101Train Acc: 0.977\n",
      "Epoch 23/50, Train Loss: 0.103Train Acc: 0.973\n",
      "Epoch 24/50, Train Loss: 0.091Train Acc: 0.979\n",
      "Epoch 25/50, Train Loss: 0.065Train Acc: 0.988\n",
      "Epoch 26/50, Train Loss: 0.062Train Acc: 0.986\n",
      "Epoch 27/50, Train Loss: 0.059Train Acc: 0.987\n",
      "Epoch 28/50, Train Loss: 0.060Train Acc: 0.985\n",
      "Epoch 29/50, Train Loss: 0.048Train Acc: 0.993\n",
      "Epoch 30/50, Train Loss: 0.036Train Acc: 0.995\n",
      "Epoch 31/50, Train Loss: 0.036Train Acc: 0.995\n",
      "Epoch 32/50, Train Loss: 0.033Train Acc: 0.996\n",
      "Epoch 33/50, Train Loss: 0.031Train Acc: 0.997\n",
      "Epoch 34/50, Train Loss: 0.029Train Acc: 0.996\n",
      "Epoch 35/50, Train Loss: 0.040Train Acc: 0.991\n",
      "Epoch 36/50, Train Loss: 0.069Train Acc: 0.979\n",
      "Epoch 37/50, Train Loss: 0.064Train Acc: 0.982\n",
      "Epoch 38/50, Train Loss: 0.036Train Acc: 0.991\n",
      "Epoch 39/50, Train Loss: 0.037Train Acc: 0.991\n",
      "Epoch 40/50, Train Loss: 0.022Train Acc: 0.998\n",
      "Epoch 41/50, Train Loss: 0.016Train Acc: 0.999\n",
      "Epoch 42/50, Train Loss: 0.018Train Acc: 0.997\n",
      "Epoch 43/50, Train Loss: 0.018Train Acc: 0.998\n",
      "Epoch 44/50, Train Loss: 0.014Train Acc: 0.998\n",
      "Epoch 45/50, Train Loss: 0.013Train Acc: 0.999\n",
      "Epoch 46/50, Train Loss: 0.019Train Acc: 0.996\n",
      "Epoch 47/50, Train Loss: 0.010Train Acc: 0.999\n",
      "Epoch 48/50, Train Loss: 0.064Train Acc: 0.980\n",
      "Epoch 49/50, Train Loss: 0.105Train Acc: 0.965\n",
      "Epoch 50/50, Train Loss: 0.088Train Acc: 0.974\n",
      "Test Loss: 0.179, Test Acc: 0.429\n",
      "Test confusion matrix:\n",
      "[[31  0  3  0  3  0 11  5  0  0]\n",
      " [ 0 30  0  0  2  1 16  0  3  3]\n",
      " [ 1  2 10  0  0  0 17 18  5  1]\n",
      " [ 0  0  0 13  1 12 11  2  3  4]\n",
      " [ 5  1  1 10  6  0 18  2  2  1]\n",
      " [ 1  1  0  0  1 25 18  3  0  1]\n",
      " [ 1  0  0  5  0  2 30  1  2  5]\n",
      " [ 0  0  0  0  2  1  7 33  3  1]\n",
      " [ 0  0  0 10  0  0 27  0 19  0]\n",
      " [ 0  0  0  0  0 16  8  7  0 19]]\n",
      "Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.58      0.67        53\n",
      "           1       0.88      0.55      0.67        55\n",
      "           2       0.71      0.19      0.29        54\n",
      "           3       0.34      0.28      0.31        46\n",
      "           4       0.40      0.13      0.20        46\n",
      "           5       0.44      0.50      0.47        50\n",
      "           6       0.18      0.65      0.29        46\n",
      "           7       0.46      0.70      0.56        47\n",
      "           8       0.51      0.34      0.41        56\n",
      "           9       0.54      0.38      0.45        50\n",
      "\n",
      "    accuracy                           0.43       503\n",
      "   macro avg       0.53      0.43      0.43       503\n",
      "weighted avg       0.54      0.43      0.44       503\n",
      "\n",
      "Dev confusion matrix:\n",
      "[[24  0  4  0  0  0  6 12  1  0]\n",
      " [ 1 19  1  0  2  1 13  1  4  3]\n",
      " [ 2  0  4  0  1  0 18 19  2  0]\n",
      " [ 0  0  0 13  0  8 27  0  3  3]\n",
      " [ 4  3  2 15 15  0 13  2  0  0]\n",
      " [ 0  1  0  0  1 23 18  1  0  6]\n",
      " [ 0  1  0  7  0  0 32  8  2  4]\n",
      " [ 0  2  0  1  0  3 12 34  1  0]\n",
      " [ 0  0  0  2  2  0 23  1 16  0]\n",
      " [ 0  0  0  3  0 10  5  6  0 26]]\n",
      "Dev classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.51      0.62        47\n",
      "           1       0.73      0.42      0.54        45\n",
      "           2       0.36      0.09      0.14        46\n",
      "           3       0.32      0.24      0.27        54\n",
      "           4       0.71      0.28      0.40        54\n",
      "           5       0.51      0.46      0.48        50\n",
      "           6       0.19      0.59      0.29        54\n",
      "           7       0.40      0.64      0.50        53\n",
      "           8       0.55      0.36      0.44        44\n",
      "           9       0.62      0.52      0.57        50\n",
      "\n",
      "    accuracy                           0.41       497\n",
      "   macro avg       0.52      0.41      0.42       497\n",
      "weighted avg       0.51      0.41      0.42       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_rnn=best_param1(train_loader=train_loader, dev_loader=dev_loader, test_loader=test_loader, \n",
    "            input_size=X_train.shape[2],output_size = len(torch.unique(y_train)), num_layers=[2,10,20], dropout_rate=[0.2,0.5],\n",
    "            hidden_size_range=[20, 50,32,64], learning_rate_range=[0.01, 0.001], num_epochs_range=[10, 20,50],model=\"rnn\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e65252a",
   "metadata": {
    "id": "2e65252a"
   },
   "source": [
    " best parameters are (64, 0.001, 50, 2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "148e7f5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "148e7f5e",
    "outputId": "9256e818-2299-4c5e-fce8-96750e4e94fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 1.924Train Acc: 0.367\n",
      "Epoch 2/50, Train Loss: 1.386Train Acc: 0.555\n",
      "Epoch 3/50, Train Loss: 1.129Train Acc: 0.653\n",
      "Epoch 4/50, Train Loss: 0.938Train Acc: 0.715\n",
      "Epoch 5/50, Train Loss: 0.812Train Acc: 0.752\n",
      "Epoch 6/50, Train Loss: 0.731Train Acc: 0.777\n",
      "Epoch 7/50, Train Loss: 0.649Train Acc: 0.798\n",
      "Epoch 8/50, Train Loss: 0.574Train Acc: 0.834\n",
      "Epoch 9/50, Train Loss: 0.541Train Acc: 0.840\n",
      "Epoch 10/50, Train Loss: 0.471Train Acc: 0.855\n",
      "Epoch 11/50, Train Loss: 0.443Train Acc: 0.865\n",
      "Epoch 12/50, Train Loss: 0.419Train Acc: 0.875\n",
      "Epoch 13/50, Train Loss: 0.378Train Acc: 0.883\n",
      "Epoch 14/50, Train Loss: 0.348Train Acc: 0.904\n",
      "Epoch 15/50, Train Loss: 0.343Train Acc: 0.897\n",
      "Epoch 16/50, Train Loss: 0.309Train Acc: 0.910\n",
      "Epoch 17/50, Train Loss: 0.285Train Acc: 0.919\n",
      "Epoch 18/50, Train Loss: 0.284Train Acc: 0.920\n",
      "Epoch 19/50, Train Loss: 0.250Train Acc: 0.924\n",
      "Epoch 20/50, Train Loss: 0.288Train Acc: 0.914\n",
      "Epoch 21/50, Train Loss: 0.229Train Acc: 0.932\n",
      "Epoch 22/50, Train Loss: 0.241Train Acc: 0.928\n",
      "Epoch 23/50, Train Loss: 0.213Train Acc: 0.937\n",
      "Epoch 24/50, Train Loss: 0.209Train Acc: 0.939\n",
      "Epoch 25/50, Train Loss: 0.213Train Acc: 0.934\n",
      "Epoch 26/50, Train Loss: 0.188Train Acc: 0.944\n",
      "Epoch 27/50, Train Loss: 0.170Train Acc: 0.951\n",
      "Epoch 28/50, Train Loss: 0.166Train Acc: 0.954\n",
      "Epoch 29/50, Train Loss: 0.174Train Acc: 0.945\n",
      "Epoch 30/50, Train Loss: 0.174Train Acc: 0.948\n",
      "Epoch 31/50, Train Loss: 0.144Train Acc: 0.957\n",
      "Epoch 32/50, Train Loss: 0.165Train Acc: 0.939\n",
      "Epoch 33/50, Train Loss: 0.147Train Acc: 0.958\n",
      "Epoch 34/50, Train Loss: 0.146Train Acc: 0.960\n",
      "Epoch 35/50, Train Loss: 0.147Train Acc: 0.953\n",
      "Epoch 36/50, Train Loss: 0.163Train Acc: 0.948\n",
      "Epoch 37/50, Train Loss: 0.116Train Acc: 0.968\n",
      "Epoch 38/50, Train Loss: 0.106Train Acc: 0.970\n",
      "Epoch 39/50, Train Loss: 0.109Train Acc: 0.971\n",
      "Epoch 40/50, Train Loss: 0.134Train Acc: 0.956\n",
      "Epoch 41/50, Train Loss: 0.114Train Acc: 0.967\n",
      "Epoch 42/50, Train Loss: 0.116Train Acc: 0.965\n",
      "Epoch 43/50, Train Loss: 0.117Train Acc: 0.965\n",
      "Epoch 44/50, Train Loss: 0.132Train Acc: 0.963\n",
      "Epoch 45/50, Train Loss: 0.095Train Acc: 0.972\n",
      "Epoch 46/50, Train Loss: 0.090Train Acc: 0.973\n",
      "Epoch 47/50, Train Loss: 0.089Train Acc: 0.976\n",
      "Epoch 48/50, Train Loss: 0.091Train Acc: 0.972\n",
      "Epoch 49/50, Train Loss: 0.090Train Acc: 0.972\n",
      "Epoch 50/50, Train Loss: 0.097Train Acc: 0.971\n",
      "Finished 1 of 12 parameter combinations\n",
      "best parameters are (0.001, 50, 0.2)\n",
      "dev accuracy for the given set of parameters 0.41448692152917505\n",
      "Epoch 1/50, Train Loss: 1.770Train Acc: 0.402\n",
      "Epoch 2/50, Train Loss: 1.187Train Acc: 0.620\n",
      "Epoch 3/50, Train Loss: 0.907Train Acc: 0.714\n",
      "Epoch 4/50, Train Loss: 0.758Train Acc: 0.757\n",
      "Epoch 5/50, Train Loss: 0.693Train Acc: 0.774\n",
      "Epoch 6/50, Train Loss: 0.564Train Acc: 0.817\n",
      "Epoch 7/50, Train Loss: 0.553Train Acc: 0.816\n",
      "Epoch 8/50, Train Loss: 0.439Train Acc: 0.857\n",
      "Epoch 9/50, Train Loss: 0.414Train Acc: 0.866\n",
      "Epoch 10/50, Train Loss: 0.401Train Acc: 0.869\n",
      "Epoch 11/50, Train Loss: 0.349Train Acc: 0.886\n",
      "Epoch 12/50, Train Loss: 0.375Train Acc: 0.874\n",
      "Epoch 13/50, Train Loss: 0.298Train Acc: 0.905\n",
      "Epoch 14/50, Train Loss: 0.323Train Acc: 0.892\n",
      "Epoch 15/50, Train Loss: 0.263Train Acc: 0.909\n",
      "Epoch 16/50, Train Loss: 0.269Train Acc: 0.911\n",
      "Epoch 17/50, Train Loss: 0.253Train Acc: 0.911\n",
      "Epoch 18/50, Train Loss: 0.252Train Acc: 0.915\n",
      "Epoch 19/50, Train Loss: 0.227Train Acc: 0.921\n",
      "Epoch 20/50, Train Loss: 0.225Train Acc: 0.920\n",
      "Epoch 21/50, Train Loss: 0.216Train Acc: 0.924\n",
      "Epoch 22/50, Train Loss: 0.216Train Acc: 0.929\n",
      "Epoch 23/50, Train Loss: 0.191Train Acc: 0.937\n",
      "Epoch 24/50, Train Loss: 0.198Train Acc: 0.933\n",
      "Epoch 25/50, Train Loss: 0.172Train Acc: 0.945\n",
      "Epoch 26/50, Train Loss: 0.204Train Acc: 0.932\n",
      "Epoch 27/50, Train Loss: 0.187Train Acc: 0.935\n",
      "Epoch 28/50, Train Loss: 0.147Train Acc: 0.954\n",
      "Epoch 29/50, Train Loss: 0.190Train Acc: 0.938\n",
      "Epoch 30/50, Train Loss: 0.215Train Acc: 0.928\n",
      "Epoch 31/50, Train Loss: 0.171Train Acc: 0.946\n",
      "Epoch 32/50, Train Loss: 0.158Train Acc: 0.946\n",
      "Epoch 33/50, Train Loss: 0.143Train Acc: 0.956\n",
      "Epoch 34/50, Train Loss: 0.156Train Acc: 0.945\n",
      "Epoch 35/50, Train Loss: 0.152Train Acc: 0.953\n",
      "Epoch 36/50, Train Loss: 0.135Train Acc: 0.952\n",
      "Epoch 37/50, Train Loss: 0.153Train Acc: 0.949\n",
      "Epoch 38/50, Train Loss: 0.141Train Acc: 0.956\n",
      "Epoch 39/50, Train Loss: 0.155Train Acc: 0.944\n",
      "Epoch 40/50, Train Loss: 0.138Train Acc: 0.957\n",
      "Epoch 41/50, Train Loss: 0.130Train Acc: 0.955\n",
      "Epoch 42/50, Train Loss: 0.111Train Acc: 0.965\n",
      "Epoch 43/50, Train Loss: 0.110Train Acc: 0.963\n",
      "Epoch 44/50, Train Loss: 0.087Train Acc: 0.971\n",
      "Epoch 45/50, Train Loss: 0.133Train Acc: 0.954\n",
      "Epoch 46/50, Train Loss: 0.123Train Acc: 0.961\n",
      "Epoch 47/50, Train Loss: 0.112Train Acc: 0.958\n",
      "Epoch 48/50, Train Loss: 0.106Train Acc: 0.964\n",
      "Epoch 49/50, Train Loss: 0.116Train Acc: 0.960\n",
      "Epoch 50/50, Train Loss: 0.116Train Acc: 0.961\n",
      "Finished 2 of 12 parameter combinations\n",
      "best parameters are (0.001, 50, 0.2)\n",
      "dev accuracy for the given set of parameters 0.4124748490945674\n",
      "Epoch 1/50, Train Loss: 2.132Train Acc: 0.278\n",
      "Epoch 2/50, Train Loss: 1.653Train Acc: 0.435\n",
      "Epoch 3/50, Train Loss: 1.410Train Acc: 0.519\n",
      "Epoch 4/50, Train Loss: 1.329Train Acc: 0.545\n",
      "Epoch 5/50, Train Loss: 1.203Train Acc: 0.590\n",
      "Epoch 6/50, Train Loss: 1.059Train Acc: 0.659\n",
      "Epoch 7/50, Train Loss: 1.040Train Acc: 0.644\n",
      "Epoch 8/50, Train Loss: 0.991Train Acc: 0.678\n",
      "Epoch 9/50, Train Loss: 0.969Train Acc: 0.672\n",
      "Epoch 10/50, Train Loss: 0.870Train Acc: 0.706\n",
      "Epoch 11/50, Train Loss: 0.870Train Acc: 0.713\n",
      "Epoch 12/50, Train Loss: 0.843Train Acc: 0.722\n",
      "Epoch 13/50, Train Loss: 0.866Train Acc: 0.713\n",
      "Epoch 14/50, Train Loss: 0.798Train Acc: 0.737\n",
      "Epoch 15/50, Train Loss: 0.729Train Acc: 0.763\n",
      "Epoch 16/50, Train Loss: 0.713Train Acc: 0.766\n",
      "Epoch 17/50, Train Loss: 0.715Train Acc: 0.755\n",
      "Epoch 18/50, Train Loss: 0.727Train Acc: 0.762\n",
      "Epoch 19/50, Train Loss: 0.721Train Acc: 0.765\n",
      "Epoch 20/50, Train Loss: 0.703Train Acc: 0.766\n",
      "Epoch 21/50, Train Loss: 0.687Train Acc: 0.776\n",
      "Epoch 22/50, Train Loss: 0.659Train Acc: 0.778\n",
      "Epoch 23/50, Train Loss: 0.663Train Acc: 0.779\n",
      "Epoch 24/50, Train Loss: 0.621Train Acc: 0.783\n",
      "Epoch 25/50, Train Loss: 0.614Train Acc: 0.800\n",
      "Epoch 26/50, Train Loss: 0.596Train Acc: 0.801\n",
      "Epoch 27/50, Train Loss: 0.605Train Acc: 0.798\n",
      "Epoch 28/50, Train Loss: 0.581Train Acc: 0.801\n",
      "Epoch 29/50, Train Loss: 0.619Train Acc: 0.796\n",
      "Epoch 30/50, Train Loss: 0.612Train Acc: 0.793\n",
      "Epoch 31/50, Train Loss: 0.584Train Acc: 0.801\n",
      "Epoch 32/50, Train Loss: 0.563Train Acc: 0.809\n",
      "Epoch 33/50, Train Loss: 0.561Train Acc: 0.810\n",
      "Epoch 34/50, Train Loss: 0.585Train Acc: 0.806\n",
      "Epoch 35/50, Train Loss: 0.526Train Acc: 0.813\n",
      "Epoch 36/50, Train Loss: 0.547Train Acc: 0.815\n",
      "Epoch 37/50, Train Loss: 0.572Train Acc: 0.813\n",
      "Epoch 38/50, Train Loss: 0.546Train Acc: 0.810\n",
      "Epoch 39/50, Train Loss: 0.540Train Acc: 0.822\n",
      "Epoch 40/50, Train Loss: 0.600Train Acc: 0.802\n",
      "Epoch 41/50, Train Loss: 0.520Train Acc: 0.829\n",
      "Epoch 42/50, Train Loss: 0.498Train Acc: 0.825\n",
      "Epoch 43/50, Train Loss: 0.521Train Acc: 0.827\n",
      "Epoch 44/50, Train Loss: 0.516Train Acc: 0.830\n",
      "Epoch 45/50, Train Loss: 0.525Train Acc: 0.824\n",
      "Epoch 46/50, Train Loss: 0.520Train Acc: 0.824\n",
      "Epoch 47/50, Train Loss: 0.503Train Acc: 0.832\n",
      "Epoch 48/50, Train Loss: 0.493Train Acc: 0.836\n",
      "Epoch 49/50, Train Loss: 0.516Train Acc: 0.822\n",
      "Epoch 50/50, Train Loss: 0.494Train Acc: 0.832\n",
      "Finished 3 of 12 parameter combinations\n",
      "best parameters are (0.001, 50, 0.2)\n",
      "dev accuracy for the given set of parameters 0.3420523138832998\n",
      "Epoch 1/20, Train Loss: 1.832Train Acc: 0.376\n",
      "Epoch 2/20, Train Loss: 1.257Train Acc: 0.601\n",
      "Epoch 3/20, Train Loss: 0.868Train Acc: 0.715\n",
      "Epoch 4/20, Train Loss: 0.698Train Acc: 0.779\n",
      "Epoch 5/20, Train Loss: 0.613Train Acc: 0.803\n",
      "Epoch 6/20, Train Loss: 0.574Train Acc: 0.808\n",
      "Epoch 7/20, Train Loss: 0.495Train Acc: 0.835\n",
      "Epoch 8/20, Train Loss: 0.463Train Acc: 0.849\n",
      "Epoch 9/20, Train Loss: 0.423Train Acc: 0.857\n",
      "Epoch 10/20, Train Loss: 0.384Train Acc: 0.875\n",
      "Epoch 11/20, Train Loss: 0.314Train Acc: 0.895\n",
      "Epoch 12/20, Train Loss: 0.300Train Acc: 0.901\n",
      "Epoch 13/20, Train Loss: 0.300Train Acc: 0.895\n",
      "Epoch 14/20, Train Loss: 0.279Train Acc: 0.912\n",
      "Epoch 15/20, Train Loss: 0.287Train Acc: 0.906\n",
      "Epoch 16/20, Train Loss: 0.265Train Acc: 0.913\n",
      "Epoch 17/20, Train Loss: 0.222Train Acc: 0.928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Train Loss: 0.247Train Acc: 0.917\n",
      "Epoch 19/20, Train Loss: 0.258Train Acc: 0.914\n",
      "Epoch 20/20, Train Loss: 0.226Train Acc: 0.924\n",
      "Finished 4 of 12 parameter combinations\n",
      "best parameters are (0.001, 50, 0.2)\n",
      "dev accuracy for the given set of parameters 0.4024144869215292\n",
      "Epoch 1/10, Train Loss: 2.227Train Acc: 0.279\n",
      "Epoch 2/10, Train Loss: 1.670Train Acc: 0.422\n",
      "Epoch 3/10, Train Loss: 1.433Train Acc: 0.523\n",
      "Epoch 4/10, Train Loss: 1.299Train Acc: 0.565\n",
      "Epoch 5/10, Train Loss: 1.218Train Acc: 0.592\n",
      "Epoch 6/10, Train Loss: 1.106Train Acc: 0.624\n",
      "Epoch 7/10, Train Loss: 1.040Train Acc: 0.652\n",
      "Epoch 8/10, Train Loss: 1.007Train Acc: 0.665\n",
      "Epoch 9/10, Train Loss: 0.947Train Acc: 0.689\n",
      "Epoch 10/10, Train Loss: 0.913Train Acc: 0.701\n",
      "Finished 5 of 12 parameter combinations\n",
      "best parameters are (0.001, 50, 0.2)\n",
      "dev accuracy for the given set of parameters 0.289738430583501\n",
      "Epoch 1/10, Train Loss: 1.746Train Acc: 0.403\n",
      "Epoch 2/10, Train Loss: 1.179Train Acc: 0.610\n",
      "Epoch 3/10, Train Loss: 0.858Train Acc: 0.721\n",
      "Epoch 4/10, Train Loss: 0.724Train Acc: 0.762\n",
      "Epoch 5/10, Train Loss: 0.622Train Acc: 0.794\n",
      "Epoch 6/10, Train Loss: 0.531Train Acc: 0.816\n",
      "Epoch 7/10, Train Loss: 0.464Train Acc: 0.859\n",
      "Epoch 8/10, Train Loss: 0.459Train Acc: 0.854\n",
      "Epoch 9/10, Train Loss: 0.393Train Acc: 0.875\n",
      "Epoch 10/10, Train Loss: 0.372Train Acc: 0.881\n",
      "Finished 6 of 12 parameter combinations\n",
      "best parameters are (0.001, 50, 0.2)\n",
      "dev accuracy for the given set of parameters 0.36217303822937624\n",
      "Epoch 1/20, Train Loss: 2.160Train Acc: 0.280\n",
      "Epoch 2/20, Train Loss: 1.652Train Acc: 0.434\n",
      "Epoch 3/20, Train Loss: 1.445Train Acc: 0.500\n",
      "Epoch 4/20, Train Loss: 1.290Train Acc: 0.567\n",
      "Epoch 5/20, Train Loss: 1.158Train Acc: 0.614\n",
      "Epoch 6/20, Train Loss: 1.091Train Acc: 0.641\n",
      "Epoch 7/20, Train Loss: 1.020Train Acc: 0.665\n",
      "Epoch 8/20, Train Loss: 0.989Train Acc: 0.671\n",
      "Epoch 9/20, Train Loss: 0.962Train Acc: 0.673\n",
      "Epoch 10/20, Train Loss: 0.881Train Acc: 0.708\n",
      "Epoch 11/20, Train Loss: 0.850Train Acc: 0.712\n",
      "Epoch 12/20, Train Loss: 0.856Train Acc: 0.723\n",
      "Epoch 13/20, Train Loss: 0.809Train Acc: 0.729\n",
      "Epoch 14/20, Train Loss: 0.830Train Acc: 0.735\n",
      "Epoch 15/20, Train Loss: 0.745Train Acc: 0.743\n",
      "Epoch 16/20, Train Loss: 0.750Train Acc: 0.741\n",
      "Epoch 17/20, Train Loss: 0.746Train Acc: 0.745\n",
      "Epoch 18/20, Train Loss: 0.724Train Acc: 0.760\n",
      "Epoch 19/20, Train Loss: 0.670Train Acc: 0.786\n",
      "Epoch 20/20, Train Loss: 0.722Train Acc: 0.759\n",
      "Finished 7 of 12 parameter combinations\n",
      "best parameters are (0.001, 50, 0.2)\n",
      "dev accuracy for the given set of parameters 0.33601609657947684\n",
      "Epoch 1/20, Train Loss: 2.158Train Acc: 0.239\n",
      "Epoch 2/20, Train Loss: 1.803Train Acc: 0.373\n",
      "Epoch 3/20, Train Loss: 1.598Train Acc: 0.446\n",
      "Epoch 4/20, Train Loss: 1.478Train Acc: 0.492\n",
      "Epoch 5/20, Train Loss: 1.355Train Acc: 0.551\n",
      "Epoch 6/20, Train Loss: 1.279Train Acc: 0.581\n",
      "Epoch 7/20, Train Loss: 1.210Train Acc: 0.598\n",
      "Epoch 8/20, Train Loss: 1.117Train Acc: 0.617\n",
      "Epoch 9/20, Train Loss: 1.082Train Acc: 0.641\n",
      "Epoch 10/20, Train Loss: 1.046Train Acc: 0.650\n",
      "Epoch 11/20, Train Loss: 1.018Train Acc: 0.670\n",
      "Epoch 12/20, Train Loss: 0.949Train Acc: 0.696\n",
      "Epoch 13/20, Train Loss: 0.898Train Acc: 0.703\n",
      "Epoch 14/20, Train Loss: 0.868Train Acc: 0.708\n",
      "Epoch 15/20, Train Loss: 0.872Train Acc: 0.716\n",
      "Epoch 16/20, Train Loss: 0.836Train Acc: 0.724\n",
      "Epoch 17/20, Train Loss: 0.823Train Acc: 0.735\n",
      "Epoch 18/20, Train Loss: 0.768Train Acc: 0.747\n",
      "Epoch 19/20, Train Loss: 0.740Train Acc: 0.758\n",
      "Epoch 20/20, Train Loss: 0.749Train Acc: 0.754\n",
      "Finished 8 of 12 parameter combinations\n",
      "best parameters are (0.001, 50, 0.2)\n",
      "dev accuracy for the given set of parameters 0.3420523138832998\n",
      "Epoch 1/50, Train Loss: 2.238Train Acc: 0.219\n",
      "Epoch 2/50, Train Loss: 1.816Train Acc: 0.357\n",
      "Epoch 3/50, Train Loss: 1.675Train Acc: 0.419\n",
      "Epoch 4/50, Train Loss: 1.544Train Acc: 0.473\n",
      "Epoch 5/50, Train Loss: 1.403Train Acc: 0.520\n",
      "Epoch 6/50, Train Loss: 1.337Train Acc: 0.525\n",
      "Epoch 7/50, Train Loss: 1.215Train Acc: 0.595\n",
      "Epoch 8/50, Train Loss: 1.169Train Acc: 0.599\n",
      "Epoch 9/50, Train Loss: 1.138Train Acc: 0.616\n",
      "Epoch 10/50, Train Loss: 1.060Train Acc: 0.643\n",
      "Epoch 11/50, Train Loss: 1.004Train Acc: 0.680\n",
      "Epoch 12/50, Train Loss: 1.006Train Acc: 0.664\n",
      "Epoch 13/50, Train Loss: 0.933Train Acc: 0.702\n",
      "Epoch 14/50, Train Loss: 0.908Train Acc: 0.683\n",
      "Epoch 15/50, Train Loss: 0.891Train Acc: 0.706\n",
      "Epoch 16/50, Train Loss: 0.888Train Acc: 0.694\n",
      "Epoch 17/50, Train Loss: 0.857Train Acc: 0.719\n",
      "Epoch 18/50, Train Loss: 0.831Train Acc: 0.733\n",
      "Epoch 19/50, Train Loss: 0.809Train Acc: 0.737\n",
      "Epoch 20/50, Train Loss: 0.763Train Acc: 0.745\n",
      "Epoch 21/50, Train Loss: 0.750Train Acc: 0.743\n",
      "Epoch 22/50, Train Loss: 0.756Train Acc: 0.747\n",
      "Epoch 23/50, Train Loss: 0.706Train Acc: 0.772\n",
      "Epoch 24/50, Train Loss: 0.697Train Acc: 0.768\n",
      "Epoch 25/50, Train Loss: 0.709Train Acc: 0.774\n",
      "Epoch 26/50, Train Loss: 0.692Train Acc: 0.764\n",
      "Epoch 27/50, Train Loss: 0.686Train Acc: 0.774\n",
      "Epoch 28/50, Train Loss: 0.675Train Acc: 0.778\n",
      "Epoch 29/50, Train Loss: 0.651Train Acc: 0.775\n",
      "Epoch 30/50, Train Loss: 0.604Train Acc: 0.798\n",
      "Epoch 31/50, Train Loss: 0.624Train Acc: 0.783\n",
      "Epoch 32/50, Train Loss: 0.608Train Acc: 0.793\n",
      "Epoch 33/50, Train Loss: 0.601Train Acc: 0.801\n",
      "Epoch 34/50, Train Loss: 0.563Train Acc: 0.810\n",
      "Epoch 35/50, Train Loss: 0.566Train Acc: 0.816\n",
      "Epoch 36/50, Train Loss: 0.599Train Acc: 0.793\n",
      "Epoch 37/50, Train Loss: 0.548Train Acc: 0.818\n",
      "Epoch 38/50, Train Loss: 0.554Train Acc: 0.815\n",
      "Epoch 39/50, Train Loss: 0.548Train Acc: 0.816\n",
      "Epoch 40/50, Train Loss: 0.544Train Acc: 0.815\n",
      "Epoch 41/50, Train Loss: 0.535Train Acc: 0.817\n",
      "Epoch 42/50, Train Loss: 0.530Train Acc: 0.825\n",
      "Epoch 43/50, Train Loss: 0.540Train Acc: 0.822\n",
      "Epoch 44/50, Train Loss: 0.507Train Acc: 0.824\n",
      "Epoch 45/50, Train Loss: 0.523Train Acc: 0.823\n",
      "Epoch 46/50, Train Loss: 0.498Train Acc: 0.839\n",
      "Epoch 47/50, Train Loss: 0.527Train Acc: 0.834\n",
      "Epoch 48/50, Train Loss: 0.497Train Acc: 0.840\n",
      "Epoch 49/50, Train Loss: 0.488Train Acc: 0.841\n",
      "Epoch 50/50, Train Loss: 0.503Train Acc: 0.828\n",
      "Finished 9 of 12 parameter combinations\n",
      "best parameters are (0.001, 50, 0.2)\n",
      "dev accuracy for the given set of parameters 0.34004024144869216\n",
      "Epoch 1/10, Train Loss: 1.904Train Acc: 0.339\n",
      "Epoch 2/10, Train Loss: 1.396Train Acc: 0.566\n",
      "Epoch 3/10, Train Loss: 1.130Train Acc: 0.656\n",
      "Epoch 4/10, Train Loss: 0.920Train Acc: 0.731\n",
      "Epoch 5/10, Train Loss: 0.796Train Acc: 0.768\n",
      "Epoch 6/10, Train Loss: 0.676Train Acc: 0.806\n",
      "Epoch 7/10, Train Loss: 0.626Train Acc: 0.820\n",
      "Epoch 8/10, Train Loss: 0.556Train Acc: 0.839\n",
      "Epoch 9/10, Train Loss: 0.499Train Acc: 0.851\n",
      "Epoch 10/10, Train Loss: 0.464Train Acc: 0.868\n",
      "Finished 10 of 12 parameter combinations\n",
      "best parameters are (0.001, 50, 0.2)\n",
      "dev accuracy for the given set of parameters 0.35412474849094566\n",
      "Epoch 1/10, Train Loss: 2.233Train Acc: 0.233\n",
      "Epoch 2/10, Train Loss: 1.796Train Acc: 0.381\n",
      "Epoch 3/10, Train Loss: 1.628Train Acc: 0.433\n",
      "Epoch 4/10, Train Loss: 1.475Train Acc: 0.499\n",
      "Epoch 5/10, Train Loss: 1.344Train Acc: 0.536\n",
      "Epoch 6/10, Train Loss: 1.303Train Acc: 0.545\n",
      "Epoch 7/10, Train Loss: 1.206Train Acc: 0.599\n",
      "Epoch 8/10, Train Loss: 1.143Train Acc: 0.622\n",
      "Epoch 9/10, Train Loss: 1.087Train Acc: 0.649\n",
      "Epoch 10/10, Train Loss: 1.032Train Acc: 0.651\n",
      "Finished 11 of 12 parameter combinations\n",
      "best parameters are (0.001, 50, 0.2)\n",
      "dev accuracy for the given set of parameters 0.27565392354124746\n",
      "Epoch 1/20, Train Loss: 1.862Train Acc: 0.367\n",
      "Epoch 2/20, Train Loss: 1.377Train Acc: 0.572\n",
      "Epoch 3/20, Train Loss: 1.090Train Acc: 0.690\n",
      "Epoch 4/20, Train Loss: 0.934Train Acc: 0.726\n",
      "Epoch 5/20, Train Loss: 0.783Train Acc: 0.773\n",
      "Epoch 6/20, Train Loss: 0.693Train Acc: 0.793\n",
      "Epoch 7/20, Train Loss: 0.650Train Acc: 0.807\n",
      "Epoch 8/20, Train Loss: 0.594Train Acc: 0.827\n",
      "Epoch 9/20, Train Loss: 0.546Train Acc: 0.828\n",
      "Epoch 10/20, Train Loss: 0.493Train Acc: 0.860\n",
      "Epoch 11/20, Train Loss: 0.447Train Acc: 0.862\n",
      "Epoch 12/20, Train Loss: 0.449Train Acc: 0.871\n",
      "Epoch 13/20, Train Loss: 0.395Train Acc: 0.886\n",
      "Epoch 14/20, Train Loss: 0.371Train Acc: 0.892\n",
      "Epoch 15/20, Train Loss: 0.353Train Acc: 0.891\n",
      "Epoch 16/20, Train Loss: 0.329Train Acc: 0.895\n",
      "Epoch 17/20, Train Loss: 0.313Train Acc: 0.900\n",
      "Epoch 18/20, Train Loss: 0.276Train Acc: 0.914\n",
      "Epoch 19/20, Train Loss: 0.289Train Acc: 0.917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Train Loss: 0.255Train Acc: 0.923\n",
      "Finished 12 of 12 parameter combinations\n",
      "best parameters are (0.001, 50, 0.2)\n",
      "dev accuracy for the given set of parameters 0.3782696177062374\n",
      "best dev accuracy 0.41448692152917505\n",
      "Epoch 1/50, Train Loss: 1.849Train Acc: 0.371\n",
      "Epoch 2/50, Train Loss: 1.347Train Acc: 0.591\n",
      "Epoch 3/50, Train Loss: 1.087Train Acc: 0.675\n",
      "Epoch 4/50, Train Loss: 0.938Train Acc: 0.723\n",
      "Epoch 5/50, Train Loss: 0.789Train Acc: 0.762\n",
      "Epoch 6/50, Train Loss: 0.683Train Acc: 0.802\n",
      "Epoch 7/50, Train Loss: 0.605Train Acc: 0.825\n",
      "Epoch 8/50, Train Loss: 0.524Train Acc: 0.844\n",
      "Epoch 9/50, Train Loss: 0.498Train Acc: 0.864\n",
      "Epoch 10/50, Train Loss: 0.464Train Acc: 0.860\n",
      "Epoch 11/50, Train Loss: 0.415Train Acc: 0.880\n",
      "Epoch 12/50, Train Loss: 0.397Train Acc: 0.886\n",
      "Epoch 13/50, Train Loss: 0.377Train Acc: 0.885\n",
      "Epoch 14/50, Train Loss: 0.333Train Acc: 0.898\n",
      "Epoch 15/50, Train Loss: 0.293Train Acc: 0.919\n",
      "Epoch 16/50, Train Loss: 0.298Train Acc: 0.909\n",
      "Epoch 17/50, Train Loss: 0.262Train Acc: 0.924\n",
      "Epoch 18/50, Train Loss: 0.270Train Acc: 0.917\n",
      "Epoch 19/50, Train Loss: 0.244Train Acc: 0.927\n",
      "Epoch 20/50, Train Loss: 0.235Train Acc: 0.929\n",
      "Epoch 21/50, Train Loss: 0.233Train Acc: 0.929\n",
      "Epoch 22/50, Train Loss: 0.222Train Acc: 0.939\n",
      "Epoch 23/50, Train Loss: 0.204Train Acc: 0.944\n",
      "Epoch 24/50, Train Loss: 0.209Train Acc: 0.939\n",
      "Epoch 25/50, Train Loss: 0.172Train Acc: 0.947\n",
      "Epoch 26/50, Train Loss: 0.180Train Acc: 0.945\n",
      "Epoch 27/50, Train Loss: 0.196Train Acc: 0.935\n",
      "Epoch 28/50, Train Loss: 0.166Train Acc: 0.951\n",
      "Epoch 29/50, Train Loss: 0.164Train Acc: 0.948\n",
      "Epoch 30/50, Train Loss: 0.141Train Acc: 0.962\n",
      "Epoch 31/50, Train Loss: 0.140Train Acc: 0.958\n",
      "Epoch 32/50, Train Loss: 0.131Train Acc: 0.964\n",
      "Epoch 33/50, Train Loss: 0.135Train Acc: 0.962\n",
      "Epoch 34/50, Train Loss: 0.122Train Acc: 0.968\n",
      "Epoch 35/50, Train Loss: 0.137Train Acc: 0.960\n",
      "Epoch 36/50, Train Loss: 0.115Train Acc: 0.970\n",
      "Epoch 37/50, Train Loss: 0.129Train Acc: 0.962\n",
      "Epoch 38/50, Train Loss: 0.138Train Acc: 0.959\n",
      "Epoch 39/50, Train Loss: 0.107Train Acc: 0.969\n",
      "Epoch 40/50, Train Loss: 0.103Train Acc: 0.967\n",
      "Epoch 41/50, Train Loss: 0.113Train Acc: 0.966\n",
      "Epoch 42/50, Train Loss: 0.122Train Acc: 0.963\n",
      "Epoch 43/50, Train Loss: 0.102Train Acc: 0.969\n",
      "Epoch 44/50, Train Loss: 0.092Train Acc: 0.973\n",
      "Epoch 45/50, Train Loss: 0.086Train Acc: 0.975\n",
      "Epoch 46/50, Train Loss: 0.085Train Acc: 0.975\n",
      "Epoch 47/50, Train Loss: 0.098Train Acc: 0.972\n",
      "Epoch 48/50, Train Loss: 0.082Train Acc: 0.978\n",
      "Epoch 49/50, Train Loss: 0.077Train Acc: 0.979\n",
      "Epoch 50/50, Train Loss: 0.093Train Acc: 0.975\n",
      "Test Loss: 0.134, Test Acc: 0.439\n",
      "Test confusion matrix:\n",
      "[[30  0  3  0  1  6  2  5  1  5]\n",
      " [ 0 23  1  2  0  6 21  1  0  1]\n",
      " [ 0  0 15  1  0  1 23 10  3  1]\n",
      " [ 0  2  3 10  0  0 10  5  6 10]\n",
      " [14  2  1  2  3 12  3  5  3  1]\n",
      " [ 0  2  0  0  3 14 18  3  1  9]\n",
      " [ 1  0  0  2  0  0 37  3  3  0]\n",
      " [ 0  0  2  1  0  3  3 35  1  2]\n",
      " [ 0  0  0  0  0  0 28  0 26  2]\n",
      " [ 0  1  1  1  1  6  8  3  1 28]]\n",
      "Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.61        53\n",
      "           1       0.77      0.42      0.54        55\n",
      "           2       0.58      0.28      0.38        54\n",
      "           3       0.53      0.22      0.31        46\n",
      "           4       0.38      0.07      0.11        46\n",
      "           5       0.29      0.28      0.29        50\n",
      "           6       0.24      0.80      0.37        46\n",
      "           7       0.50      0.74      0.60        47\n",
      "           8       0.58      0.46      0.51        56\n",
      "           9       0.47      0.56      0.51        50\n",
      "\n",
      "    accuracy                           0.44       503\n",
      "   macro avg       0.50      0.44      0.42       503\n",
      "weighted avg       0.51      0.44      0.43       503\n",
      "\n",
      "Dev confusion matrix:\n",
      "[[31  0  3  1  2  4  2  0  1  3]\n",
      " [ 0 22  1  0  0  3 18  0  1  0]\n",
      " [ 1  0  3  6  0  1 12 13  9  1]\n",
      " [ 3  7  0 12  1  2 14  5  6  4]\n",
      " [18  3  2  3  4 10  3  7  1  3]\n",
      " [ 1  5  0  1  1  7 19  1  6  9]\n",
      " [ 0  1  0  2  0  1 42  4  2  2]\n",
      " [ 0  0  4  4  0  1  9 34  0  1]\n",
      " [ 0  0  1  0  0  2 16  0 24  1]\n",
      " [ 0  3  1  0  0  7  8  1  1 29]]\n",
      "Dev classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.66      0.61        47\n",
      "           1       0.54      0.49      0.51        45\n",
      "           2       0.20      0.07      0.10        46\n",
      "           3       0.41      0.22      0.29        54\n",
      "           4       0.50      0.07      0.13        54\n",
      "           5       0.18      0.14      0.16        50\n",
      "           6       0.29      0.78      0.43        54\n",
      "           7       0.52      0.64      0.58        53\n",
      "           8       0.47      0.55      0.51        44\n",
      "           9       0.55      0.58      0.56        50\n",
      "\n",
      "    accuracy                           0.42       497\n",
      "   macro avg       0.42      0.42      0.39       497\n",
      "weighted avg       0.42      0.42      0.38       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_TCN=best_param1(train_loader=train_loader, dev_loader=dev_loader, test_loader=test_loader, \n",
    "            input_size=X_train.shape[2],output_size = len(torch.unique(y_train)), num_layers=[2,10,20], dropout_rate=[0.2,0.5],\n",
    "            hidden_size_range=[20, 50,32,64], learning_rate_range=[0.01, 0.001], num_epochs_range=[10, 20,50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qM-VCq7FdgAX",
   "metadata": {
    "id": "qM-VCq7FdgAX"
   },
   "source": [
    "In the baseline model, we got a Dev accuracy of 0.342 and Test accuracy of 0.38. When we look at the Test Classification report, we can see that the precision, recall and f1-score is highest for the digits 1, 0 and 0 repectively.\n",
    "\n",
    "In the RNN model, we got a Dev accuracy of 0.456 and Test accuracy of 0.429. When we look at the Test Classification report, we can see that the precision, recall and f1-score is highest for the digits 1, 7 and 0 repectively.\n",
    "\n",
    "In the TCN model, we got a Dev accuracy of 0.414 and Test accuracy of 0.439. When we look at the Test Classification report, we can see that the precision, recall and f1-score is highest for 1, 6 and 0 repectively.\n",
    "\n",
    "The Neural Networks shows comparitively better accuracies than the baseline model. \n",
    "\n",
    "We can definitely observe the signs of overfitting by looking at the training accuracies. we got very high training accuracies in both RNN and TCN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a57ef1",
   "metadata": {
    "id": "30a57ef1"
   },
   "source": [
    "best parameters are  learning_rate,num_epochs,dropout_rate=best_params=0.001,50,0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "896949b1",
   "metadata": {
    "id": "896949b1"
   },
   "outputs": [],
   "source": [
    "learning_ratetcn=0.001\n",
    "num_epochstcn=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o734zJyQ3wwm",
   "metadata": {
    "id": "o734zJyQ3wwm"
   },
   "source": [
    "## tSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3e456a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "e3e456a8",
    "outputId": "8d847b83-008e-45f6-99e4-95e6ed121725"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Function to get the features from a model for a given dataset\n",
    "def get_features(model, dataloader):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            features.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "    return np.array(features), np.array(targets)\n",
    "\n",
    "# Get features from TCN model\n",
    "tcn_features, tcn_targets = get_features(model_TCN, test_loader)\n",
    "\n",
    "# Get features from RNN model\n",
    "rnn_features, rnn_targets = get_features(model_rnn, test_loader)\n",
    "\n",
    "# Concatenate the features and targets from both models\n",
    "all_features = np.concatenate((tcn_features, rnn_features))\n",
    "all_targets = np.concatenate((tcn_targets, rnn_targets))\n",
    "\n",
    "# Apply t-SNE to reduce dimensionality to 2D\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_features = tsne.fit_transform(all_features)\n",
    "\n",
    "# Plot the reduced features\n",
    "plt.scatter(reduced_features[:, 0], reduced_features[:, 1], c=all_targets)\n",
    "plt.title('t-SNE visualization of features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a0bd71cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to get the features from a model for a given dataset\n",
    "def get_features2(model, dataloader):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs,use_lastlayer=True)\n",
    "            features.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "    return np.array(features), np.array(targets)\n",
    "\n",
    "# Get features from TCN model\n",
    "tcn_features, tcn_targets = get_features2(model_TCN, test_loader)\n",
    "\n",
    "# Apply t-SNE to reduce dimensionality to 2D\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_features = tsne.fit_transform(tcn_features)\n",
    "\n",
    "# Plot the reduced features\n",
    "plt.scatter(reduced_features[:, 0], reduced_features[:, 1], c=tcn_targets)\n",
    "plt.title('t-SNE visualization of TCN features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "daa26f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to get the features from a model for a given dataset\n",
    "def get_features(model, dataloader):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            features.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "    return np.array(features), np.array(targets)\n",
    "\n",
    "# Get features from RNN model\n",
    "rnn_features, rnn_targets = get_features(model_rnn, test_loader)\n",
    "\n",
    "# Apply t-SNE to reduce dimensionality to 2D\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_features = tsne.fit_transform(rnn_features)\n",
    "\n",
    "# Plot the reduced features\n",
    "plt.scatter(reduced_features[:, 0], reduced_features[:, 1], c=rnn_targets)\n",
    "plt.title('t-SNE visualization of RNN features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d6f17c",
   "metadata": {
    "id": "07d6f17c"
   },
   "source": [
    "Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b010f78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2b010f78",
    "outputId": "c2daa77f-5d94-4ee2-b142-3910158b8675"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.134, Test Acc: 0.439\n",
      "Test confusion matrix:\n",
      "[[30  0  3  0  1  6  2  5  1  5]\n",
      " [ 0 23  1  2  0  6 21  1  0  1]\n",
      " [ 0  0 15  1  0  1 23 10  3  1]\n",
      " [ 0  2  3 10  0  0 10  5  6 10]\n",
      " [14  2  1  2  3 12  3  5  3  1]\n",
      " [ 0  2  0  0  3 14 18  3  1  9]\n",
      " [ 1  0  0  2  0  0 37  3  3  0]\n",
      " [ 0  0  2  1  0  3  3 35  1  2]\n",
      " [ 0  0  0  0  0  0 28  0 26  2]\n",
      " [ 0  1  1  1  1  6  8  3  1 28]]\n",
      "Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.61        53\n",
      "           1       0.77      0.42      0.54        55\n",
      "           2       0.58      0.28      0.38        54\n",
      "           3       0.53      0.22      0.31        46\n",
      "           4       0.38      0.07      0.11        46\n",
      "           5       0.29      0.28      0.29        50\n",
      "           6       0.24      0.80      0.37        46\n",
      "           7       0.50      0.74      0.60        47\n",
      "           8       0.58      0.46      0.51        56\n",
      "           9       0.47      0.56      0.51        50\n",
      "\n",
      "    accuracy                           0.44       503\n",
      "   macro avg       0.50      0.44      0.42       503\n",
      "weighted avg       0.51      0.44      0.43       503\n",
      "\n",
      "Test Loss: 0.179, Test Acc: 0.429\n",
      "Test confusion matrix:\n",
      "[[31  0  3  0  3  0 11  5  0  0]\n",
      " [ 0 30  0  0  2  1 16  0  3  3]\n",
      " [ 1  2 10  0  0  0 17 18  5  1]\n",
      " [ 0  0  0 13  1 12 11  2  3  4]\n",
      " [ 5  1  1 10  6  0 18  2  2  1]\n",
      " [ 1  1  0  0  1 25 18  3  0  1]\n",
      " [ 1  0  0  5  0  2 30  1  2  5]\n",
      " [ 0  0  0  0  2  1  7 33  3  1]\n",
      " [ 0  0  0 10  0  0 27  0 19  0]\n",
      " [ 0  0  0  0  0 16  8  7  0 19]]\n",
      "Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.58      0.67        53\n",
      "           1       0.88      0.55      0.67        55\n",
      "           2       0.71      0.19      0.29        54\n",
      "           3       0.34      0.28      0.31        46\n",
      "           4       0.40      0.13      0.20        46\n",
      "           5       0.44      0.50      0.47        50\n",
      "           6       0.18      0.65      0.29        46\n",
      "           7       0.46      0.70      0.56        47\n",
      "           8       0.51      0.34      0.41        56\n",
      "           9       0.54      0.38      0.45        50\n",
      "\n",
      "    accuracy                           0.43       503\n",
      "   macro avg       0.53      0.43      0.43       503\n",
      "weighted avg       0.54      0.43      0.44       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tcn_test_cr=test(model_TCN,test_loader)\n",
    "rnn_test_cr = test(model_rnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9d391e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9d391e0",
    "outputId": "85f083a9-5bf6-4e9b-d970-e1b6bac8a78c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value for difference between RNN and TCN models: 0.0429\n",
      "p-value for difference between baseline and RNN models: 0.6121\n",
      "p-value for difference between baseline and TCN models: 0.0765\n",
      "The difference between the F1 scores of the RNN and TCN models is statistically significant.\n",
      "The difference between the F1 scores of the baseline and RNN models is not statistically significant.\n",
      "The difference between the F1 scores of the baseline and TCN models is not statistically significant.\n"
     ]
    }
   ],
   "source": [
    "# Define the F1 scores for each model\n",
    "report_lines_base = test_classification_report.split('\\n')\n",
    "report_lines_rnn = rnn_test_cr.split('\\n')\n",
    "report_lines_tcn = tcn_test_cr.split('\\n')\n",
    "model_base_f1 = [float(report_lines_base[i].split()[-2]) for i in range(2, 12)]\n",
    "model_rnn_f1 = [float(report_lines_rnn[i].split()[-2]) for i in range(2, 12)]\n",
    "model_tcn_f1 = [float(report_lines_tcn[i].split()[-2]) for i in range(2, 12)]\n",
    "\n",
    "# Define the number of bootstrap samples to generate\n",
    "n_samples = 10000\n",
    "\n",
    "# Define a function to compute the difference in F1 score between two specific F1 scores\n",
    "def diff_f1(f1_1, f1_2):\n",
    "    return f1_1 - f1_2\n",
    "\n",
    "# Compute the differences in F1 score for each pair of models\n",
    "diff_base_rnn = diff_f1(model_base_f1[0], model_rnn_f1[0])\n",
    "diff_base_tcn = diff_f1(model_base_f1[0], model_tcn_f1[0])\n",
    "diff_rnn_tcn = diff_f1(model_rnn_f1[0], model_tcn_f1[0])\n",
    "\n",
    "# Generate multiple bootstrap samples and compute the differences in F1 score for each sample\n",
    "diffs_base_rnn = np.zeros(n_samples)\n",
    "diffs_base_tcn = np.zeros(n_samples)\n",
    "diffs_rnn_tcn = np.zeros(n_samples)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # Generate a new sample by randomly sampling with replacement from the original dataset\n",
    "    y_true_sample = np.random.choice([0, 1], size=len(y_test_1), replace=True)\n",
    "    model_base_sample = np.random.choice([0, 1], size=len(y_test_1), replace=True)\n",
    "    model_rnn_sample = np.random.choice([0, 1], size=len(y_test), replace=True)\n",
    "    model_tcn_sample = np.random.choice([0, 1], size=len(y_test), replace=True)\n",
    "\n",
    "    # Compute the F1 scores for each model using the new sample\n",
    "    model_base_f1_sample = f1_score(y_true_sample, model_base_sample)\n",
    "    model_rnn_f1_sample = f1_score(y_true_sample, model_rnn_sample)\n",
    "    model_tcn_f1_sample = f1_score(y_true_sample, model_tcn_sample)\n",
    "\n",
    "    # Compute the differences in F1 score for each pair of models using the new sample\n",
    "    diffs_base_rnn[i] = diff_f1(model_base_f1_sample, model_rnn_f1_sample)\n",
    "    diffs_base_tcn[i] = diff_f1(model_base_f1_sample, model_tcn_f1_sample)\n",
    "    diffs_rnn_tcn[i] = diff_f1(model_rnn_f1_sample, model_tcn_f1_sample)\n",
    "\n",
    "# Compute the p-values for each pair of models based on the bootstrap samples\n",
    "\n",
    "p_value_rnn_tcn = np.mean(diffs_rnn_tcn >= diff_rnn_tcn)\n",
    "p_value_base_rnn = np.mean(diffs_base_rnn >= diff_base_rnn)\n",
    "p_value_base_tcn = np.mean(diffs_base_tcn >= diff_base_tcn)\n",
    "\n",
    "\n",
    "# Print the p-value and whether the difference is significant or not\n",
    "print(\"p-value for difference between RNN and TCN models:\", p_value_rnn_tcn)\n",
    "print(\"p-value for difference between baseline and RNN models:\", p_value_base_rnn)\n",
    "print(\"p-value for difference between baseline and TCN models:\", p_value_base_tcn)\n",
    "\n",
    "if p_value_rnn_tcn < 0.05:\n",
    "    print(\"The difference between the F1 scores of the RNN and TCN models is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference between the F1 scores of the RNN and TCN models is not statistically significant.\")\n",
    "\n",
    "if p_value_base_rnn < 0.05:\n",
    "    print(\"The difference between the F1 scores of the baseline and RNN models is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference between the F1 scores of the baseline and RNN models is not statistically significant.\")\n",
    "\n",
    "if p_value_base_tcn < 0.05:\n",
    "    print(\"The difference between the F1 scores of the baseline and TCN models is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference between the F1 scores of the baseline and TCN models is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f95e312",
   "metadata": {
    "id": "8f95e312"
   },
   "source": [
    "## Task III (Open Ended)\n",
    "1. Consider the case where we have speech data from a single speaker (e.g., george). Train your models on this subset of the data. What do you observe? How does this affect the model performance?\n",
    "\n",
    "2. Even though a model is trained on a single speaker, we would like the model to generalizes to any speaker. To this end, one can use data augmentation techniques to artificially create more samples for each class. Some of these augmentations can be applied on the spectrogram (e.g., SpecAugment https://ai.googleblog.com/2019/04/specaugment-new-data-augmentation.html), and other can be applied on the raw waveform before creating the spectrogram such as pitch manipulation (https://github.com/facebookresearch/WavAugment). Explore the effect of one type of augmentation from each type. Report your observation and anaylze the confusion matrices.\n",
    "\n",
    "3. Data augmentation techniques create different \"views\" of each training sample in a stochastic or determinstic approach. One can leaverage speech data augmentation to create views for training a neural network in a contrastive learning setting with margin-based objective function (for more info, read http://proceedings.mlr.press/v130/al-tahan21a/al-tahan21a.pdf). Implement at least one model using a contrastive loss based on different views of the training samples. Does this model improve over the model without contrastive learning? Report and discuss your observations. \n",
    "\n",
    "For more information on the contrastive learning framework, you can refer to this paper\n",
    "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9226466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "33674cd9",
   "metadata": {
    "id": "33674cd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 13, 229])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metadata\n",
    "sdr_df = pd.read_csv('SDR_metadata.tsv', sep='\\t', header=0, index_col='Unnamed: 0')\n",
    "\n",
    "# Load data for each audio file, downsample and extract mel-spectrogram features\n",
    "def load_downsample_melspec(audio_file, sr=8000, num_mels=13, hop_length=80):\n",
    "    signal, _ = librosa.load(audio_file, sr=sr)\n",
    "    mel_features = extract_melspectrogram(signal,sr=8000, num_mels=13)\n",
    "    return mel_features\n",
    "\n",
    "\n",
    "max_length = 0\n",
    "for _, row in sdr_df.iterrows():\n",
    "    mel_spec = load_downsample_melspec(row['file'])\n",
    "    if mel_spec.shape[1] > max_length:\n",
    "        max_length = mel_spec.shape[1]\n",
    "\n",
    "# Load data and labels for all files in the metadata\n",
    "X = []\n",
    "y = []\n",
    "for _, row in sdr_df.iterrows():\n",
    "    mel_features = load_downsample_melspec(row['file'])\n",
    "    padded_mel_features = np.pad(mel_features, ((0, 0), (0, max_length - mel_features.shape[1])), mode='constant')\n",
    "    X.append(padded_mel_features)\n",
    "    y.append(row['label'])\n",
    "speakers=[\"george\"]\n",
    "# Split data into train, dev, and test sets\n",
    "train_indices = sdr_df[sdr_df['split'] == 'TRAIN']\n",
    "train_indices= train_indices[train_indices['speaker'].isin(speakers)].index\n",
    "dev_indices = sdr_df[sdr_df['split'] == 'DEV'].index\n",
    "test_indices = sdr_df[sdr_df['split'] == 'TEST'].index\n",
    "\n",
    "X_train = [X[i] for i in train_indices]\n",
    "y_train = [y[i] for i in train_indices]\n",
    "\n",
    "X_dev = [X[i] for i in dev_indices]\n",
    "y_dev = [y[i] for i in dev_indices]\n",
    "\n",
    "X_test = [X[i] for i in test_indices]\n",
    "y_test = [y[i] for i in test_indices]\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_onedata = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_dev = torch.tensor(X_dev, dtype=torch.float32)\n",
    "y_dev = torch.tensor(y_dev, dtype=torch.long)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "\n",
    "X_train_onedata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d47f4125",
   "metadata": {
    "id": "d47f4125"
   },
   "outputs": [],
   "source": [
    "train_loaderone,dev_loaderone,test_loaderone=loader(X_train_onedata,y_train,X_dev,y_dev,X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "688e3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelone = TCN(input_size, output_size, num_channels=[64, 64, 64], kernel_size=3,dropout=0.2)\n",
    "modelonernn=RNNModel(input_size, 60, 2, output_size, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6aab3876",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6aab3876",
    "outputId": "04a45c14-976e-43d6-baed-e21b72b2f19b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 2.210Train Acc: 0.236\n",
      "Epoch 2/50, Train Loss: 1.715Train Acc: 0.456\n",
      "Epoch 3/50, Train Loss: 1.463Train Acc: 0.556\n",
      "Epoch 4/50, Train Loss: 1.278Train Acc: 0.626\n",
      "Epoch 5/50, Train Loss: 1.086Train Acc: 0.686\n",
      "Epoch 6/50, Train Loss: 0.961Train Acc: 0.754\n",
      "Epoch 7/50, Train Loss: 0.875Train Acc: 0.774\n",
      "Epoch 8/50, Train Loss: 0.772Train Acc: 0.814\n",
      "Epoch 9/50, Train Loss: 0.698Train Acc: 0.814\n",
      "Epoch 10/50, Train Loss: 0.626Train Acc: 0.838\n",
      "Epoch 11/50, Train Loss: 0.571Train Acc: 0.844\n",
      "Epoch 12/50, Train Loss: 0.531Train Acc: 0.870\n",
      "Epoch 13/50, Train Loss: 0.531Train Acc: 0.876\n",
      "Epoch 14/50, Train Loss: 0.469Train Acc: 0.882\n",
      "Epoch 15/50, Train Loss: 0.440Train Acc: 0.894\n",
      "Epoch 16/50, Train Loss: 0.391Train Acc: 0.902\n",
      "Epoch 17/50, Train Loss: 0.376Train Acc: 0.910\n",
      "Epoch 18/50, Train Loss: 0.356Train Acc: 0.914\n",
      "Epoch 19/50, Train Loss: 0.316Train Acc: 0.934\n",
      "Epoch 20/50, Train Loss: 0.279Train Acc: 0.934\n",
      "Epoch 21/50, Train Loss: 0.274Train Acc: 0.936\n",
      "Epoch 22/50, Train Loss: 0.265Train Acc: 0.942\n",
      "Epoch 23/50, Train Loss: 0.263Train Acc: 0.936\n",
      "Epoch 24/50, Train Loss: 0.277Train Acc: 0.920\n",
      "Epoch 25/50, Train Loss: 0.267Train Acc: 0.932\n",
      "Epoch 26/50, Train Loss: 0.230Train Acc: 0.940\n",
      "Epoch 27/50, Train Loss: 0.202Train Acc: 0.948\n",
      "Epoch 28/50, Train Loss: 0.181Train Acc: 0.960\n",
      "Epoch 29/50, Train Loss: 0.182Train Acc: 0.962\n",
      "Epoch 30/50, Train Loss: 0.177Train Acc: 0.958\n",
      "Epoch 31/50, Train Loss: 0.163Train Acc: 0.952\n",
      "Epoch 32/50, Train Loss: 0.183Train Acc: 0.964\n",
      "Epoch 33/50, Train Loss: 0.151Train Acc: 0.968\n",
      "Epoch 34/50, Train Loss: 0.138Train Acc: 0.970\n",
      "Epoch 35/50, Train Loss: 0.124Train Acc: 0.970\n",
      "Epoch 36/50, Train Loss: 0.124Train Acc: 0.972\n",
      "Epoch 37/50, Train Loss: 0.111Train Acc: 0.976\n",
      "Epoch 38/50, Train Loss: 0.098Train Acc: 0.990\n",
      "Epoch 39/50, Train Loss: 0.092Train Acc: 0.984\n",
      "Epoch 40/50, Train Loss: 0.113Train Acc: 0.978\n",
      "Epoch 41/50, Train Loss: 0.134Train Acc: 0.968\n",
      "Epoch 42/50, Train Loss: 0.125Train Acc: 0.972\n",
      "Epoch 43/50, Train Loss: 0.110Train Acc: 0.966\n",
      "Epoch 44/50, Train Loss: 0.103Train Acc: 0.980\n",
      "Epoch 45/50, Train Loss: 0.122Train Acc: 0.966\n",
      "Epoch 46/50, Train Loss: 0.097Train Acc: 0.982\n",
      "Epoch 47/50, Train Loss: 0.075Train Acc: 0.986\n",
      "Epoch 48/50, Train Loss: 0.081Train Acc: 0.986\n",
      "Epoch 49/50, Train Loss: 0.073Train Acc: 0.990\n",
      "Epoch 50/50, Train Loss: 0.073Train Acc: 0.986\n",
      "Test Loss: 0.137, Test Acc: 0.219\n",
      "Test confusion matrix:\n",
      "[[22  4  0  2  9  5  2  4  1  4]\n",
      " [ 1 21  0  9  6  2  9  1  2  4]\n",
      " [ 2  4  1 19  2  3  6 13  4  0]\n",
      " [15  3  1  8  7  1  7  2  0  2]\n",
      " [14  0  2  7 15  1  2  3  2  0]\n",
      " [11 16  0  4  2  2  6  3  1  5]\n",
      " [ 5  1  1  0  4  0 19 12  0  4]\n",
      " [ 1  2  3  8  9  7  4  9  2  2]\n",
      " [ 2  3  1 15  2  3 26  2  1  1]\n",
      " [ 3 10  0  2  7 10  0  5  1 12]]\n",
      "Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.42      0.34        53\n",
      "           1       0.33      0.38      0.35        55\n",
      "           2       0.11      0.02      0.03        54\n",
      "           3       0.11      0.17      0.13        46\n",
      "           4       0.24      0.33      0.28        46\n",
      "           5       0.06      0.04      0.05        50\n",
      "           6       0.23      0.41      0.30        46\n",
      "           7       0.17      0.19      0.18        47\n",
      "           8       0.07      0.02      0.03        56\n",
      "           9       0.35      0.24      0.29        50\n",
      "\n",
      "    accuracy                           0.22       503\n",
      "   macro avg       0.20      0.22      0.20       503\n",
      "weighted avg       0.20      0.22      0.20       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(modelone,train_loaderone,num_epochstcn,learning_ratetcn)\n",
    "test_one=test(modelone,test_loaderone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f595f201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 2.235Train Acc: 0.174\n",
      "Epoch 2/50, Train Loss: 2.027Train Acc: 0.310\n",
      "Epoch 3/50, Train Loss: 1.876Train Acc: 0.430\n",
      "Epoch 4/50, Train Loss: 1.738Train Acc: 0.506\n",
      "Epoch 5/50, Train Loss: 1.581Train Acc: 0.578\n",
      "Epoch 6/50, Train Loss: 1.399Train Acc: 0.644\n",
      "Epoch 7/50, Train Loss: 1.208Train Acc: 0.692\n",
      "Epoch 8/50, Train Loss: 1.030Train Acc: 0.772\n",
      "Epoch 9/50, Train Loss: 0.879Train Acc: 0.794\n",
      "Epoch 10/50, Train Loss: 0.736Train Acc: 0.834\n",
      "Epoch 11/50, Train Loss: 0.635Train Acc: 0.868\n",
      "Epoch 12/50, Train Loss: 0.538Train Acc: 0.906\n",
      "Epoch 13/50, Train Loss: 0.483Train Acc: 0.908\n",
      "Epoch 14/50, Train Loss: 0.412Train Acc: 0.920\n",
      "Epoch 15/50, Train Loss: 0.371Train Acc: 0.928\n",
      "Epoch 16/50, Train Loss: 0.335Train Acc: 0.936\n",
      "Epoch 17/50, Train Loss: 0.317Train Acc: 0.934\n",
      "Epoch 18/50, Train Loss: 0.274Train Acc: 0.946\n",
      "Epoch 19/50, Train Loss: 0.239Train Acc: 0.950\n",
      "Epoch 20/50, Train Loss: 0.204Train Acc: 0.970\n",
      "Epoch 21/50, Train Loss: 0.189Train Acc: 0.962\n",
      "Epoch 22/50, Train Loss: 0.168Train Acc: 0.974\n",
      "Epoch 23/50, Train Loss: 0.151Train Acc: 0.970\n",
      "Epoch 24/50, Train Loss: 0.149Train Acc: 0.976\n",
      "Epoch 25/50, Train Loss: 0.136Train Acc: 0.970\n",
      "Epoch 26/50, Train Loss: 0.122Train Acc: 0.982\n",
      "Epoch 27/50, Train Loss: 0.102Train Acc: 0.988\n",
      "Epoch 28/50, Train Loss: 0.095Train Acc: 0.982\n",
      "Epoch 29/50, Train Loss: 0.087Train Acc: 0.984\n",
      "Epoch 30/50, Train Loss: 0.082Train Acc: 0.990\n",
      "Epoch 31/50, Train Loss: 0.071Train Acc: 0.990\n",
      "Epoch 32/50, Train Loss: 0.065Train Acc: 0.992\n",
      "Epoch 33/50, Train Loss: 0.058Train Acc: 0.992\n",
      "Epoch 34/50, Train Loss: 0.065Train Acc: 0.986\n",
      "Epoch 35/50, Train Loss: 0.092Train Acc: 0.976\n",
      "Epoch 36/50, Train Loss: 0.076Train Acc: 0.990\n",
      "Epoch 37/50, Train Loss: 0.088Train Acc: 0.980\n",
      "Epoch 38/50, Train Loss: 0.056Train Acc: 0.994\n",
      "Epoch 39/50, Train Loss: 0.045Train Acc: 0.998\n",
      "Epoch 40/50, Train Loss: 0.037Train Acc: 1.000\n",
      "Epoch 41/50, Train Loss: 0.031Train Acc: 1.000\n",
      "Epoch 42/50, Train Loss: 0.028Train Acc: 1.000\n",
      "Epoch 43/50, Train Loss: 0.027Train Acc: 1.000\n",
      "Epoch 44/50, Train Loss: 0.025Train Acc: 1.000\n",
      "Epoch 45/50, Train Loss: 0.022Train Acc: 1.000\n",
      "Epoch 46/50, Train Loss: 0.021Train Acc: 1.000\n",
      "Epoch 47/50, Train Loss: 0.023Train Acc: 1.000\n",
      "Epoch 48/50, Train Loss: 0.022Train Acc: 1.000\n",
      "Epoch 49/50, Train Loss: 0.019Train Acc: 1.000\n",
      "Epoch 50/50, Train Loss: 0.018Train Acc: 1.000\n",
      "Test Loss: 0.207, Test Acc: 0.306\n",
      "Test confusion matrix:\n",
      "[[27  7  0  2  8  0  0  6  0  3]\n",
      " [ 0 36  0  0  0  1 13  2  0  3]\n",
      " [ 1 11  8  0  5  0 15 10  1  3]\n",
      " [ 0 12  0 21  0  4  4  0  0  5]\n",
      " [34  7  1  0  1  0  2  0  0  1]\n",
      " [ 0 19  0  0  0 18  2  1  0 10]\n",
      " [ 3 23  0  4  0  0 10  4  0  2]\n",
      " [ 2  6  0  4  4  3  6 10  4  8]\n",
      " [ 3  2  0  1  3  0 40  1  3  3]\n",
      " [ 0  8  0  2  0 18  1  1  0 20]]\n",
      "Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.51      0.44        53\n",
      "           1       0.27      0.65      0.39        55\n",
      "           2       0.89      0.15      0.25        54\n",
      "           3       0.62      0.46      0.52        46\n",
      "           4       0.05      0.02      0.03        46\n",
      "           5       0.41      0.36      0.38        50\n",
      "           6       0.11      0.22      0.14        46\n",
      "           7       0.29      0.21      0.24        47\n",
      "           8       0.38      0.05      0.09        56\n",
      "           9       0.34      0.40      0.37        50\n",
      "\n",
      "    accuracy                           0.31       503\n",
      "   macro avg       0.37      0.30      0.29       503\n",
      "weighted avg       0.38      0.31      0.29       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(modelonernn,train_loaderone,num_epochstcn,learning_ratetcn)\n",
    "test_one=test(modelonernn,test_loaderone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3e4aec",
   "metadata": {},
   "source": [
    "From this we can observe that when we train both our models on training data with only one speaker both the models overfit the training data with RNN model acheving training accuracy of 1.0 and TCN with 0.990 but the performance on the testing data decreased in both cases with RNN acheiving a test accuracy of 0.306 and 0.219 for RNN and TCN respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f0bae3",
   "metadata": {
    "id": "98f0bae3"
   },
   "source": [
    "# Frequency masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3523f0f2",
   "metadata": {
    "id": "3523f0f2"
   },
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "sdr_df = pd.read_csv('SDR_metadata.tsv', sep='\\t', header=0, index_col='Unnamed: 0')\n",
    "\n",
    "# Load data for each audio file, downsample and extract mel-spectrogram features\n",
    "def load_downsample_melspec(audio_file, sr=8000, num_mels=13, hop_length=80):\n",
    "    signal, _ = librosa.load(audio_file, sr=sr)\n",
    "    mel_features = extract_melspectrogram(signal,sr=8000, num_mels=13)\n",
    "    return mel_features\n",
    "\n",
    "\n",
    "max_length = 0\n",
    "for _, row in sdr_df.iterrows():\n",
    "    mel_spec = load_downsample_melspec(row['file'])\n",
    "    if mel_spec.shape[1] > max_length:\n",
    "        max_length = mel_spec.shape[1]\n",
    "\n",
    "# Load data and labels for all files in the metadata\n",
    "X = []\n",
    "y = []\n",
    "for _, row in sdr_df.iterrows():\n",
    "    mel_features = load_downsample_melspec(row['file'])\n",
    "    padded_mel_features = np.pad(mel_features, ((0, 0), (0, max_length - mel_features.shape[1])), mode='constant')\n",
    "    X.append(padded_mel_features)\n",
    "    y.append(row['label'])\n",
    "speakers=[\"george\"]\n",
    "# Split data into train, dev, and test sets\n",
    "train_indices = sdr_df[sdr_df['split'] == 'TRAIN']\n",
    "train_indices= train_indices[train_indices['speaker'].isin(speakers)].index\n",
    "dev_indices = sdr_df[sdr_df['split'] == 'DEV'].index\n",
    "test_indices = sdr_df[sdr_df['split'] == 'TEST'].index\n",
    "\n",
    "X_train = [X[i] for i in train_indices]\n",
    "y_train = [y[i] for i in train_indices]\n",
    "\n",
    "X_dev = [X[i] for i in dev_indices]\n",
    "y_dev = [y[i] for i in dev_indices]\n",
    "\n",
    "X_test = [X[i] for i in test_indices]\n",
    "y_test = [y[i] for i in test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5ce2f590",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "5ce2f590",
    "outputId": "07341898-a131-46e5-cdb7-ca92984f7268"
   },
   "outputs": [],
   "source": [
    "def apply_frequency_masking(spec, num_masks=1, freq_mask_param=10):\n",
    "    \n",
    "    spec = spec.copy()\n",
    "    for i in range(num_masks):\n",
    "        f = random.randint(0, freq_mask_param)\n",
    "        f0 = random.randint(0, spec.shape[0] - f)\n",
    "        spec[f0:f0+f, :] = 0\n",
    "    return spec\n",
    "\n",
    "X_train_augmented = []\n",
    "y_train_augmented = []\n",
    "\n",
    "for spec, label in zip(X_train, y_train):\n",
    "    for i in range(3):  # Generate 3 augmented samples for each original sample\n",
    "        spec_augmented = apply_frequency_masking(spec)\n",
    "        X_train_augmented.append(spec_augmented)\n",
    "        y_train_augmented.append(label)\n",
    "\n",
    "X_train_augmented = np.array(X_train_augmented)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6a85f561",
   "metadata": {
    "id": "6a85f561"
   },
   "outputs": [],
   "source": [
    "X_train_oneaug = torch.tensor(X_train_augmented, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "97561c38",
   "metadata": {
    "id": "97561c38"
   },
   "outputs": [],
   "source": [
    "y_train_oneaug=torch.tensor(y_train_augmented, dtype=torch.long)\n",
    "\n",
    "X_dev = torch.tensor(X_dev, dtype=torch.float32)\n",
    "y_dev = torch.tensor(y_dev, dtype=torch.long)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "70b1242b",
   "metadata": {
    "id": "70b1242b"
   },
   "outputs": [],
   "source": [
    "train_loaderfre,dev_loaderfre,test_loaderfre=loader(X_train_oneaug,y_train_oneaug,X_dev,y_dev,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "785c3e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfr = TCN(input_size, output_size, num_channels=[64, 64, 64], kernel_size=3,dropout=0.2)\n",
    "modelfrrnn=RNNModel(input_size, 60, 2, output_size, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "662b96f8",
   "metadata": {
    "id": "662b96f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 1.974Train Acc: 0.328\n",
      "Epoch 2/50, Train Loss: 1.457Train Acc: 0.527\n",
      "Epoch 3/50, Train Loss: 1.179Train Acc: 0.632\n",
      "Epoch 4/50, Train Loss: 0.999Train Acc: 0.702\n",
      "Epoch 5/50, Train Loss: 0.873Train Acc: 0.717\n",
      "Epoch 6/50, Train Loss: 0.724Train Acc: 0.769\n",
      "Epoch 7/50, Train Loss: 0.665Train Acc: 0.785\n",
      "Epoch 8/50, Train Loss: 0.552Train Acc: 0.827\n",
      "Epoch 9/50, Train Loss: 0.501Train Acc: 0.848\n",
      "Epoch 10/50, Train Loss: 0.463Train Acc: 0.854\n",
      "Epoch 11/50, Train Loss: 0.462Train Acc: 0.855\n",
      "Epoch 12/50, Train Loss: 0.404Train Acc: 0.877\n",
      "Epoch 13/50, Train Loss: 0.375Train Acc: 0.885\n",
      "Epoch 14/50, Train Loss: 0.343Train Acc: 0.895\n",
      "Epoch 15/50, Train Loss: 0.303Train Acc: 0.903\n",
      "Epoch 16/50, Train Loss: 0.307Train Acc: 0.903\n",
      "Epoch 17/50, Train Loss: 0.277Train Acc: 0.913\n",
      "Epoch 18/50, Train Loss: 0.245Train Acc: 0.927\n",
      "Epoch 19/50, Train Loss: 0.245Train Acc: 0.917\n",
      "Epoch 20/50, Train Loss: 0.233Train Acc: 0.931\n",
      "Epoch 21/50, Train Loss: 0.207Train Acc: 0.941\n",
      "Epoch 22/50, Train Loss: 0.188Train Acc: 0.945\n",
      "Epoch 23/50, Train Loss: 0.159Train Acc: 0.959\n",
      "Epoch 24/50, Train Loss: 0.180Train Acc: 0.949\n",
      "Epoch 25/50, Train Loss: 0.169Train Acc: 0.950\n",
      "Epoch 26/50, Train Loss: 0.149Train Acc: 0.959\n",
      "Epoch 27/50, Train Loss: 0.167Train Acc: 0.950\n",
      "Epoch 28/50, Train Loss: 0.132Train Acc: 0.966\n",
      "Epoch 29/50, Train Loss: 0.132Train Acc: 0.960\n",
      "Epoch 30/50, Train Loss: 0.141Train Acc: 0.957\n",
      "Epoch 31/50, Train Loss: 0.131Train Acc: 0.959\n",
      "Epoch 32/50, Train Loss: 0.126Train Acc: 0.959\n",
      "Epoch 33/50, Train Loss: 0.128Train Acc: 0.964\n",
      "Epoch 34/50, Train Loss: 0.127Train Acc: 0.961\n",
      "Epoch 35/50, Train Loss: 0.111Train Acc: 0.969\n",
      "Epoch 36/50, Train Loss: 0.151Train Acc: 0.949\n",
      "Epoch 37/50, Train Loss: 0.136Train Acc: 0.954\n",
      "Epoch 38/50, Train Loss: 0.095Train Acc: 0.970\n",
      "Epoch 39/50, Train Loss: 0.116Train Acc: 0.969\n",
      "Epoch 40/50, Train Loss: 0.095Train Acc: 0.972\n",
      "Epoch 41/50, Train Loss: 0.104Train Acc: 0.972\n",
      "Epoch 42/50, Train Loss: 0.091Train Acc: 0.975\n",
      "Epoch 43/50, Train Loss: 0.085Train Acc: 0.974\n",
      "Epoch 44/50, Train Loss: 0.103Train Acc: 0.964\n",
      "Epoch 45/50, Train Loss: 0.084Train Acc: 0.980\n",
      "Epoch 46/50, Train Loss: 0.101Train Acc: 0.969\n",
      "Epoch 47/50, Train Loss: 0.084Train Acc: 0.978\n",
      "Epoch 48/50, Train Loss: 0.092Train Acc: 0.969\n",
      "Epoch 49/50, Train Loss: 0.065Train Acc: 0.979\n",
      "Epoch 50/50, Train Loss: 0.071Train Acc: 0.981\n"
     ]
    }
   ],
   "source": [
    "train_model(modelfr,train_loaderfre,num_epochstcn,learning_ratetcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b012ee46",
   "metadata": {
    "id": "b012ee46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.215, Test Acc: 0.207\n",
      "Test confusion matrix:\n",
      "[[11 16  6  0  4  7  4  4  0  1]\n",
      " [ 6 14  2  5  8  3 17  0  0  0]\n",
      " [ 4  5  2 10  6  6 19  1  1  0]\n",
      " [ 5  9  7  8  7  0  7  2  0  1]\n",
      " [ 3 10  2  3 15  2 10  0  1  0]\n",
      " [10 17  1  2  2  6  6  4  0  2]\n",
      " [ 6  3  0  0  4  1 28  4  0  0]\n",
      " [ 7  1  2  1  8  8  8  9  1  2]\n",
      " [ 2  7  7  5  8  3 21  2  1  0]\n",
      " [ 5 17  0  2  6  8  1  1  0 10]]\n",
      "Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.21      0.20        53\n",
      "           1       0.14      0.25      0.18        55\n",
      "           2       0.07      0.04      0.05        54\n",
      "           3       0.22      0.17      0.20        46\n",
      "           4       0.22      0.33      0.26        46\n",
      "           5       0.14      0.12      0.13        50\n",
      "           6       0.23      0.61      0.34        46\n",
      "           7       0.33      0.19      0.24        47\n",
      "           8       0.25      0.02      0.03        56\n",
      "           9       0.62      0.20      0.30        50\n",
      "\n",
      "    accuracy                           0.21       503\n",
      "   macro avg       0.24      0.21      0.19       503\n",
      "weighted avg       0.24      0.21      0.19       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_fr=test(modelfr,test_loaderfre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa1a7a6",
   "metadata": {},
   "source": [
    "From this report we can see that TCN acheives a good training accuracy while on the test set it acheives an accuracy of 0.207\n",
    "We can conclude from this that the TCN model is overfitting to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "679e6f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 2.105Train Acc: 0.260\n",
      "Epoch 2/50, Train Loss: 1.851Train Acc: 0.396\n",
      "Epoch 3/50, Train Loss: 1.672Train Acc: 0.493\n",
      "Epoch 4/50, Train Loss: 1.515Train Acc: 0.529\n",
      "Epoch 5/50, Train Loss: 1.391Train Acc: 0.579\n",
      "Epoch 6/50, Train Loss: 1.251Train Acc: 0.627\n",
      "Epoch 7/50, Train Loss: 1.160Train Acc: 0.655\n",
      "Epoch 8/50, Train Loss: 1.064Train Acc: 0.691\n",
      "Epoch 9/50, Train Loss: 0.967Train Acc: 0.722\n",
      "Epoch 10/50, Train Loss: 0.886Train Acc: 0.743\n",
      "Epoch 11/50, Train Loss: 0.844Train Acc: 0.743\n",
      "Epoch 12/50, Train Loss: 0.766Train Acc: 0.781\n",
      "Epoch 13/50, Train Loss: 0.728Train Acc: 0.781\n",
      "Epoch 14/50, Train Loss: 0.677Train Acc: 0.799\n",
      "Epoch 15/50, Train Loss: 0.633Train Acc: 0.810\n",
      "Epoch 16/50, Train Loss: 0.573Train Acc: 0.821\n",
      "Epoch 17/50, Train Loss: 0.558Train Acc: 0.845\n",
      "Epoch 18/50, Train Loss: 0.520Train Acc: 0.847\n",
      "Epoch 19/50, Train Loss: 0.497Train Acc: 0.857\n",
      "Epoch 20/50, Train Loss: 0.465Train Acc: 0.864\n",
      "Epoch 21/50, Train Loss: 0.426Train Acc: 0.874\n",
      "Epoch 22/50, Train Loss: 0.417Train Acc: 0.873\n",
      "Epoch 23/50, Train Loss: 0.390Train Acc: 0.884\n",
      "Epoch 24/50, Train Loss: 0.351Train Acc: 0.902\n",
      "Epoch 25/50, Train Loss: 0.343Train Acc: 0.903\n",
      "Epoch 26/50, Train Loss: 0.338Train Acc: 0.903\n",
      "Epoch 27/50, Train Loss: 0.339Train Acc: 0.899\n",
      "Epoch 28/50, Train Loss: 0.306Train Acc: 0.902\n",
      "Epoch 29/50, Train Loss: 0.294Train Acc: 0.912\n",
      "Epoch 30/50, Train Loss: 0.269Train Acc: 0.919\n",
      "Epoch 31/50, Train Loss: 0.254Train Acc: 0.930\n",
      "Epoch 32/50, Train Loss: 0.251Train Acc: 0.933\n",
      "Epoch 33/50, Train Loss: 0.263Train Acc: 0.919\n",
      "Epoch 34/50, Train Loss: 0.233Train Acc: 0.940\n",
      "Epoch 35/50, Train Loss: 0.179Train Acc: 0.951\n",
      "Epoch 36/50, Train Loss: 0.192Train Acc: 0.943\n",
      "Epoch 37/50, Train Loss: 0.197Train Acc: 0.937\n",
      "Epoch 38/50, Train Loss: 0.176Train Acc: 0.954\n",
      "Epoch 39/50, Train Loss: 0.168Train Acc: 0.951\n",
      "Epoch 40/50, Train Loss: 0.207Train Acc: 0.931\n",
      "Epoch 41/50, Train Loss: 0.196Train Acc: 0.937\n",
      "Epoch 42/50, Train Loss: 0.148Train Acc: 0.959\n",
      "Epoch 43/50, Train Loss: 0.166Train Acc: 0.946\n",
      "Epoch 44/50, Train Loss: 0.141Train Acc: 0.962\n",
      "Epoch 45/50, Train Loss: 0.118Train Acc: 0.969\n",
      "Epoch 46/50, Train Loss: 0.124Train Acc: 0.965\n",
      "Epoch 47/50, Train Loss: 0.131Train Acc: 0.964\n",
      "Epoch 48/50, Train Loss: 0.163Train Acc: 0.946\n",
      "Epoch 49/50, Train Loss: 0.123Train Acc: 0.966\n",
      "Epoch 50/50, Train Loss: 0.099Train Acc: 0.976\n",
      "Test Loss: 0.231, Test Acc: 0.225\n",
      "Test confusion matrix:\n",
      "[[30  8  0  0  7  0  1  4  0  3]\n",
      " [ 4 14  0  4  5  0 24  3  0  1]\n",
      " [11  7  2  3  8  0 21  0  2  0]\n",
      " [ 4 11  0  6  0  4 14  3  0  4]\n",
      " [11  7  1  0  9  0 10  3  0  5]\n",
      " [ 4 17  0  0  0  9  5 11  1  3]\n",
      " [ 2 10  0  0  4  0 22  6  0  2]\n",
      " [ 7  6  0  7  6  2  2 11  2  4]\n",
      " [ 2  2  0 13  4  1 31  0  1  2]\n",
      " [ 9 14  0  2  0 12  1  3  0  9]]\n",
      "Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.57      0.44        53\n",
      "           1       0.15      0.25      0.19        55\n",
      "           2       0.67      0.04      0.07        54\n",
      "           3       0.17      0.13      0.15        46\n",
      "           4       0.21      0.20      0.20        46\n",
      "           5       0.32      0.18      0.23        50\n",
      "           6       0.17      0.48      0.25        46\n",
      "           7       0.25      0.23      0.24        47\n",
      "           8       0.17      0.02      0.03        56\n",
      "           9       0.27      0.18      0.22        50\n",
      "\n",
      "    accuracy                           0.22       503\n",
      "   macro avg       0.27      0.23      0.20       503\n",
      "weighted avg       0.28      0.22      0.20       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(modelfrrnn,train_loaderfre,num_epochstcn,learning_ratetcn)\n",
    "test_fr=test(modelfrrnn,test_loaderfre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05055509",
   "metadata": {},
   "source": [
    "From this report we can see that RNN acheives a good training accuracy while on the test set it acheives an accuracy of 0.225\n",
    "We can conclude from this that the RNN model is overfitting to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ccd6a6bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "ccd6a6bf",
    "outputId": "90cecf40-0aba-4169-9833-eb623eda7582"
   },
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "sdr_df = pd.read_csv('SDR_metadata.tsv', sep='\\t', header=0, index_col='Unnamed: 0')\n",
    "\n",
    "# Load data for each audio file, downsample and extract mel-spectrogram features\n",
    "def load_downsample_melspec(audio_file, sr=8000, num_mels=13, hop_length=80, pitch_shift=None):\n",
    "    signal, _ = librosa.load(audio_file, sr=sr)\n",
    "    if pitch_shift:\n",
    "        signal = librosa.effects.pitch_shift(signal, sr, n_steps=pitch_shift)\n",
    "    mel_features = extract_melspectrogram(signal,sr=8000, num_mels=13)\n",
    "    return mel_features\n",
    "\n",
    "\n",
    "max_length = 0\n",
    "for _, row in sdr_df.iterrows():\n",
    "    mel_spec = load_downsample_melspec(row['file'])\n",
    "    if mel_spec.shape[1] > max_length:\n",
    "        max_length = mel_spec.shape[1]\n",
    "\n",
    "# Load data and labels for all files in the metadata\n",
    "X = []\n",
    "y = []\n",
    "for _, row in sdr_df.iterrows():\n",
    "    if row['split'] == 'TRAIN':\n",
    "        mel_features = load_downsample_melspec(row['file'], pitch_shift=2)\n",
    "    else:\n",
    "        mel_features = load_downsample_melspec(row['file'])\n",
    "    padded_mel_features = np.pad(mel_features, ((0, 0), (0, max_length - mel_features.shape[1])), mode='constant')\n",
    "    X.append(padded_mel_features)\n",
    "    y.append(row['label'])\n",
    "\n",
    "speakers=[\"george\"]\n",
    "# Split data into train, dev, and test sets\n",
    "train_indices_p = sdr_df[sdr_df['split'] == 'TRAIN']\n",
    "train_indices_p= train_indices_p[train_indices_p['speaker'].isin(speakers)].index\n",
    "dev_indices = sdr_df[sdr_df['split'] == 'DEV'].index\n",
    "test_indices = sdr_df[sdr_df['split'] == 'TEST'].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c528c6a7",
   "metadata": {
    "id": "c528c6a7"
   },
   "outputs": [],
   "source": [
    "X_train = [X[i] for i in train_indices_p]\n",
    "y_train = [y[i] for i in train_indices_p]\n",
    "\n",
    "X_dev = [X[i] for i in dev_indices]\n",
    "y_dev = [y[i] for i in dev_indices]\n",
    "\n",
    "X_test = [X[i] for i in test_indices]\n",
    "y_test = [y[i] for i in test_indices]\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_p = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_p = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_dev = torch.tensor(X_dev, dtype=torch.float32)\n",
    "y_dev = torch.tensor(y_dev, dtype=torch.long)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c0016ca0",
   "metadata": {
    "id": "c0016ca0"
   },
   "outputs": [],
   "source": [
    "train_loaderp,dev_loaderp,test_loaderp=loader(X_train_p,y_train_p,X_dev,y_dev,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c7e01f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelp = TCN(input_size, output_size, num_channels=[64, 64, 64], kernel_size=3,dropout=0.2)\n",
    "modelrnnp=RNNModel(input_size, 60, 2, output_size, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7297bccd",
   "metadata": {
    "id": "7297bccd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 2.203Train Acc: 0.270\n",
      "Epoch 2/50, Train Loss: 1.798Train Acc: 0.398\n",
      "Epoch 3/50, Train Loss: 1.609Train Acc: 0.478\n",
      "Epoch 4/50, Train Loss: 1.463Train Acc: 0.576\n",
      "Epoch 5/50, Train Loss: 1.322Train Acc: 0.604\n",
      "Epoch 6/50, Train Loss: 1.198Train Acc: 0.658\n",
      "Epoch 7/50, Train Loss: 1.068Train Acc: 0.718\n",
      "Epoch 8/50, Train Loss: 0.998Train Acc: 0.732\n",
      "Epoch 9/50, Train Loss: 0.862Train Acc: 0.790\n",
      "Epoch 10/50, Train Loss: 0.784Train Acc: 0.818\n",
      "Epoch 11/50, Train Loss: 0.692Train Acc: 0.820\n",
      "Epoch 12/50, Train Loss: 0.680Train Acc: 0.826\n",
      "Epoch 13/50, Train Loss: 0.606Train Acc: 0.836\n",
      "Epoch 14/50, Train Loss: 0.540Train Acc: 0.866\n",
      "Epoch 15/50, Train Loss: 0.505Train Acc: 0.870\n",
      "Epoch 16/50, Train Loss: 0.467Train Acc: 0.878\n",
      "Epoch 17/50, Train Loss: 0.424Train Acc: 0.890\n",
      "Epoch 18/50, Train Loss: 0.415Train Acc: 0.896\n",
      "Epoch 19/50, Train Loss: 0.340Train Acc: 0.928\n",
      "Epoch 20/50, Train Loss: 0.358Train Acc: 0.906\n",
      "Epoch 21/50, Train Loss: 0.334Train Acc: 0.926\n",
      "Epoch 22/50, Train Loss: 0.306Train Acc: 0.934\n",
      "Epoch 23/50, Train Loss: 0.271Train Acc: 0.942\n",
      "Epoch 24/50, Train Loss: 0.266Train Acc: 0.946\n",
      "Epoch 25/50, Train Loss: 0.246Train Acc: 0.940\n",
      "Epoch 26/50, Train Loss: 0.210Train Acc: 0.960\n",
      "Epoch 27/50, Train Loss: 0.216Train Acc: 0.958\n",
      "Epoch 28/50, Train Loss: 0.237Train Acc: 0.940\n",
      "Epoch 29/50, Train Loss: 0.224Train Acc: 0.950\n",
      "Epoch 30/50, Train Loss: 0.163Train Acc: 0.970\n",
      "Epoch 31/50, Train Loss: 0.153Train Acc: 0.960\n",
      "Epoch 32/50, Train Loss: 0.170Train Acc: 0.964\n",
      "Epoch 33/50, Train Loss: 0.164Train Acc: 0.966\n",
      "Epoch 34/50, Train Loss: 0.177Train Acc: 0.956\n",
      "Epoch 35/50, Train Loss: 0.164Train Acc: 0.954\n",
      "Epoch 36/50, Train Loss: 0.150Train Acc: 0.966\n",
      "Epoch 37/50, Train Loss: 0.130Train Acc: 0.976\n",
      "Epoch 38/50, Train Loss: 0.131Train Acc: 0.968\n",
      "Epoch 39/50, Train Loss: 0.108Train Acc: 0.986\n",
      "Epoch 40/50, Train Loss: 0.124Train Acc: 0.972\n",
      "Epoch 41/50, Train Loss: 0.110Train Acc: 0.978\n",
      "Epoch 42/50, Train Loss: 0.099Train Acc: 0.982\n",
      "Epoch 43/50, Train Loss: 0.103Train Acc: 0.978\n",
      "Epoch 44/50, Train Loss: 0.105Train Acc: 0.974\n",
      "Epoch 45/50, Train Loss: 0.113Train Acc: 0.984\n",
      "Epoch 46/50, Train Loss: 0.085Train Acc: 0.988\n",
      "Epoch 47/50, Train Loss: 0.070Train Acc: 0.986\n",
      "Epoch 48/50, Train Loss: 0.068Train Acc: 0.990\n",
      "Epoch 49/50, Train Loss: 0.067Train Acc: 0.990\n",
      "Epoch 50/50, Train Loss: 0.053Train Acc: 0.996\n"
     ]
    }
   ],
   "source": [
    "train_model(modelp,train_loaderp,num_epochstcn,learning_ratetcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "953ad7f2",
   "metadata": {
    "id": "953ad7f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.205, Test Acc: 0.207\n",
      "Test confusion matrix:\n",
      "[[24  0  0  3  5  3  8 10  0  0]\n",
      " [ 4  5  0 16  0  0 26  2  2  0]\n",
      " [ 0  1  3  2  1  0 33 11  2  1]\n",
      " [15  2  0 10  4  0 11  3  0  1]\n",
      " [ 9  0  0  9  6  2 10 10  0  0]\n",
      " [ 9  5  0  5  0  3 21  3  2  2]\n",
      " [ 3  2  0  6  1  0 28  5  0  1]\n",
      " [ 7  0  1  3  5  0 12 17  2  0]\n",
      " [ 9  0  0  9  0  0 32  4  1  1]\n",
      " [ 3  5  0  3  3  3 14 12  0  7]]\n",
      "Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.45      0.35        53\n",
      "           1       0.25      0.09      0.13        55\n",
      "           2       0.75      0.06      0.10        54\n",
      "           3       0.15      0.22      0.18        46\n",
      "           4       0.24      0.13      0.17        46\n",
      "           5       0.27      0.06      0.10        50\n",
      "           6       0.14      0.61      0.23        46\n",
      "           7       0.22      0.36      0.27        47\n",
      "           8       0.11      0.02      0.03        56\n",
      "           9       0.54      0.14      0.22        50\n",
      "\n",
      "    accuracy                           0.21       503\n",
      "   macro avg       0.30      0.21      0.18       503\n",
      "weighted avg       0.30      0.21      0.18       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_p=test(modelp,test_loaderp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1a834460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 2.192Train Acc: 0.216\n",
      "Epoch 2/50, Train Loss: 2.029Train Acc: 0.306\n",
      "Epoch 3/50, Train Loss: 1.925Train Acc: 0.396\n",
      "Epoch 4/50, Train Loss: 1.767Train Acc: 0.466\n",
      "Epoch 5/50, Train Loss: 1.516Train Acc: 0.578\n",
      "Epoch 6/50, Train Loss: 1.273Train Acc: 0.670\n",
      "Epoch 7/50, Train Loss: 1.088Train Acc: 0.710\n",
      "Epoch 8/50, Train Loss: 0.930Train Acc: 0.760\n",
      "Epoch 9/50, Train Loss: 0.798Train Acc: 0.806\n",
      "Epoch 10/50, Train Loss: 0.690Train Acc: 0.844\n",
      "Epoch 11/50, Train Loss: 0.625Train Acc: 0.848\n",
      "Epoch 12/50, Train Loss: 0.524Train Acc: 0.896\n",
      "Epoch 13/50, Train Loss: 0.445Train Acc: 0.898\n",
      "Epoch 14/50, Train Loss: 0.394Train Acc: 0.918\n",
      "Epoch 15/50, Train Loss: 0.338Train Acc: 0.930\n",
      "Epoch 16/50, Train Loss: 0.311Train Acc: 0.922\n",
      "Epoch 17/50, Train Loss: 0.271Train Acc: 0.952\n",
      "Epoch 18/50, Train Loss: 0.247Train Acc: 0.960\n",
      "Epoch 19/50, Train Loss: 0.234Train Acc: 0.954\n",
      "Epoch 20/50, Train Loss: 0.217Train Acc: 0.964\n",
      "Epoch 21/50, Train Loss: 0.187Train Acc: 0.966\n",
      "Epoch 22/50, Train Loss: 0.177Train Acc: 0.970\n",
      "Epoch 23/50, Train Loss: 0.152Train Acc: 0.978\n",
      "Epoch 24/50, Train Loss: 0.140Train Acc: 0.984\n",
      "Epoch 25/50, Train Loss: 0.125Train Acc: 0.986\n",
      "Epoch 26/50, Train Loss: 0.114Train Acc: 0.984\n",
      "Epoch 27/50, Train Loss: 0.098Train Acc: 0.988\n",
      "Epoch 28/50, Train Loss: 0.090Train Acc: 0.992\n",
      "Epoch 29/50, Train Loss: 0.084Train Acc: 0.994\n",
      "Epoch 30/50, Train Loss: 0.073Train Acc: 0.992\n",
      "Epoch 31/50, Train Loss: 0.091Train Acc: 0.984\n",
      "Epoch 32/50, Train Loss: 0.072Train Acc: 0.990\n",
      "Epoch 33/50, Train Loss: 0.069Train Acc: 0.990\n",
      "Epoch 34/50, Train Loss: 0.065Train Acc: 0.994\n",
      "Epoch 35/50, Train Loss: 0.048Train Acc: 0.998\n",
      "Epoch 36/50, Train Loss: 0.047Train Acc: 0.996\n",
      "Epoch 37/50, Train Loss: 0.044Train Acc: 0.998\n",
      "Epoch 38/50, Train Loss: 0.038Train Acc: 0.998\n",
      "Epoch 39/50, Train Loss: 0.039Train Acc: 0.994\n",
      "Epoch 40/50, Train Loss: 0.032Train Acc: 0.998\n",
      "Epoch 41/50, Train Loss: 0.030Train Acc: 0.998\n",
      "Epoch 42/50, Train Loss: 0.027Train Acc: 0.998\n",
      "Epoch 43/50, Train Loss: 0.024Train Acc: 0.998\n",
      "Epoch 44/50, Train Loss: 0.028Train Acc: 0.998\n",
      "Epoch 45/50, Train Loss: 0.021Train Acc: 0.998\n",
      "Epoch 46/50, Train Loss: 0.019Train Acc: 1.000\n",
      "Epoch 47/50, Train Loss: 0.018Train Acc: 0.998\n",
      "Epoch 48/50, Train Loss: 0.017Train Acc: 1.000\n",
      "Epoch 49/50, Train Loss: 0.016Train Acc: 1.000\n",
      "Epoch 50/50, Train Loss: 0.017Train Acc: 1.000\n",
      "Test Loss: 0.181, Test Acc: 0.203\n",
      "Test confusion matrix:\n",
      "[[25  1  1  4  1  0 11  9  0  1]\n",
      " [ 0 17  0  1  3  0 24  9  0  1]\n",
      " [ 9  1  4  2  2  0 22 12  1  1]\n",
      " [ 2  9  1 11  1 15  4  2  0  1]\n",
      " [17  4  5  2  1  0 12  5  0  0]\n",
      " [ 3 24  0  0  0  7  6 10  0  0]\n",
      " [ 2  2  1  4  0  5 15 17  0  0]\n",
      " [ 0  5  0  6  1  0 15 16  2  2]\n",
      " [ 7  1  2  4  2  0 25 12  1  2]\n",
      " [ 3 21  0  1  1  4  4 11  0  5]]\n",
      "Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.47      0.41        53\n",
      "           1       0.20      0.31      0.24        55\n",
      "           2       0.29      0.07      0.12        54\n",
      "           3       0.31      0.24      0.27        46\n",
      "           4       0.08      0.02      0.03        46\n",
      "           5       0.23      0.14      0.17        50\n",
      "           6       0.11      0.33      0.16        46\n",
      "           7       0.16      0.34      0.21        47\n",
      "           8       0.25      0.02      0.03        56\n",
      "           9       0.38      0.10      0.16        50\n",
      "\n",
      "    accuracy                           0.20       503\n",
      "   macro avg       0.24      0.20      0.18       503\n",
      "weighted avg       0.24      0.20      0.18       503\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.37      0.47      0.41        53\\n           1       0.20      0.31      0.24        55\\n           2       0.29      0.07      0.12        54\\n           3       0.31      0.24      0.27        46\\n           4       0.08      0.02      0.03        46\\n           5       0.23      0.14      0.17        50\\n           6       0.11      0.33      0.16        46\\n           7       0.16      0.34      0.21        47\\n           8       0.25      0.02      0.03        56\\n           9       0.38      0.10      0.16        50\\n\\n    accuracy                           0.20       503\\n   macro avg       0.24      0.20      0.18       503\\nweighted avg       0.24      0.20      0.18       503\\n'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(modelrnnp,train_loaderp,num_epochstcn,learning_ratetcn)\n",
    "test(modelrnnp,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a839f4c",
   "metadata": {
    "id": "e0989e37"
   },
   "source": [
    "Constrastive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9c45e4d9",
   "metadata": {
    "id": "9c45e4d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.9976\n",
      "Epoch 2: Train Loss=0.8222\n",
      "Epoch 3: Train Loss=-0.0234\n",
      "Epoch 4: Train Loss=-0.8923\n",
      "Epoch 5: Train Loss=-1.2639\n",
      "Epoch 6: Train Loss=-1.5666\n",
      "Epoch 7: Train Loss=-2.0405\n",
      "Epoch 8: Train Loss=-2.2692\n",
      "Epoch 9: Train Loss=-2.5132\n",
      "Epoch 10: Train Loss=-2.7047\n",
      "Epoch 11: Train Loss=-2.7901\n",
      "Epoch 12: Train Loss=-2.8538\n",
      "Epoch 13: Train Loss=-2.9577\n",
      "Epoch 14: Train Loss=-3.0099\n",
      "Epoch 15: Train Loss=-3.0776\n",
      "Epoch 16: Train Loss=-3.1692\n",
      "Epoch 17: Train Loss=-3.1752\n",
      "Epoch 18: Train Loss=-3.2043\n",
      "Epoch 19: Train Loss=-3.2114\n",
      "Epoch 20: Train Loss=-3.2702\n",
      "Epoch 21: Train Loss=-3.2862\n",
      "Epoch 22: Train Loss=-3.3374\n",
      "Epoch 23: Train Loss=-3.3382\n",
      "Epoch 24: Train Loss=-3.3498\n",
      "Epoch 25: Train Loss=-3.3425\n",
      "Epoch 26: Train Loss=-3.3724\n",
      "Epoch 27: Train Loss=-3.3571\n",
      "Epoch 28: Train Loss=-3.3910\n",
      "Epoch 29: Train Loss=-3.3906\n",
      "Epoch 30: Train Loss=-3.4018\n",
      "Epoch 31: Train Loss=-3.3970\n",
      "Epoch 32: Train Loss=-3.4204\n",
      "Epoch 33: Train Loss=-3.4115\n",
      "Epoch 34: Train Loss=-3.4280\n",
      "Epoch 35: Train Loss=-3.4355\n",
      "Epoch 36: Train Loss=-3.4421\n",
      "Epoch 37: Train Loss=-3.4437\n",
      "Epoch 38: Train Loss=-3.4498\n",
      "Epoch 39: Train Loss=-3.4588\n",
      "Epoch 40: Train Loss=-3.4560\n",
      "Epoch 41: Train Loss=-3.4647\n",
      "Epoch 42: Train Loss=-3.4664\n",
      "Epoch 43: Train Loss=-3.4675\n",
      "Epoch 44: Train Loss=-3.4711\n",
      "Epoch 45: Train Loss=-3.4769\n",
      "Epoch 46: Train Loss=-3.4750\n",
      "Epoch 47: Train Loss=-3.4810\n",
      "Epoch 48: Train Loss=-3.4843\n",
      "Epoch 49: Train Loss=-3.4842\n",
      "Epoch 50: Train Loss=-3.4852\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "class ContrastiveDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x1 = self.X[idx]\n",
    "        if self.transform:\n",
    "            x2 = self.transform(x1)\n",
    "        else:\n",
    "            x2 = x1\n",
    "        return x1, x2, self.y[idx]\n",
    "    \n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def forward(self, x1, x2, y):\n",
    "        dist = F.pairwise_distance(x1, x2)\n",
    "        loss = torch.mean((y * dist**2) + ((1 - y) * F.relu(self.margin - dist)**2))\n",
    "        return loss\n",
    "    \n",
    "\n",
    "def augment(x):\n",
    "    x = apply_frequency_masking(x)\n",
    "    return x\n",
    "\n",
    "# Create contrastive dataset\n",
    "train_dataset = ContrastiveDataset(X_train, y_train, transform=augment)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create model and optimizer\n",
    "modelcontra = TCN(input_size=229, output_size=2, num_channels=[32]*5, kernel_size=3, dropout=0.2)\n",
    "optimizer = Adam(modelcontra.parameters(), lr=0.001)\n",
    "\n",
    "# Train model\n",
    "criterion = ContrastiveLoss(margin=1.0)\n",
    "for epoch in range(50):\n",
    "    train_loss = 0.0\n",
    "    for x1, x2, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out1 = modelcontra(x1)\n",
    "        out2 = modelcontra(x2)\n",
    "        loss = criterion(out1, out2, y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * len(x1)\n",
    "    train_loss /= len(train_dataset)\n",
    "    \n",
    "  \n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "11184059",
   "metadata": {
    "id": "11184059"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10934393638170974"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "\n",
    "test_dataset = ContrastiveDataset(X_test, y_test, transform=None)\n",
    "modelcontra.eval()\n",
    "with torch.no_grad():\n",
    "    for x1, y in test_loader:\n",
    "        outputs = modelcontra(x1)\n",
    "        predicted_labels = torch.argmax(outputs, dim=1)\n",
    "        total_correct += (predicted_labels == y).sum().item()\n",
    "        total_samples += y.shape[0]\n",
    "test_acc=total_correct/total_samples\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff3379c",
   "metadata": {
    "id": "4ff3379c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1c2aecac",
   "metadata": {
    "id": "1c2aecac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=-1.3753\n",
      "Epoch 2: Train Loss=-2.4246\n",
      "Epoch 3: Train Loss=-2.9760\n",
      "Epoch 4: Train Loss=-3.2207\n",
      "Epoch 5: Train Loss=-3.3518\n",
      "Epoch 6: Train Loss=-3.4066\n",
      "Epoch 7: Train Loss=-3.4431\n",
      "Epoch 8: Train Loss=-3.4602\n",
      "Epoch 9: Train Loss=-3.4711\n",
      "Epoch 10: Train Loss=-3.4760\n",
      "Epoch 11: Train Loss=-3.4804\n",
      "Epoch 12: Train Loss=-3.4835\n",
      "Epoch 13: Train Loss=-3.4860\n",
      "Epoch 14: Train Loss=-3.4878\n",
      "Epoch 15: Train Loss=-3.4893\n",
      "Epoch 16: Train Loss=-3.4905\n",
      "Epoch 17: Train Loss=-3.4913\n",
      "Epoch 18: Train Loss=-3.4919\n",
      "Epoch 19: Train Loss=-3.4924\n",
      "Epoch 20: Train Loss=-3.4932\n",
      "Epoch 21: Train Loss=-3.4938\n",
      "Epoch 22: Train Loss=-3.4943\n",
      "Epoch 23: Train Loss=-3.4946\n",
      "Epoch 24: Train Loss=-3.4949\n",
      "Epoch 25: Train Loss=-3.4953\n",
      "Epoch 26: Train Loss=-3.4956\n",
      "Epoch 27: Train Loss=-3.4957\n",
      "Epoch 28: Train Loss=-3.4960\n",
      "Epoch 29: Train Loss=-3.4963\n",
      "Epoch 30: Train Loss=-3.4966\n",
      "Epoch 31: Train Loss=-3.4965\n",
      "Epoch 32: Train Loss=-3.4968\n",
      "Epoch 33: Train Loss=-3.4969\n",
      "Epoch 34: Train Loss=-3.4971\n",
      "Epoch 35: Train Loss=-3.4973\n",
      "Epoch 36: Train Loss=-3.4973\n",
      "Epoch 37: Train Loss=-3.4975\n",
      "Epoch 38: Train Loss=-3.4974\n",
      "Epoch 39: Train Loss=-3.4976\n",
      "Epoch 40: Train Loss=-3.4978\n",
      "Epoch 41: Train Loss=-3.4979\n",
      "Epoch 42: Train Loss=-3.4978\n",
      "Epoch 43: Train Loss=-3.4981\n",
      "Epoch 44: Train Loss=-3.4981\n",
      "Epoch 45: Train Loss=-3.4981\n",
      "Epoch 46: Train Loss=-3.4982\n",
      "Epoch 47: Train Loss=-3.4982\n",
      "Epoch 48: Train Loss=-3.4983\n",
      "Epoch 49: Train Loss=-3.4984\n",
      "Epoch 50: Train Loss=-3.4984\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "class ContrastiveDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x1 = self.X[idx]\n",
    "        if self.transform:\n",
    "            x2 = self.transform(x1)\n",
    "        else:\n",
    "            x2 = x1\n",
    "        return x1, x2, self.y[idx]\n",
    "    \n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def forward(self, x1, x2, y):\n",
    "        dist = F.pairwise_distance(x1, x2)\n",
    "        loss = torch.mean((y * dist**2) + ((1 - y) * F.relu(self.margin - dist)**2))\n",
    "        return loss\n",
    "    \n",
    "\n",
    "def augment(x):\n",
    "    x = apply_frequency_masking(x)\n",
    "    return x\n",
    "\n",
    "# Create contrastive dataset\n",
    "train_dataset = ContrastiveDataset(X_train, y_train, transform=augment)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create model and optimizer\n",
    "modelrnncontra=RNNModel(input_size, 60, 2, output_size, 0.2)\n",
    "optimizer = Adam(modelrnncontra.parameters(), lr=0.001)\n",
    "\n",
    "# Train model\n",
    "criterion = ContrastiveLoss(margin=1.0)\n",
    "for epoch in range(50):\n",
    "    train_loss = 0.0\n",
    "    for x1, x2, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out1 = modelrnncontra(x1)\n",
    "        out2 = modelrnncontra(x2)\n",
    "        loss = criterion(out1, out2, y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * len(x1)\n",
    "    train_loss /= len(train_dataset)\n",
    "    \n",
    "  \n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e1bd9c5d",
   "metadata": {
    "id": "e1bd9c5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09145129224652088"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "\n",
    "test_dataset = ContrastiveDataset(X_test, y_test, transform=None)\n",
    "modelrnncontra.eval()\n",
    "with torch.no_grad():\n",
    "    for x1, y in test_loader:\n",
    "        outputs = modelrnncontra(x1)\n",
    "        predicted_labels = torch.argmax(outputs, dim=1)\n",
    "        total_correct += (predicted_labels == y).sum().item()\n",
    "        total_samples += y.shape[0]\n",
    "test_acc=total_correct/total_samples\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6edf78",
   "metadata": {
    "id": "788899c9"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
